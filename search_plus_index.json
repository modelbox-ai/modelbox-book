{"./":{"url":"./","title":"ModelBox介绍","keywords":"","body":"ModelBox介绍 什么是ModelBox 一个典型场景AI算法的商用落地除了模型训练外，还需要进行视频图片解码、HTTP服务、预处理、后处理、多模型复杂业务串联、运维、打包等工程开发，往往需要耗费比模型训练多得多的时间，同时算法的性能和可靠性通常随开发人员的工程能力水平高低而参差不齐，严重影响AI算法的上线效率。 ModelBox是一套专门为AI开发者提供的易于使用，高效，高扩展的AI推理开发框架，它可以帮助AI开发者快速完成从模型文件到AI推理应用的开发和上线工作，降低AI算法落地门槛，同时带来AI应用的高稳定性和极致性能。 ModelBox特点 易于开发，AI推理业务可视化编排开发，功能模块化，丰富组件库；c++，python，java多语言支持。 易于集成，集成云上对接的组件，云上对接更容易。 高性能，高可靠，pipeline并发运行，数据计算智能调度，资源管理调度精细化，业务运行更高效。 软硬件异构， CPU，ARM，GPU，NPU多异构硬件支持，资源利用更便捷高效。 全场景，视频，语音，文本，NLP全场景，专为服务化定制，云上集成更容易，端边云数据无缝交换。 易于维护，服务运行状态可视化，应用，组件性能实时监控，优化更容易。 ModelBox主要功能 功能 说明 主要业务场景 快速完成AI推理业务的开发工作 支持数据类型 视频，图片，文字，通用数据，其他 用户群 软件开发者，研究人员，学生，平台集成商 跨平台 服务器， 边侧设备，嵌入式设备 图形化编排 支持模型的串联，支持视频流，音频流，图片等推理 API列表 C++SDK, PYTHON SDK, JAVA SDK(暂未支持) 支持OS Linux, andriod(暂未支持),iOS（暂未支持) 支持硬件 X86, ARM, GPU, Ascend, ... 图可视化 编排开发可视化图，子图 性能调测 性能跟踪 图能力 支持条件分支，循环分支，splice，reduce等图能力 分布式 支持分布式图处理，分布式动态调整业务执行 一次开发，多处运行 PYTHON功能单元，C++功能单元，java功能单元（暂未支持) 完善的功能单元 包含了大部分高性能的基础功能单元，包括http，视频，图像，云相关的功能单元 ModelBox解决的问题 目前AI应用开发时，训练完成模型后，需要将多个模型和应用逻辑串联在一起组成AI应用，并上线发布成为服务或应用。在整个过程中，需要面临复杂的应用编程问题： 问题 问题说明 需要开发AI应用的周边功能 比如AI应用编译工程，应用初始化，配置管理接口，日志管理口，应用故障监控等功能。 需要开发AI常见的前后处理 音视频加解码，图像转换处理，推理前处理，后处理YOLO等开发。 需要开发和云服务对接的周边功能 比如HTTP服务开发，云存储，大数据服务，视频采集服务对接开发。 需要开发出高性能的推理应用 需要基于多线程，内存池化，显存池化，多GPU加速卡，模batch，调用硬件卡的API等手段开发应用。 需要开发验证docker镜像 需要开发docker镜像，集成必要的ffmpeg，opencv软件，cudamindsopre，tensorflow等软件，并做集成测试验证。 多种AI业务，需要共享代码，降低维护工作 需要复用不同组件的代码，包括AI前后处理代码AI应用管理代码。底层内存，线程管理代码等。 模型开发者，验证模型功能比较复杂 模型开发者完成模型后，需要写python代码验证，转成产业务后，高性能，高可靠场景需要改造转换对应代码。 ModelBox的目标是解决AI开发者在开发AI应用时的编程复杂度，降低AI应用的开发难度，将复杂的数据处理，并发互斥，多设备协同，组件复用，数据通信，交由ModelBox处理。开发者主要聚焦业务逻辑本身，而不是软件细节。 在提高AI推理开发的效率同时，保证软件的性能，可靠性，安全性等属性。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"use-modelbox/use-modelbox.html":{"url":"use-modelbox/use-modelbox.html","title":"如何使用ModelBox","keywords":"","body":"如何使用ModelBox ModelBox的使用和其他服务类软件类似。流程上也是安装运行环境，配置服务，开发业务，调试优化，部署运行，维护定位。 ModelBox采用编排方式开发业务，这点和主流软件有一点不同。所以在开发前，需要对ModelBox的一些概念做了解。 ModelBox必知概念 如图所示，开发者在使用ModelBox前，需要关注的基本核心概念包括：功能单元、流程图和接收数据处理请求的部分（REST API、Service）。 流程图：ModelBox中用流程图(Graph)来表达应用逻辑。采用有向图的方式，将应用的执行逻辑表达为顶点和边，其中顶点表示了应用的某个数据处理逻辑单元，边则表示了逻辑单元之间的数据传递关系。在ModelBox中，针对流程图的开发，既可以使用文本方式直接编辑，也可以使用可视化的编辑器进行编辑。对于流程图的表述，ModelBox默认采用Graphviz进行解释，即图的表述需要满足Graphviz的语法要求。 功能单元：ModelBox将流程图中的顶点称为功能单元(FlowUnit)。功能单元是应用的基本组成部分，也是ModelBox的执行单元。在ModelBox中，内置了大量的基础功能单元，开发者可以将这些功能单元直接集成到应用流程图中，这也是基于流程图开发的一大好处。除内置功能单元外，ModelBox支持功能单元的自定义开发，支持的功能单元形式多样，如C/C++动态库、Python脚本、模型+Toml配置文件等。 接收数据处理请求：应用流程图构建完毕后，需要数据处理请求才能触发应用运行。ModelBox提供两种数据处理请求接收的方式：在flowunit中，通过在加载时调用API产生数据处理的请求，因为产生的请求是固定的，所以一般用于调试场景；标准使用方式是使用ModelBox提供的服务插件机制，在插件中接收外部请求，并调用任务相关的API来完成数据处理的请求。ModelBox提供了默认的服务插件可用于参考。数据处理请求的创建请详见数据流。 ModelBox：在应用构建完成后，结合ModelBox的框架才能形成完整可运行的应用。ModelBox作为应用入口，首先进行功能单元的扫描加载、应用流程图读取构建，然后接收数据处理请求，数据触发ModelBox中的执行引擎对功能单元进行调度，最终完成请求的数据处理任务。 更多概念更详细的概念可以阅读基本概念章节的内容。 ModelBox使用流程 ModelBox的开发使用流程指导，开发者可以在这里全局了解开发的过程。 1. 环境准备： 准备ModelBox运行或编译环境。下述两个步骤二选一即可，优先推荐使用已有镜像。 步骤 说明 指导链接 使用已经有镜像 ModelBox提供了多种推理Docker镜像，可以直接使用这些docker镜像来开发。 链接 源码构建ModelBox 在无可用镜像或参与ModelBox框架代码开发时，可以从源码构建ModelBox。 链接 2. 配置服务： ModelBox服务有两种工作模式，一种是生产使用的服务模式，一种是开发模式。 步骤 说明 指导链接 服务模式，运行ModelBox生产模式 用于生产环境运行AI流程图，ModelBox环境准备好后，默认情况下会启动ModelBox服务进程，生产环境中使用该模式。 链接 开发者模式，运行ModelBox开发模式 用于开发流程图时，可视化编排ModelBox流程图，提供了开发所需要的编排界面，开发环境下使用，同时也提供了体验内置推理方案的界面。 链接 3. 推理业务开发： ModelBox的软件架构采用了分层，插件架构。开发者可以按照自己的诉求开发AI推理业务，或扩展ModelBox功能。开发上，可分为流程图开发，功能单元开发，服务插件开发和SDK集成ModelBox开发。 开发内容 说明 指导链接 解决方案体验 ModelBox内置了一些可用的解决方案和样例工程，开发者在开发业务之前，可以体验这些方案，以便更加了解ModelBox开发。此步骤非必须。 链接 流程图开发 开发ModelBox运行的推理流程图，每个ModelBox推理业务都有一个流程图对应，所以需要先开发流程图。 链接 功能单元开发 在完成了流程图编排之后，还需通过功能单元(FlowUnit)来实现应用的实际功能。 链接 服务插件开发 此功能主要用于服务模式下，扩展ModelBox管理接口，比如需要扩展ModelBox任务管理，统计等你功能 链接 SDK模式使用ModelBox 在已有进程中扩展推理业务，可以直接将上述步骤完成的AI推理功能，扩展到已有的进程中。提供了C++，Python接口，如果是新业务，推荐使用服务模式，避免从main函数开始。 链接 4. 调试优化： ModelBox的推理业务开发过程中，需要对开发的代码进行调试。ModelBox提供了相关的调试能力 调试能力 说明 指导链接 modelbox-tool ModelBox运维调试工具，快速运行流程图，调整ModelBox服务日志，输出内存占用性能，模型加解密等功能 链接 流程图性能调试 通过甘特图，输出流程图中每个节点的耗时时间，供优化功能单元，或队列，batchsize等使用。 链接 代码调试 功能单元有BUG的情况下，如何使用log，gdb，pdb，ide调试代码。 链接 5. 服务运行： ModelBox开发完成后，需要部署到生产环境中运行，对应的需要对镜像，ModelBox软件，AI业务流程图进行配置。 步骤 说明 指导链接 运行已有的流程图 将开发完成后的流程图，部署到生产环境中运行。 链接 发送REST-API请求 运行好流程图后，可以通过REST-API发送请求给ModelBox服务执行。 链接 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/first-app/first-app.html":{"url":"develop/first-app/first-app.html","title":"第一个应用","keywords":"","body":"第一个应用 环境准备 环境准备可以使用现成ModleBox镜像，也可以从源代码构建ModelBox。本章节使用现成ModelBox镜像开发，如果没有相关的镜像，可以参考编译安装 Docker开发镜像 安装启动docker后，执行下列命令下载docker镜像 docker pull modelbox/modelbox-develop-tensorflow_2.6.0-cuda_11.2-openeuler-x86_64 配置并启动容器 可采用一键式脚本快速进入容器。参考一键式脚本相关内容。 进入容器并且切换至ModelBox开发者模式 注意事项： 如果需要通过可视化UI进行图的编排，可参考可视化编排服务章节访问http://[host]:[EDITOR_MAP_PORT]/editor/地址； 如果访问被拒绝，可参考运行编排服务中的访问控制列表相关内容 第一个应用开发-mnist识别 开发环境准备好了之后进入应用开发环节，这里以MNIST为例介绍整个应用开发过程。首先介绍MNIST应用实现的功能，然后介绍流程图编排、功能单元编写、运行与调试3个开发步骤。 MNIST案例是使用MNIST数据集，训练的一个手写数字识别tensorflow模型，搭建的一个简易的http请求服务。模型训练可参考tensorflow教程 。 功能 将MNIST数据，通过base格式发送到ModelBox推理，并获取结果。 流程上：ModelBox Server监听端口接收http请求，然后从请求体中的base64解析出图片，接着用训练出的MNIST模型进行推理，最后将识别出的数字返回给用户。 Request 请求样例： { \"image_base64\": \"xxxxx\" } Response 响应样例： { \"predict_reuslt\": \"x\" } 模型准备 AI应用开发前需要准备好匹配当前modelbox版本支持的推理框架和版本的模型文件，这里默认已经准备好了tensorflow1.13版本的minist pb模型文件，路径如下：/opt/modelbox/solution/model/mnist_model.pb 流程图开发 流程图编排是根据实际情况将现有业务逻辑拆分为N个功能单元，再将功能单元串联成一个完整的业务的过程。功能单元分为ModelBox预置功能单元和用户自定义功能单元，当预置功能单元满足不了业务场景时，需要用户进行功能单元开发。有两种方式可编排流程图，第一种是使用UI进行可视化UI编排，第二种是直接编写图文件。具体可参考流程图开发章节。这里采用第二种方式。 如上图所示，根据业务流程可以将业务划分为5个功能单元，分别为接收http请求，MNIST预处理，MNIST模型推理，MNIST响应构造，发送http响应。对应图编排文件描述如下 [graph] format = \"graphviz\" graphconf = '''digraph mnist_sample { queue_size=32 batch_size=1 node [shape=Mrecord] httpserver_sync_receive[type=flowunit, flowunit=httpserver_sync_receive, device=cpu, deviceid=0, time_out_ms=5000, endpoint=\"https://127.0.0.1:8080\", max_requests=100] mnist_preprocess[type=flowunit, flowunit=mnist_preprocess, device=cpu, deviceid=0] mnist_infer[type=flowunit, flowunit=mnist_infer, device=cuda, deviceid=0] mnist_response[type=flowunit, flowunit=mnist_response, device=cpu, deviceid=0] httpserver_sync_reply[type=flowunit, flowunit=httpserver_sync_reply, device=cpu, deviceid=0] httpserver_sync_receive:out_request_info -> mnist_preprocess:In_1 mnist_preprocess:Out_1 -> mnist_infer:Input mnist_infer:Output -> mnist_response:In_1 mnist_response:Out_1 -> httpserver_sync_reply:in_reply_info } 除了构建图之外，还需要增加必要配置，如功能单元扫描路径，日志级别等，具体可参考样例文件/usr/local/share/modelbox/solution/graphs/mnist_detection/mnist.toml。 功能单元开发 ModelBox提供基础预置功能单元，除此之外还需补充流程图中缺失的功能单元，具体开发可参考功能单元开发章节。 这里接收http请求、发送http响应两个功能单元ModelBox已提供，我们只需实现MNIST的预处理，推理，响应构造三个功能单元即可。 MNIST预处理功能单元 预处理需要做：解析出图片，对图片进行reshape，构建功能单元输出buffer。 in_data = data_context.input(\"In_1\") out_data = data_context.output(\"Out_1\") for buffer in in_data: # get image from request body request_body = json.loads(buffer.as_object().strip(chr(0))) img_base64 = request_body[\"image_base64\"] img_file = base64.b64decode(img_base64) # reshape img img = cv2.imdecode(np.fromstring(img_file, np.uint8), cv2. IMREAD_GRAYSCALE) img = cv2.resize(img, (28, 28)) infer_data = np.array([255 - img], dtype=np.float32) infer_data = np.reshape(infer_data, (784,)) / 255. # build buffer add_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) out_data.push_back(add_buffer) 详细代码可参考/usr/local/share/modelbox/solution/flowunit/mnist/mnist_preprocess。 MNIST推理功能单元 推理功能单元只需准备好模型和对应的配置文件即可。 配置文件如下： [base] name = \"mnist_infer\" device = \"cuda\" version = \"1.0.0\" description = \"Recognition handwritten digits recognition. The sample mnist_model.pb requires tensorflow1.13 \" entry = \"path_to_mnist_model.pb\" type = \"inference\" virtual_type = \"tensorflow\" [input] [input.input1] device = \"cpu\" name = \"Input\" type = \"float\" [output] [output.output1] name = \"Output\" type = \"float\" 详细代码可参考/usr/local/share/modelbox/solution/flowunit/mnist/mnist_infer。 MNIST响应功能单元 得到推理的结果之后，需要构造响应： in_data = data_context.input(\"In_1\") out_data = data_context.output(\"Out_1\") for buffer in in_data: # get result max_index = np.argmax(buffer.as_object()) # build response result = { \"predict_reuslt\": str(max_index) } result_str = (json.dumps(result) + chr(0)).encode('utf-8').strip() add_buffer = modelbox.Buffer(self.get_bind_device(), result_str) out_data.push_back(add_buffer) 详细代码可参考/usr/local/share/modelbox/solution/flowunit/mnist/mnist_response。 调试运行 首先需要把http服务运行起来，然后再模拟请求测试。 运行流程图 执行如下命令即可启动MNIST识别http服务： modelbox-tool -log-level info flow -run path_to_mnist.toml 由于ModelBox库已集成样例，可直接运行modelbox-tool -log-level info flow -run /usr/local/share/modelbox/solution/graphs/mnist_detection/mnist.toml。 测试 可以使用已经准备好测试脚本/usr/local/share/modelbox/solution/graphs/mnist_detection/test_mnist.py，测试图片是mnist测试集中的0数字。 直接运行python3 test_mnist.py得到结果为： { \"predict_reuslt\": \"0\" } ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"server/summary.html":{"url":"server/summary.html","title":"ModelBox服务运行","keywords":"","body":"目录 服务使用流程 可视化编排服务 服务配置安装 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"server/server.html":{"url":"server/server.html","title":"服务使用流程","keywords":"","body":"Server服务 通常情况下，ModelBox可以看作是一个应用服务。当需要运行ModelBox时，需要启动ModelBox Server服务。ModelBox Server是最基本也是最重要的服务,ModelBox Server服务提供流程图的加载、可视化编排UI服务、流程图Restful API等能力。用户只需将flow流程图配置文件放到指定的目录下，即可实现flow作为服务的功能。 Server服务使用流程 在ModelBox镜像中，Server服务是预编译好的可执行文件，在使用时，按照正常的服务流程使用，其流程为： 安装服务。 启动服务。 修改服务配置文件。 重启服务使配置生效。 添加流程图。 管理扩展插件。 启动管理服务 ModelBox Server服务使用标准的systemd unit管理，启动管理服务，使用systemd命令管理。 当运行环境支持Systemd时，可通过如下命令对ModelBox服务进行操作： sudo systemctl status modelbox.service：查看ModelBox服务的状态。 sudo systemctl stop modelbox.service：停止ModelBox服务。 sudo systemctl start modelbox.service：启动ModelBox服务。 sudo systemctl restart modelbox.service：重启ModelBox服务。 如无systemd管理机制时，可以使用SysvInit命令管理ModelBox服务，命令如下： sudo /etc/init.d/modelbox [start|status|stop] 此方式相比systemd，缺失了进程的监控，所以建议优先使用systemd启动ModelBox服务。 ModelBox Server服务配置 ModelBox Serverf服务配置文件中包含主服务配置、插件、服务启动参数、编排服务配置和访问控制列表。 一个典型modelbox.conf配置文件如下图所示： [server] ip = \"127.0.0.1\" port = \"1104\" flow_path = \"/usr/local/etc/modelbox/graph/\" [acl] allow = [ \"127.0.0.1/8\" ] [control] enable = true listen = \"/var/run/modelbox/modelbox.sock\" [plugin] files = [ \"/usr/local/lib/modelbox-plugin.so\", \"/usr/local/lib/modelbox-plugin-editor.so\" ] [editor] enable = false root = \"/usr/local/share/modelbox/www\" solution_graphs = \"/usr/local/share/modelbox/solution/graphs\" [log] level = \"INFO\" num = 32 path = \"/var/log/modelbox/modelbox.log\" [include] files = [ \"/usr/local/etc/modelbox/conf.d/*.conf\", ] ModelBox服务相关配置文件和配置功能说明如下： 配置类别 配置文件 说明 主服务配置 /usr/local/etc/modelbox/modelbox.conf 包含基本的配置信息，如插件路径，日志级别。 插件配置 /usr/local/etc/modelbox/modelbox.conf 和具体插件相关。 编排服务配置 /usr/local/etc/modelbox/modelbox.conf 包括编排服务的配置信息，详情可见运行服务中的可视化编排服务 访问控制列表 /usr/local/etc/modelbox/modelbox.conf 可访问ModelBox后端服务的白名单列表，详情可见运行服务中的访问控制列表 服务启动参数配置 /usr/local/etc/modelbox/modelbox-opts 支持配置ModelBox Server服务的启动参数。 主服务配置项 主服务配置主要配置插件列表，日志级别信息，具体配置项如下： 配置项 配置功能 plugin.files ModelBox Server插件列表，顺序加载。 log.level ModelBox服务日志级别，默认为INFO，支持DEBUG, INFO, NOTICE, WARN, ERROR, FATAL, OFF，如果指定OFF，将关闭日志打印。 log.num ModelBox服务日志归档文件个数最大值，默认为32，当归档日志超过该阈值时，最旧归档日志文件将删除。 log.path ModelBox服务日志文件路径，默认为/var/log/modelbox/modelbox.log。如果修改该配置项，需要保证日志目录存在且具有可读写权限。 include.files ModelBox服务配置的子配置路径，当子配置存在字段和主配置相同时，取子配置的值。 插件服务配置 除上述配置外，其他配置均为插件配置。ModelBox服务支持灵活的ModelBox服务插件加载，ModelBox启动后，会按照plugin.files配置的插件，顺序加载插件，各插件的配置参考各自插件配置参数。当前ModelBox的可视化编排及流程图的restful api及通过服务插件实现, 每个插件有各自配置字段： modelbox-plugin插件的配置，可参考服务安装配置。 modelbox-plugin-editor插件的配置，可参考可视化编排服务。 ModelBox服务启动参数配置 ModelBox Server服务启动参数配置项目如下： 配置项 配置功能 MODELBOX_OPTS ModelBox服务启动时会加载该变量的内容作为启动参数。如果用户需要重新指定其他的ModelBox服务运行配置时，可修改该变量的值实现。 ModelBox Server预置功能列表 ModelBox Server可以通过自定义插件的形式扩展其基本功能，默认情况下，ModelBox Server集成了任务管理REST API服务，以及流程图的执行能力, ModelBox集成的插件列表。 插件 功能 说明 使用指导 modelbox-plugin 默认流程图执行插件 默认的流程图执行插件，支持REST API管理流程图，和其执行结果。 指导 modelbox-plugin-editor 可视化编排UI插件 提供可视化的流程图编排UI界面。 指导 ModelBox Server文件目录 ModelBox Server安装完成后，对应的安装目录如下 文件路径 说明 /usr/local/bin/modelbox ModelBox独立服务器主进程。 /usr/local/etc/modelbox ModelBox配置目录。 /usr/local/etc/modelbox/modelbox.conf ModelBox主程序配置文件。 /usr/local/etc/modelbox/modelbox-opts ModelBox主程序启动参数配置文件。 /usr/local/etc/modelbox/graph ModelBox执行程序图存储目录。 /lib/systemd/modelbox.systemd ModelBox服务启动systemd unit。 /usr/local/lib/libmodelbox-*.so libmodelbox，以及相关插件目录。 ModelBox Server运行日志 ModelBox Server运行时的日志会记录到modelbox.conf配置文件log.path配置指定的文件中。默认路径为[/var/log/modelbox/modelbox.log] ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"server/editor.html":{"url":"server/editor.html","title":"可视化编排服务","keywords":"","body":"可视化编排服务 ModelBox提供了在线可视化编排的工具——Editor，在开发时，可使用此工具，提升开发效率。 编排服务是什么 编排服务是用来在Editor可视化界面上，编排流程图并自动生成相对应的图代码的快速开发工具。 编排服务开发使用流程 安装ModelBox server服务。 配置ModelBox Server。 配置启用编排服务。 浏览器访问Editor界面。 业务进行编排操作。 下发编排任务。 编排服务集成在ModelBox Server中，默认情况下，编排服务未启用。可以参考下方编排服务配置章节来启用编排服务并加载Editor界面。 编排服务配置 ModelBox Server安装完成后，编排服务会通过插件的形式由ModelBox Server加载，并在网页浏览器上提供在线可视化编排服务。 对应插件路径为\"/usr/local/lib/modelbox-plugin-editor.so\"(#由于不同操作系统目录结构存在差异，此路径也可能为 \"/usr/local/lib64/modelbox-plugin-editor.so\"，下文涉及系统lib库路径的地方均存在系统路径差异)。 编排服务插件的配置文件路径为/usr/local/etc/modelbox/modelbox.conf，其配置项目如下： 配置项目 配置说明 editor.enable 是否启用Editor工具 editor.ip Editor工具监听IP，默认为127.0.0.1。不指定的情况下，和server.ip一致 editor.port Editor工具监听端口，默认为1104，不指定情况下，和server.port一致 editor.root Editor前端UI路径，默认为/usr/local/share/modelbox/www editor.solution_graphs Editor solution_graphs路径，默认为/usr/local/share/modelbox/solution/graphs 下面分别介绍两种启用Editor的方法。 命令行启用Editor 通过如下命令，可开启基于Web的可视化编辑工具——Editor。 modelbox-tool develop -e 命令执行后，将开启http服务，可使用对应主机的IP地址，和开启的端口号（默认端口号为1104），在配置ACL生效之后，即可访问Editor界面。 配置启用Editor 若需要定制化编排服务启动参数，可以修改配置文件，具体修改流程如下： 打开/usr/local/etc/modelbox/modelbox.conf，修改其中的配置项： [server] # 允许访问服务 ip = \"0.0.0.0\" port = \"1104\" flow_path = \"/usr/local/etc/modelbox/graph\" [plugin] # 确保Editor组件加载。 files = [ \"/usr/local/lib/modelbox-plugin-editor.so\" # ] [editor] # 启用Editor enable = true # 设置绑定IP和端口。 ip = \"0.0.0.0\" port = \"1104\" # 指定前端UI路径，默认情况无需修改。 root = \"/usr/local/share/modelbox/www\" solution_graphs = \"/usr/local/share/modelbox/solution/graphs\" 重启ModelBox Server服务使配置生效。 systemd环境： systemctl restart modelbox 非Systemd环境： /etc/init.d/modelbox restart 访问编排服务 服务启动成功后，可使用浏览器访问服务，输入对应的网址即可，如：http://[host]:1104/editor/，成功后，将显示如下界面： UI界面分为7个功能区域，其对应的功能如下： 区域1，功能页面选择。 区域2，基本编排操作区域，包含对6号区域的放大，缩小，重置大小，居中显示等操作。 区域3，基础组件列表区域，安装不同的组件分类，可从此面板选择对应编排的组件。组件数量受图的FlowUnit路径和服务器中功能单元插件个数的影响。 区域4，帮助和API页面的链接。 区域5，图操作功能区，包含新建，保持，图属性，选择图表，和解决方案功能。 区域6，图形化编排界面，使用鼠标可以控制组件链接和移动。Ctrl+鼠标左键可以拖动画布。 区域7，对应文本化编排界面，可使用标准的DOT语法进行文本编辑。 快捷键说明： 放大缩小：鼠标滚轮，或键盘，-，=按键。 全选：ctrl+a 撤销：ctrl+z 重做：ctrl+u 取消选择：escape 注意事项： 对应网址的端口号以docker启动脚本中的 EDITOR_MAP_PORT 为准，默认端口号为1104。 区域3中若无显示任务组件，请确保图设置界面中，选中了使用系统功能单元，和正确指定功能单元路径。 编排完成后，需要点击另存为保存图，然后才能在任务管理界面下发任务。 执行编排任务 编排完成，并保存完编排图后，可在编排管理界面下发编排任务，对应的编排任务管理界面如下： 任务界面分为4个功能区域，其对应的功能如下： 区域1，新建任务按钮，用于新建编排页面创建的图。 区域2，服务器端执行的任务列表。 区域3，任务执行状态。 区域4，任务执行出错情况下的错误信息。 访问控制列表 访问控制列表ACL（Access Control List）是由一条或多条规则组成的集合，里面配置了允许访问Editor的IP地址。 可以通过修改配置文件，来修改ACL列表，具体流程如下： 打开/usr/local/etc/modelbox/modelbox.conf，修改其中的配置项： 假设打开编排UI的机器的IP地址为10.11.12.13 [acl] allow = [ \"10.11.12.13\", ] [plugin] files = [ \"/usr/local/lib/modelbox-plugin.so\", \"/usr/local/lib/modelbox-plugin-editor.so\" ] 如果没有配置任何访问白名单，则允许所有人皆可访问。 # [acl] # allow = [ # \"10.11.12.13\", # ] 重启ModelBox Server服务使配置生效。 systemctl restart modelbox 注意：1. 确保[editor]下enable = true。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"server/run-flow.html":{"url":"server/run-flow.html","title":"服务配置安装","keywords":"","body":"服务安装配置 ModelBox Server提供了如下方式加载运行流程图： 通过默认ModelBox Plugin插件自动加载 通过图形化UI运行流程图 通过Restful API运行流程图 ModelBox Plugin插件 ModelBox Plugin插件用于对外提供服务，管理并运行流程图。此插件内置在ModelBox Server中。 默认情况下，可以直接使用此插件执行相关的流程图功能。例如，新建任务后，将使用插件运行流程图，并将结果对外输出。 ModelBox Plugin功能说明： ModelBox Plugin主要提供两个功能。 添加配置文件管理流程图。 调用REST API执行流程图。 ModelBox Plugin插件配置 ModelBox Plugin插件配置文件和ModelBox Server主配置文件相同，即为/usr/local/etc/modelbox/modelbox.conf, ModelBox Plugin插件的配置项目如下： 配置项目 配置说明 server.ip ModelBox Plugin绑定的管理IP地址，默认为127.0.0.1 server.port ModelBox Plugin绑定的管理端口，默认为1104 server.flow_path ModelBox Plugin加载flow配置文件的扫描路径。默认为/usr/local/etc/modelbox/graph 为确保ModelBox Plugin插件生效，请确保插件在/usr/local/etc/modelbox/modelbox.conf配置文件的plugin.files配置项中配置此插件，并在配置完成后，重启ModelBox服务。 添加配置文件管理流程图 ModelBox Plugin支持通过添加流程图配置文件的形式自动执行流程图，默认情况下的流程图配置文件路径为/usr/local/etc/modelbox/graph, 配置文件的存放目录为： /usr/local/etc/modelbox/graph |-some-flow1.toml |-some-flow2.toml . . . 配置文件复制到图存储目录后，可执行ModelBox Server服务重启命令systemctl restart modelbox生效. 注意： ModelBox服务加载该目录下的所有文件作为flow作业，如果加载失败将跳过该flow，文件名将作为flow的作业名 文件名不要包含特殊符号，并且后缀名为.toml。 如果修改该配置项，需要保证指定的目录存在并具有读权限，否则将加载失败。 路径可通过server.flow_path参数修改。 图形化运行流程图 请参考可视化编排服务。 REST API管理执行流程图 请参考REST API。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/summary.html":{"url":"develop/summary.html","title":"应用开发与调试","keywords":"","body":"目录 AI应用开发流程 流程图开发 功能单元开发 服务插件开发 SDK API集成 ModelBox Tool 调试定位 性能优化 设备接口 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/develop.html":{"url":"develop/develop.html","title":"AI应用开发流程","keywords":"","body":"应用开发与调试 本章节开始，将开始介绍如何使用ModelBox进行应用的开发。ModelBox在设计中以易扩展为目标，在框架多个位置增加了扩展的能力，提供多种编程的模式，以及多语言的支持，以更加灵活的满足应用的实现。 ModelBox的扩展能力如下： ModelBox服务插件扩展。 ModelBox组件可任意集成。 推理加速设备支持扩展。 功能单元的扩展及复用。 C++，Python等多语言的开发支持。 针对这些扩展能力，ModelBox提供了开发套件，开发者可以根据自身业务场景利用ModelBox提供的开发接口进行灵活扩展。 ModelBox开发套件 ModelBox的开发视图如下，图中绿色的部分是开发者可以自定义扩展的部分。 ModelBox开发套件包含如下部分： 流程图 Flow 控制ModelBox执行的过程，默认情况，采用Graphviz DOT语言进行流程图设计，开发。 ModelBox Server 为简化服务化应用开发者的工作量，ModelBox集成了服务功能，ModelBox Server有完善的服务集成功能，REST-API功能，任务管理功能，并集成了ModelBox library，对应用开发者提供了插件扩展的接口，应用开发者只需编写业务需要的服务插件，即可驱动ModelBox和业务控制服务对接。 自定义应用 与ModelBox Server对应，如果业务需要更多的定制能力，业务可以直接使用ModelBox SDK提供的接口来驱动ModelBox，支持的语言有C++，Python，Java等。 ModelBox SDK ModelBox应用提供的开发API，包含了C++, Python，Java等多种语言的支持。开发者可以使用自己熟悉的语言进行集成或扩展。 ModelBox Tool ModelBox 开发调试工具，可用于检查图的正确性，调试单个图，查询可用的功能单元Flowunit，模型加密等功能。 ModelBox Library ModelBox核心库，包含了ModelBox运行需要的功能，包含内存管理，调度管理，图管理等功能。此核心组件不可定制，开发者直接通过API使用ModelBox核心库功能。 ModelBox Flowunit 功能单元，ModelBox的关键组成，处理数据的关键组件，也是开发者主要开发的组件。 ModelBox Device 设备支持组件，用于支持特定的硬件，如GPU，Ascend芯片等，ModelBox已经内置了主流的GPU，Ascend芯片开发支持。开发者只需要开发相应的功能即可。 AI应用开发典型场景 基本AI应用开发场景 对于基本AI应用开发场景，开发者需要进行流程图开发和功能单元开发：流程图开发需要将业务流程通过功能单元编排的方式组织ModelBox可以识别的配置文件，功能单元开发则是需要实现业务的基础功能。 与外部系统存在交互 对于外部系统存在交互的场景需要当进行Server Plugin服务插件开发，典型场景如：视频场景分析任务的输入源信息往往是从外部系统下发，需要有一个Server与外部系统进行对接，然后转换为Modeblox分析任务。 硬件扩展 当应用需要支持的运行环境含有ModelBox未支持的硬件设备时，则开发者需要扩展开发ModelBox Device推理加速设备支持模块。 系统集成 通常基于Modelbox的AI应用作为独立进程运行，当AI应用需要作为组件被集成到其他系统进程中时，可以直接使用libmodelbox组件提供的ModelBox SDK API进行集成开发，完成应用的集成, Modelbox同时提供了C++ SDK接口和Python SDK接口。 AI应用开发流程 通常情况，可以按照如下流程进行应用开发： 开发前准备 AI应用开发前需要准备好匹配当前ModelBox版本支持的推理框架和版本的模型文件，否则无法进行推理。如果是采用tensorRT框架，还需要注意模型转换时的显卡类型需要与运行时的显卡类型匹配。 创建工程 通过modelbox-tool创建AI应用工程，具体命令如下： modelbox-tool create -t project -n [ProjectName] -d ./ 默认工程目录结构如下： [ProjectName] |---Cmake //cmake脚本 |---package //打包脚本 |---src |---flowunit //存放功能单元代码 ---flowunitA ---flowunitB |---graph //存放图配置 ---graph.toml |---service-plugin //存放服务插件代码 ---pluginA ---pluginB |---CMakeLists.txt |---test //测试框架及用例 |---thirdparty //存放第三方库 |---CMakeLists.txt 流程图开发 梳理实际业务逻辑，设计拆分为多个功能单元，再编排为图。具体开发流程可见流程图开发。 修改图toml文件其他系统配置项，重点关注driver.dir路径是否正确。 功能单元开发 通过modelbox-tool创建对应语言的功能单元模板，具体命令如下： modelbox-tool create -t c++ -n [name] -d ./ProjectName/src/flowunit modelbox-tool create -t python -n [name] -d ./ProjectName/src/flowunit modelbox-tool create -t infer -n [name] -d ./ProjectName/src/flowunit 命令执行后会生成对应文件和函数，注意name不可携带数字、中划线等特殊字符，建议是全英文。 模板创建完成后进行接口函数实现，具体开发流程可见功能单元开发 服务插件开发 不涉及新增服务插件可跳过此步骤。 通过modelbox-tool创建对应语言的服务插件模板，具体命令如下： modelbox-tool create -t service-plugin -n [name] -d ./ProjectName/src/service-plugin 命令执行后会生成对应文件和函数，注意name不可携带数字、中划线等特殊字符，建议是全英文。 模板创建完成后进行接口函数实现，服务插件开发流程可见功能单元开发 功能调试 可以使用样例工程自带的测试框架进行功能单元和图的用例测试。也可以安装在到当前系统进行调试。编译安装过程如下： 在工程最上级目录执行如下命令进行编译安装： mkdir build cd build cmake ../ -DCMAKE_BUILD_TYPE=Debug make install 功能单元so、服务插件so、python、模型文件、图配置等都会安装到Cmakelist中指定的路径（默认安装在 /opt/modelbox/目录下）。也可以通过 make package 进行打RPM包。 安装完成后可以通过modelbox-tool 在环境上运行图文件进行调试。命令如下： modelbox-tool -verbose [-log-level INFO] [-log-path filepath] flow -run [/path/to/graph.toml] 具体可见调试。 性能调优 可以使用profiling工具对性能数据进行采集分析和优化，具体使用可见性能。 系统集成 通常情况使用ModelBox服务运行图即可。如果有诉求需要将ModelBox图的运行集成到其他进程时，可采用ModelBox提供的sdk接口进行调用。具体可见SDK API集成。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/flow/flow.html":{"url":"develop/flow/flow.html","title":"流程图开发","keywords":"","body":"流程图开发及运行 流程图(Graph)是应用的逻辑表述，ModelBox将根据流程图构建应用的处理逻辑。 因此在应用开发中，流程图的开发是首要进行的。流程图开发完毕后，才能明确需要开发的功能单元。 流程图开发模型 流程图的开发的四个步骤 graph LR A(图的创建) --> B(图的加载) --> C(图的构建) --> D(图的运行) 图的创建： 也叫图的定义，是开发者根据实际的业务需求，按照流程图的开发规范创建的流程图。流程图中标识了功能单元的名称、配置以及数据流向。 图的加载： 用户通过调用ModelBox的函数将图文件或者存储图的内存块加载到ModelBox中， ModelBox会根据配置解析出代码可识别的模型，如果图的配置有问题也会在此时发现并通过返回值获取。此时ModelBox会根据配置中的flowunit以及device去查询当前已加载的驱动库是否有匹配的driver，只有当所有的driver都能正确查询到时，才能正确加载图。 图的构建： 当用户调用对应的ModelBox函数接口时， ModelBox会将解析完毕的图模型转换为各个Node对象，并且创建好数据流通道。 此时所有的node都已经准备好，等有数据到来时既可以直接处理数据。 图的运行： 当用户调用函数接口时， ModelBox会从用户配置的数据源读取数据并按照图构建的路径处理数据，并输出到用户指定的路径中。此时node从前面的节点中获取数据并调用flowunit的处理函数处理数据，并将处理后的数据输出到下一个node中，此时所有的node节点都已经运行起来了，直到数据结束或者用户手动终结流程。 流程图开发 流程图配置 一个流程图使用一份TOML格式的配置表示，配置文件内容如下： [log] level=\"DEBUG\" [driver] dir=[\"dir1\",\"dir2\"] skip-default=false [graph] graphconf = '''digraph demo { input[type=input] output[type=output] process[flowunit=process] input->process->output }''' graph.graphconffilepath = \"/path/to/graphviz/flow.conf\" format = \"graphviz\" 配置文件项目说明： [driver]：用于说明驱动加载路径。 dir: 指定功能单元等驱动加载路径，可以指定多个路径，通过[] 和 ，分隔。 skip-default：true表示只扫描dir路径，false表示扫描系统目录和dir路径。 [graph]：用于指定图的内容。 format指定流程图的格式，目前仅支持graphviz。 graphconf为内联graphviz流程图。 graph.graphconffilepath为外部流程图文件。 [log]: 指定图的日志级别。 level: 指定级别，可以是DEBUG, INFO, NOTICE, WARN, ERROR, FATAL, OFF 注意：修改此级别，将全局影响日志级别，建议仅在调试时使用。 流程图定义 ModelBox默认情况，采用Graphviz DOT语法表达图，关于DOT语法，可以查看Graphviz DOT的指导。 假设有一个简单的业务例子如下图： ModelBox启动http server监听80端口 当有请求时，调用PROCESS功能处理数据 数据处理完成后，再将结果回应到客户端 Graphviz的表达： digraph G { node[shape=Mrecord] // 定义点属性 HTTP_REQUEST[flowunit=http, listen=\"127.0.0.1:8080\", label=\"{% raw %}{HTTP REQUEST|{OUT}}{% endraw %}\"] PROCESS[flowunit=json, label=\"{% raw %}{{IN}|PROCESS|{OUT}}{% endraw %}\"] HTTP_RESPONSE[flowunit=http, label=\"{% raw %}{{IN}|HTTP RESPONSE}{% endraw %}\"] // 定义点关系 HTTP_REQUEST:OUT->PROCESS:IN PROCESS:OUT->HTTP_RESPONSE:IN } 完成上述图构成后，即可将上述图，组成ModelBox可识别的配置文件。ModelBox可识别的配置文件采用TOML配置格式。生成TOML文件后，即可将配置文件加载到ModelBox中执行。 [graph] graphconf = ''' digraph G { node[shape=Mrecord] // 定义点属性 HTTP_REQUEST[flowunit=http, listen=\"127.0.0.1:8080\", label=\"{% raw %}{HTTP REQUEST|{OUT}}{% endraw %}\"] PROCESS[flowunit=json, label=\"{% raw %}{{IN}|PROCESS|{OUT}}{% endraw %}\"] HTTP_RESPONSE[flowunit=http, label=\"{% raw %}{{IN}|HTTP RESPONSE}{% endraw %}\"] // 定义点关系 HTTP_REQUEST:OUT->PROCESS:IN PROCESS:OUT->HTTP_RESPONSE:IN } ''' format = \"graphviz\" 关键字说明 下面图的配置，包含三部分。 // 1. 图 digraph G { node[shape=Mrecord] // 2. 定义点属性 HTTP_REQUEST[flowunit=http, listen=\"127.0.0.1:8080\", label=\"{% raw %}{HTTP REQUEST|{OUT}}{% endraw %}\"] PROCESS[flowunit=json, label=\"{% raw %}{{IN}|PROCESS|{OUT}}{% endraw %}\"] HTTP_RESPONSE[flowunit=http, label=\"{% raw %}{{IN}|HTTP RESPONSE}{% endraw %}\"] // 3. 定义点关系 HTTP_REQUEST:OUT->PROCESS:IN PROCESS:OUT->HTTP_RESPONSE:IN } 第一部分是图 格式 digraph [name] 说明 digraph开头，[name]可以是字符串。 第二部分是点Node的定义 格式 name[key=value] 说明 name为点的名称，key为node的配置属性，每个节点不同，value为key的配置值。 type参数指定点node的类型，可以是input, output, flowunit 当未指定type参数时，node缺省为flowunit。 flowunit表示此点为功能单元功能模块，配合flowunit=xx指定，功能单元的执行实体。 node[type=\"flowunit\", flowunit=httpserver] 上述配置表示，点的名称为node，类型为flowunit，其执行实体为httpserver。 支持的Flowunit可以使用modelbox-tool工具查询。 input：表示此点的类型为输入端口，为整个图的配置，表示图的数据输入端口。 graphinput[type=input] 上述配置表示，图输入点的名称为graphinput，在使用SDK形式调用ModelBox时可以使用此名称发送数据给图。 output: 表示此点的类型为输出端口，为整个图的配置，表示图的数据输出端口。 graphoutput[type=output] 上述配置表示，图输出点的名称为graphoutput，在使用SDK形式调用ModelBox时可以使用此名称接收图处理后的数据。 第三部分是点的关系定义 格式 name:outport -> name:inport 说明 name为点的名称，outport为输出端口名称，inport为输入端口名称。 流程图开发方式 流程图开发时，可采用如下形式进行开发 方式 说明 推荐度 连接 ModelBox编排服务 使用ModelBox编排服务进行流程图的开发。 ⭐️⭐️⭐️ 指导 手工编写 手工编写toml格式的流程图文件，并添加到ModelBox Server插件中运行 ⭐️ 指导 流程图的运行 流程图完成后，可以采用下列形式运行流程图 方式 说明 特点 推荐度 连接 modelbox-server 使用ModelBox加载运行流程图 基本无需编程，只需要通过配置即可完成图的运行 ⭐️⭐️⭐️ 指导 modelbox-tool ModelBox Tool调试 调试图时使用的工具，方便，快速检查结果是否正确 ⭐️⭐️⭐️ 指导 Python SDK Python SDK形式 Python接口形式，方便开发者与当前python服务集成 ⭐️⭐️ 指导 C++ SDK C++ SDK形式 c++SDK形式，方便开发者与当前c/c++程序集成 ⭐️⭐️ 指导 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/flowunit/flowunit.html":{"url":"develop/flowunit/flowunit.html","title":"功能单元开发","keywords":"","body":"功能单元开发 在完成了流程图编排之后，还需通过功能单元(FlowUnit)来实现应用的实际功能。ModelBox加载功能单元后，根据图的结构，将实例化为图中的各个节点。功能单元需提供特定的接口，根据接口协议，在数据处理的各个阶段对接口进行调用。 有关功能单元的详细介绍，请先阅读基本概念章节，以及后续的功能单元、数据流章节内容。 本章节内容主要介绍功能单元的开发过程。 功能单元开发流程 可以通过modelbox-tool 创建功能单元模板工程 modelbox-tool create -t c++ -n xxx -d ./ 确定功能单元类型。 修改Example代码的编译，TOML，源代码名称，和设置功能单元的输入，输出，参数，以及运行设备信息。 根据需要实现FlowUnit的Open，DataPre，DataPost，Process，DataGroupPre，DataGroupPost，Close接口。 编译连接外部组件，调用外部功能组件接口。 编译安装包。 流程图中配置使用功能单元。 功能单元类型 在开发功能单元时，应该先明确开发功能单元处理数据的类型，业务的场景。再根据上述信息选择合适的功能单元类型。 具体功能单元类型，请查看功能单元的分类。在确认功能单元类型后，需要对功能单元进行如下参数的配置。 功能单元参数说明： 配置项 C++函数接口 Python配置接口 必填 c++参数类型 功能描述 功能单元名称 SetFlowUnitName base.name 是 String 功能单元名称 功能单元描述 SetDescription base.description 否 String 功能单元描述 功能单元组类型 SetFlowUnitGroupType -- 否 GroupType 功能单元分类 功能单元工作模式 SetFlowType base.stream 是 FlowType 功能单元工作模式，分为NORMAL 和STREAM 功能单元输入端口 AddFlowUnitInput input.* 是 FlowUnitInput 设置输入端口和数据存放设备 功能单元输出端口 AddFlowUnitOutput output.* 是 FlowUnitOutput 设置输出端口和数据存放设备 功能单元配置参数 AddFlowUnitOption config.* 是 FlowUnitOption 设置功能单元配置参数，包括参数名，类型，描述等信息 条件类型 SetConditionType baes.condition 否 ConditionType 是否为条件功能单元 输出类型 SetOutputType base.collapse/base.expand 否 FlowOutputType 设置是否为扩张或者合并功能单元 输入输出buffer数量是否相同 SetStreamSameCount -- 否 bool 仅STREAM类型功能单元可设置，标识是否允许输入buffer和输出buffer数量不一致 输入内存是否连续 SetInputContiguous -- 否 bool 是否要求输入内存是否是分配的连续空间 设置是否需要收齐buffer SetCollapseAll -- 否 bool 是否收集所有扩张的buffer。仅当收缩功能单元需设置，默认false 异常是否可见 SetExceptionVisible -- 否 bool 本功能单元是否处理前面功能单元的异常消息 是否为虚拟类型 SetVirtualType -- 否 bool 虚拟功能单元不可直接当作正常功能单元使用 设置资源调度策略 SetResourceNice -- 否 bool false是表示本功能单元优先抢占资源，默认true Driver名称 SetName -- 是 String driver描述 Driver功能类型 SetClass -- 是 String driver功能类型，功能单元类型为DRIVER-FLOWUNIT Driver设备类型 SetType base.device 是 String driver描述，cuda/cpu/ascend类型 Driver版本号 SetVersion base.version 是 String driver版本号 Driver描述 SetDescription base.description 是 String driver功能描述 Driver和功能单元的关系：Driver是ModelBox中各类插件的集合，功能单元属于Driver中的一种类型。在C++语言中，一个Driver对应一个so，一个Driver可以支持多个功能单元，即将多个功能单元编译进一个so文件。而再python中，Driver和功能单元一一对应。 根据业务类型，常用功能单元的可以分为以下几类： 功能单元类型 配置参数 适用场景 通用功能单元 工作模式设置为NORMAL 图像操作，如resize 条件功能单元 工作模式设置为NORMAL，并且条件类型设置为IF_ELSE 业务逻辑的分支判断 流数据功能单元 工作模式设置为STREAM 视频流的处理，可以感知任务的开始结束 流数据拆分功能单元 工作模式设置为STREAM，并且输出类型设置为扩张 一张图片推理出多辆车，多每辆车做车牌检测，再讲整张图的所有车牌汇总 流数据合并功能单元 工作模式设置为STREAM，并且输出类型设置为合并 一张图片推理出多辆车，多每辆车做车牌检测，再讲整张图的所有车牌汇总 推理功能单元 只需准备好模型和配置toml文件即可 功能单元接口说明 功能单元接口，包含功能单元插件初始化接口，功能单元初始化接口和数据处理接口。 API接口类型实现对照关系 功能单元提供了FlowUnit::相关的接口，其接口按不同类型的功能单元而不同，开发者应根据FlowUnit处理数据的类型，选择实现相关的接口，对应的关系表如下： 接口 接口类型 接口功能 调用实时机 是否必须 通用功能单元 条件功能单元 数据流功能单元 数据流拆分功能单元 数据流合并功能单元 DriverInit 插件初始化接口 模块初始化 插件加载时调用一次 否 ✔️ ✔️ ✔️ ✔️ ✔️ DriverFini 插件初关闭接口 模块退出 插件结束时调用一次 否 ✔️ ✔️ ✔️ ✔️ ✔️ FlowUnit::Open 功能单元初始化接口 功能单元初始化 图加载功能单元时调用 否 ✔️ ✔️ ✔️ ✔️ ✔️ FlowUnit::Close 功能单元关闭接口 功能单元关闭 图结束时调用 否 ✔️ ✔️ ✔️ ✔️ ✔️ FlowUnit::Process 数据处理接口 数据处理 有数据产生时调用 是 ✔️ ✔️ ✔️ ✔️ ✔️ FlowUnit::DataGroupPre 数据处理接口 流数据合并开始 流数据合并时，流开始点触发 否 ✔️ FlowUnit::DataGroupPost 数据处理接口 流数据合并结束 流数据合并时，流结束点触发 否 ✔️ FlowUnit::DataPre 数据处理接口 流数据开始 流数据开始时触发 否 ✔️ FlowUnit::DataPost 数据处理接口 流数据结束 流数据结束时触发 否 ✔️ 接口实现关系说明 大部分情况下，业务都属于通用功能单元，仅需要处理单个数据，开发只需要实现FlowUnit::Process的功能即可。 若功能单元需要处理流数据，或需要记录状态，对数据进行跟踪处理，则需要实现FlowUnit:DataPre, FlowUnit::Process, FlowUnit::DataPost接口的功能。 若需要多数据合并，汇总结果，则需要实现FlowUnit::DataGroupPre, FlowUnit::DataPre, FlowUnit::Process, FlowUnit::DataPost, FlowUnit::DataGroupPost接口。 DriverInit, DriverFini, FlowUnit::Open, FlowUnit::Close在不同的时机触发，业务可根据需要实现相关的功能。比如初始化某些会话，句柄等资源。 功能单元初始化、关闭 对应需实现的接口为FlowUnit::Open、FlowUnit::Close，此接口可按需求实现。例如，使用::Open接口获取用户在图中的配置参数，使用::Close接口释放功能单元的一些公共资源。 数据处理 对应需实现的接口为FlowUnit::Process, Process为FlowUnit的核心函数。输入数据的处理、输出数据的构造都在此函数中实现。Process接口处理流程大致如下： 从DataContext中获取Input输入BufferList，Output输出BufferList对象，参数为Port名称。 循环处理每一个Input Buffer数据。 对每一个Input Buffer数据可使用Get获取元数据信息。 业务处理，根据需求对输入数据进行处理。 构造output_buffer，并使用output_buffer->Build申请输出内存，内存和设备相关，设备DriverDesc的时候设置。如是CPU则是CPU内存，如是GPU则是GPU显存。 对每一个Output Buffer数据可使用Set设置元数据信息。 返回成功后，ModelBox框架将数据发送到后续的功能单元。 Stream流数据处理 对应需实现的接口为FlowUnit::DataPre、FlowUnit::DataPost，此接口Stream模式可按需实现。例如，处理一个视频流时，在视频流开始时会调用DataPre，视频流结束时会调用DataPost。FlowUnit可以在DataPre阶段初始化解码器，在DataPost阶段关闭解码器，解码器的相关句柄可以设置到DataContext上下文中。DataPre、DataPost接口处理流程大致如下： Stream流数据开始时，在DataPre中获取数据流元数据信息，并初始化相关的上下文，存储DataContext->SetPrivate中。 处理Stream流数据时，在Process中，使用DataContext->GetPrivate获取到上下文对象，并从Inpu中获取输入，处理后，输出到Output中。 Stream流数据结束时，在DataPost中释放相关的上下文信息。 拆分合并处理 对应需实现的接口为FlowUnit::DataGroupPre、FlowUnit::DataGroupPost，当数据需要拆分合并时需要实现。 在业务处理过程中对数据进行拆分，然后在后续功能单元中处理，当数据处理完成后需要对数据进行合并得到最终结果。 对应的处理代码和DataPre，DataPost类似，如下图 如要将输入Stream1，Stream2，...合并为一个Stream。则接口调用过程为 DataGroupPre DataPre, Stream1 DataPost, Stream1 DataPre, Stream2 DataPost, Stream2 ... DataGroupPost 在编写代码时，其过程和DataPre类似，差别在于合并时对一组数据的归并动作：GroupPre中获取数据，并在Post中打开output的数据流上下文， 每个DataPre，DataPost中处理每个数据，最后在GroupPost中结束数据的合并。 上下文 功能单元上下文包含，会话上下文|SessionContext和数据上下文|DataContext SessionContext 会话上下文 SessionContext主要供调用图的业务使用，业务处理数据时，设置状态对象。 生命周期 绑定ExternalData，从数据进入Flow，贯穿整个图，一直到数据处理完成结束。 使用场景 例如http服务同步响应场景，首先接收到http请求后转化成buffer数据，然后通过ExternalData->GetSessionContext接口获取到SessionContext，接着调用SessionContext->SetPrivate设置响应的回调函数，之后通过ExternalData->Send接口把buffer数据发送到flow中；经过中间的业务处理功能单元；最后http响应功能单元中在业务数据处理完成后，再调用SessionContext->GetPrivate获取响应回调函数，发送http响应。至此SessionContext也结束。 DataContext 数据上下文 DataContext是提供给当前功能单元处理数据时的临时获取BufferList 功能单元处理一次Stream流数据，或一组数据的上下文，当数据生命周期不再属于当前功能单元时，DataContext生命周期也随之结束。 生命周期 绑定BufferList，从数据进入FlowUnit到处理完成。 使用场景 通过DataContext->Input接口获取输入端口BufferList，通过DataContext->Output接口获取输出端口BufferList对象,通过DataContext->SetPrivate接口设置临时对象，DataContext->GetPrivate接口获取临时对象。 功能单元处理异常 开发者在运行流程图和开发流程图的过程当中，需要针对功能单元的情况返回异常，并且能够可以在其他业务功能单元中捕获当前异常进行自定义处理，modelbox即可提供该场景下异常捕获处理的能力。 具体可以参考指导 多种语言开发功能单元 功能单元的开发可以使用多种语言，开发者可以选择使用合适的语言进行开发，也可以多种方式混合。 方式 适合类型 复杂度 连接 C++ 适合有高性能要求的功能开发，需要编译成so，开发复杂度稍高。 ⭐️⭐️⭐️ 指导 Python 适合对性能要求不高的功能开发，可快速上线运行。 ⭐️⭐️ 指导 配置文件 适合模型推理类功能的开发，直接提供模型即可运行，方便快捷。 ⭐️ 指导 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/flowunit/inference.html":{"url":"develop/flowunit/inference.html","title":"推理","keywords":"","body":"推理功能单元 ModelBox内置了主流的推理引擎，如TensorFlow，TensorRT，Pytorch，Ascend ACL，Mindspore。在开发推理功能单元时，只需要通过配置toml文件，即可完成推理功能单元的开发。 开发之前，可以从功能单元概念章节了解流单的执行过程。 推理功能单元目录结构 推理功能单元只需要提供独立的toml配置文件，指定推理功能单元的基本属性即可，目录结构为： [flowunit-name] |---[flowunit-name].toml #推理功能单元配置 |---[model].pb #模型文件 |---[infer-plugin].so #推理自定义插件 ModelBox框架在初始化时，会扫描[some-flowunit]目录中的toml后缀的文件，并读取相关的推理功能单元信息。[infer-plugin].so是推理所需插件，推理功能单元支持加载自定义插件，开发者可以实现tensorRT 自定义算子。 开发着可以通过modelbox-tool命令进行推理功能单元模板创建： modelbox-tool create -t infer -n FlowUnitName -d ./ProjectName/src/flowunit 推理功能流单元配置(toml格式) # 基础配置 [base] name = \"FlowUnit-Name\" # 功能单元名称 device = \"cuda\" # 功能单元运行的设备类型，cpu，cuda，ascend等。 version = \"1.0.0\" # 功能单元组件版本号 description = \"description\" # 功能单元功能描述信息 entry = \"model.pb\" # 模型文件路径 type = \"inference\" #推理功能单元时，此处为固定值 virtual_type = \"tensorrt\" # 指定推理引擎, 可以是tensorflow, tensorrt, torch, acl, mindspore plugin = \"infer-plugin.so\" # 推理自定义引擎插件 仅支持virtual_type为tensorflow, tensorrt # 模型解密配置 （可选，非必须） [encryption] plugin_name = \"modeldecrypt-plugin\" # 可以修改为自己实现的解密插件名 plugin_version = \"1.0.0\" # 通常情况下，rootkey和passwd需要隐藏，不能配置在此处，实现自己的解密插件，从云端下载或者隐藏在代码内 rootkey = \"encrypt root key\" passwd = \"encrypt password\" # 输入端口描述 [input] [input.input1] # 输入端口编号，格式为input.input[N] name = \"Input\" # 输入端口名称 type = \"datatype\" # 输入端口数据类型, 取值float or uint8 device = \"cpu\" #输入数据存放位置，取值cpu/cuda/ascend，tensorflow框架只支持cpu，其他场景一般和base.device一致，可不填 # 输出端口描述 [output] [output.output1] # 输出端口编号，格式为output.output[N] name = \"Output\" # 输出端口名称 type = \"datatype\" # 输出端口数据类型, 取值float or uint8 编写完成toml文件后，将对应的路径加入ModelBox的图配置中的搜索路径即可使用开发后的推理功能单元。 说明 模型文件类型和模型推理引擎一一对应，如下表： 推理引擎 模型格式 tensorflow xxx.pb tensorrt xxx.engine(序列化模型) torch xxx.pt acl xxx.om mindspore xxx.mindir 模型引擎为tensorrt时，可以对应三种模型格式，toml文件的修改如下： 模型类型为uff, 配置文件当中增加 ... [config] uff_input = \"input.1.28.28\" # 输入名称以及输入的shape大小，以.隔开 ... 模型类型为caffe, 配置文件当中修改增加 ... entry = \"xxx.prototxt\" model_file = \"xxx.caffemodel\" ... 模型类型为onnx, 配置文件当中修改 entry = \"xxx.onnx\" 模型类型为tensorrt自己生成的序列化模型, 不论任何后缀直接配置到entry即可 base域下面的plugin选项 plugin即为文件路径下面的so，该so为为自定义modelbox的tensorflow推理的预处理以及后处理函数，需要自定义实现以下接口(为可选项) // tensorflow class InferencePlugin { ... /** * @brief init plugin * @param config modelbox config, can get key value from the graph toml * @return init result, modelbox status */ virtual modelbox::Status PluginInit(std::shared_ptr config) = 0; /** * @brief before inferencere, preprocess data * @param ctx modelbox datacontext, can get input data from this * @param input_tf_tensor_list tensorflow TF_Tensor*, after preprocess data from ctx, * build input TF_Tensor to inference * @return preprocess result, modelbox status */ virtual modelbox::Status PreProcess(std::shared_ptr ctx, std::vector &input_tf_tensor_list) = 0; /** * @brief after inferencere, postprocess data * @param ctx modelbox datacontext, can get modelbox output object from this * @param output_tf_tensor_list tensorflow TF_Tensor*, after inference output data store in it, * build output bufferlist from it * @return postprocess result, modelbox status */ virtual modelbox::Status PostProcess(std::shared_ptr ctx, std::vector &output_tf_tensor_list) = 0; ... }; tensorrt的自定义算子构建的PluginFactory 目前自带yolo版本的PluginFactory，只需要在toml配置文件当中增加 [config] plugin = \"yolo\" 后续支持自定义算子的tensorrt插件，编译成动态库，把路径配置在这里 torch模型需要保存成成jit模型，参考sample如下： jit_model = torch.jit.script(Module) jit_model.save(\"save_model.pt\") torch模型的输入输出配置可以自定义名称，在此仅仅为位置占位符，但是需要保证输入输出的顺序一致 模型加解密 模型加密分为2个部分：模型加密工具和模型解密插件。 模型加密工具为modelbox-tool key内，使用ModelBox Tool加密模型后，可获取root key和模型密钥，以及加密后的模型。 ModelBox目前默认自带了模型加密功能，但为了确保模型安全，开发者应该至少实现自己的模型解密插件，至少需要隐藏模型的rootkey和passwd，具体参考修改src/drivers/devices/cpu/flowunit/model_decrypt_plugin/model_decrypt_plugin.cc内的Init函数， rootkey_ = config->GetString(\"encryption.rootkey\"); en_pass_ = config->GetString(\"encryption.passwd\"); 注意事项1： encryption.rootkey和 encryption.passwd为加密后的模型解密密钥，但模型加密使用的是对称算法，模型仍然存在被破解的可能性，比如反汇编跟踪调试解密代码。 为保证模型不被非法获取，开发者需要对运行的系统环境进行加固，比如设置bootloader锁，设置OS分区签名校验，移除调试跟踪工具，若是容器的，关闭容器的ptrace功能。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/flowunit/python.html":{"url":"develop/flowunit/python.html","title":"Python","keywords":"","body":"Python开发功能单元 Python开发功能单元时，需要预先安装ModelBox的运行包， 可参考编译安装章节， 在开发之前，可以从功能单元概念章节了解流单的执行过程。 Python API调用说明 Python FlowUnit接口调用过程如下图所示。 FlowUnit开发分为两部分，一部分是TOML配置, 一部分是FlowUnit代码，用户需要实现如下接口和配置： 组件 函数 功能 是否必须 实现功能 TOML配置 base.* 设置Python插件基本属性 是 填写Python插件相关的描述信息，包括，插件名称，插件版本号，插件运行的设备类型，查询的细节描述信息，以及插件的Python入口信息。 TOML配置 config.* 配置参数 是 可以自定义增加功能单元配置参数 TOML配置 input. output. 输入，输出端口属性 是 用于描述插件的输入，输出端口个数，名称，类型 FlowUnit FlowUnit::OpenFlowUnit::Close FlowUnit初始化 否 FlowUnit初始化、关闭，创建、释放相关的资源 FlowUnit FlowUnit::Process FlowUnit数据处理 是 FlowUnit数据处理函数，读取数据数据，并处理后，输出数据 FlowUnit FlowUnit::DataPreFlowUnit::DataPost Stream流数据开始，结束通知 部分 Stream流数据开始时调用DataPre函数初始化状态数据，Stream流数据结束时释放状态数据，比如解码器上下文。 FlowUnit FlowUnit::DataGroupPreFlowUnit::DataGroupPost 数据组归并开始，结束通知 部分 数据组归并，结束通知函数，当数据需要合并时，对一组数据进行上下文相关的操作。 Python功能单元目录结构 python功能单元需要提供独立的toml配置文件，指定python功能单元的基本属性。一般情况，目录结构为： [FlowUnitName] |---[FlowUnitName].toml |---[FlowUnitName].py |---xxx.py 创建模板代码 ModelBox提供了模板创建工具，可以通过ModelBox Tool工具产生python功能单元的模板，具体的命令为 modelbox-tool create -t python -n FlowUnitName -d ./ProjectName/src/flowunit ModelBox框架在初始化时，会扫描/path/to/flowunit/[FlowUnitName]目录中的toml后缀的文件，并读取相关的信息，具体可通过ModelBox Tool工具查询。 TOML配置 # 基础配置 [base] name = \"FlowUnit-Name\" # 功能单元名称 device = \"cpu\" # 功能单元运行的设备类型，python 功能单元仅支持cpu类型。 version = \"x.x.x\" # 功能单元组件版本号 description = \"description\" # 功能单元功能描述信息 entry = \"python-module@SomeFlowunit\" # python 功能单元入口函数 type = \"python\" # Python功能单元时，此处为固定值 # 工作模式 stream = false # 是否数据功能单元 condition = false # 是否条件功能单元 collapse = false # 是否合并功能单元 collapse_all = false # 是否合并所有数据 expand = false # 是否拆分功能单元 # 默认配置值 [config] item = value # 输入端口描述 [input] [input.input1] # 输入端口编号，格式为input.input[N] name = \"Input\" # 输入端口名称 type = \"datatype\" # 输入端口数据类型 # 输出端口描述 [output] [output.output1] # 输出端口编号，格式为output.output[N] name = \"Output\" # 输出端口名称 type = \"datatype\" # 输出端口数据类型 头文件 编写时，需要先确认设备的类型，确认完成设备类型后，导入对应设备的头文件，例如 import _flowunit as modelbox 基本接口 import _flowunit as modelbox from PIL import Image class SomeFlowunit(modelbox.FlowUnit): # 派生自modelbox.FlowUnit def __init__(self): super().__init__() def open(self, config): # 打开功能单元，获取配置信息 return modelbox.Status.StatusCode.STATUS_SUCCESS def process(self, data_context): # 数据处理 return modelbox.Status.StatusCode.STATUS_SUCCESS def close(self): # 关闭功能单元 return modelbox.Status() def data_pre(self, data_context): # stream流数据开始 return modelbox.Status() def data_post(self, data_context): # stream流数据结束 return modelbox.Status() def data_group_pre(self, data_context): # 数据组开始 return modelbox.Status() def data_group_post(self, data_context): # 数据组结束 return modelbox.Status() FlowUnit接口说明 功能单元的数据处理的基本单元。如果功能单元的工作模式是stream = false时，功能单元会调用open、process、close接口；如果功能单元的工作模式是stream = true时，功能单元会调用open、data_group_pre、data_pre、process、data_post、data_group_post、close接口；用户可根据实际需求实现对应接口。 功能单元初始化、关闭接口 对应的需要实现的接口为open, close接口，实现样例如下： def open(self, config): # 打开功能单元，获取配置信息。 # 获取用户配置。 config_item = config.get_float(\"config\", \"default\") # 初始化公共资源。 # 返回初始化结果。 return modelbox.Status.StatusCode.STATUS_SUCCESS def close(self): # 关闭功能单元，返回关闭结果。 return modelbox.Status.StatusCode.STATUS_SUCCESS 返回modelbox.Status.StatusCode.STATUS_SUCCESS，表示初始化成功，否则初始化失败。 数据处理 对应的需要实现的接口为process接口，实现样例如下： def process(self, data_context): # 获取输入，输出控制对象。 # 此处的\"Input\"和\"Output\"必须与toml的端口名称一致 inputs = data_context.input(\"Input\") outputs = data_context.output(\"Output\") # 循环处理每一个input输入 for buffer in inputs: np_in_data = np.array(buffer, copy= False) np_out_data = process_data(np_in_data) out_buffer = self.create_buffer(np_out_data) out_buffer.set(\"brightness\", self.__brightness) outputs.push_back(out_buffer) return modelbox.Status.StatusCode.STATUS_SUCCESS Process接口处理流程大致如下： 从context中获取Input输入，Output输出对象，参数为Port名称。 循环处理每一个inputs数据。 将input数据转换为numpy对象，并编写process_data函数。 将process_data结果返回的output numpy数据调用self.create_buffer，转换为buffer。 设置output buffer的meta信息。 将output放入outputs结果集中。 返回处理结果。 Process的返回值说明 返回值 说明 STATUS_OK 返回成功，将Output中的数据，发送到后续FlowUnit流程。 STATUS_CONTINUE 返回成功，暂缓发送Output中的数据。 STATUS_SHUTDOWN 停止数据处理，终止整个流程图。 其他 停止数据处理，当前数据处理报错。 Stream流数据处理 对应需实现的接口为data_pre、data_post，此接口Stream模式可按需实现。实现样例如下： def data_pre(self, data_ctx): # 获取Stream流元数据信息 stream_meta = data_ctx.get_input_meta(\"Stream-Meta\") # 初始化Stream流数据处理上下文对象。 decoder = self.CreateDecoder(stream_meta) # 保存流数据处理上下文对象。 data_ctx.SetPrivate(\"Decoder\", decoder) return modelbox.Status.StatusCode.STATUS_SUCCESS def process(self, data_ctx): # 获取流数据处理上下文对象。 decoder = data_ctx.GetPrivate(\"Decoder\") inputs = data_ctx.input(\"Input\") outputs = data_ctx.output(\"Output\") # 处理输入数据。 decoder.Decode(inputs, outputs) return modelbox.Status.StatusCode.STATUS_SUCCESS def data_post(self, data_ctx): # 关闭解码器。 decoder = data_context.GetPrivate(\"Decoder\") decoder.DestroyDecoder() return modelbox.Status.StatusCode.STATUS_SUCCESS 拆分合并处理 对应需实现的接口为data_group_pre、data_group_post，假设需要统计视频流中每一帧有几个人脸，和整个视频文件所有人脸数量，实现样例如下： def data_group_pre(self, data_ctx): # 创建整个视频流计数 stream_count = 0 data_ctx.SetPrivate(\"stream_count\", stream_count) return modelbox.Status.StatusCode.STATUS_SUCCESS def data_pre(self, data_ctx): # 创建当前帧的人脸计数 frame_count = 0 data_ctx.SetPrivate(\"frame_count\", frame_count) return modelbox.Status.StatusCode.STATUS_SUCCESS def process(self, data_ctx): # 获取流数据处理上下文对象 inputs = data_ctx.input(\"Input\") outputs = data_ctx.output(\"Output\") stream_count = data_ctx.GetPrivate(\"stream_count\") frame_count = data_ctx.GetPrivate(\"frame_count\") return modelbox.Status.StatusCode.STATUS_SUCCESS def data_post(self, data_ctx): # 打印当前帧人脸计数 frame_count = data_context.GetPrivate(\"frame_count\") print(\"frame face total is \", frame_count) return modelbox.Status.StatusCode.STATUS_SUCCESS def data_group_post(self, data_ctx): # 打印视频流的人脸计数 stream_count = data_context.GetPrivate(\"stream_count\") print(\"stream face total is \", stream_count) return modelbox.Status.StatusCode.STATUS_SUCCESS ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/flowunit/c++.html":{"url":"develop/flowunit/c++.html","title":"C++","keywords":"","body":"c++开发功能单元 在开发之前，可以从功能单元概念章节了解功能单元的执行过程。 C++ API调用说明 FlowUnit接口调用过程如下图所示。 FlowUnit开发分为三部分，Driver和Factory，分别设置插件属性和功能单元属性，封装为易于接口，FlowUnit为功能单元处理对象，三部分的需要实现的功能如下： 组件 函数 功能 是否必须 实现功能 Driver MODELBOX_DRIVER_FLOWUNIT 设置插件属性 是 Driver属性设置接口，填写插件相关的描述信息，包括，插件名称，插件版本号，插件运行的设备类型，初始化函数，查询的细节描述信息，插件的配置参数列表。 Factory MODELBOX_FLOWUNIT 功能单元属性设置接口，并注册到ModelBox 是 填写ModelBox相关的输入，输出端口，参数设置等信息 FlowUnit FlowUnit::OpenFlowUnit::Close FlowUnit初始化 否 FlowUnit初始化、关闭，创建、释放相关的资源 FlowUnit FlowUnit::ProcessAscendFlowUnit::AscendProcess CudaFlowUnit::CudaProcess FlowUnit数据处理 是 FlowUnit数据处理函数，读取数据数据，并处理后，输出数据 FlowUnit FlowUnit::DataPreFlowUnit::DataPost Stream流数据开始，结束通知 部分 stream流数据开始时调用DataPre函数初始化状态数据，Stream流数据结束时释放状态数据，比如解码器上下文。 FlowUnit FlowUnit::DataGroupPreFlowUnit::DataGroupPost 数据组归并开始，结束通知 部分 数据组归并，结束通知函数，当数据需要合并时，对一组数据进行上下文相关的操作。 头文件 编写时，需要先确认设备的类型，确认完成设备类型后，导入对应设备的头文件，例如 设备类型 头文件 说明 cpu #include CPU类型的功能单元 cuda #include Nvidia GPU类型的功能单元 ascend #include Huawei Ascend类型的功能单元 flowunit #include 功能单元开发接口 创建模板工程 ModelBox提供了模板创建工具，可以通过ModelBox Tool工具产生c++功能单元的模板，具体的命令为 modelbox-tool create -t c++ -n FlowUnitName -d ./ProjectName/src/flowunit Driver接口说明 Driver相关的接口，主要用于描述Drvier相关的属性，如Driver名称，版本号，设备类型，描述信息。FlowUnit功能单元开发，这里只需修改功能单元名称即可。 设置Driver相关属性 #include \"modelbox/flowunit_api_helper.h\" MODELBOX_DRIVER_FLOWUNIT(desc) { // 设置插件相关属性 desc.Desc.SetName(FLOWUNIT_NAME); desc.Desc.SetClass(modelbox::DRIVER_CLASS_FLOWUNIT); desc.Desc.SetType(modelbox::DEVICE_TYPE); desc.Desc.SetVersion(FLOWUNIT_VERSION); desc.Desc.SetDescription(FLOWUNIT_DESC); desc.Init([]() { // driver init function. return modelbox::STATUS_OK; }); desc.Exit([]() { // driver finish function. return modelbox::STATUS_OK; }); return; } 代码从上到下，分别设置Driver命令，类型，设备类型，描述信息，版本号。 如果有需要Driver相关的初始化功能，可以通过desc.Init, desc.Exit设置回调函数。desc.Init在插件启用时调用，desc.Exit在插件关闭时调用。 设置FlowUnit相关属性 ModelBox在编写插件时，需要定义FlowUnit对应的处理函数和设置FlowUnit对应的端口，参数等信息。 FlowUnit属性设置 #include \"modelbox/flowunit_api_helper.h\" MODELBOX_FLOWUNIT(SomeFlowUnit, desc) { // 设置FlowUnit属性 desc.SetFlowUnitName(\"some-flowuint\"); desc.SetFlowType(modelbox::NORMAL); desc.AddFlowUnitInput( modelbox::FlowUnitInput(\"input\", modelbox::DEVICE_TYPE)); desc.AddFlowUnitOutput( modelbox::FlowUnitOutput(\"output\", modelbox::DEVICE_TYPE)); } 设置功能单元名称，工作模式，输入及输出的名称、类型。此处可以写多个功能单元功能模块的描述，此描述等效于向框架注册功能单元的信息，注册后框架扫描到so时，才能够正确按照名称对功能单元进行加载。 SomeFlowUnit：对应的插件功能单元派生对象，从FlowUnit派生出来的类。 MODELBOX_FLOWUNIT: 一个Driver内部可以注册多个功能单元，MODELBOX_FLOWUNIT可以设置多个不同的FlowUnit。 FlowUnit接口说明 功能单元的数据处理的基本单元。如果功能单元的工作模式是modelbox::NORMAL时，功能单元会调用::Open、::Process、::Close接口；如果功能单元的工作模式是modelbox::STREAM时，功能单元会调用::Open、::DataGroupPre、::DataPre、::Process、::DataPost、::DataGroupPost、::Close接口；用户可根据实际需求实现对应接口。 FlowUnit数据处理接口 class SomeFlowUnit : public modelbox::FlowUnit { public: modelbox::Status Open(const std::shared_ptr &opts) { // 功能单元打开，读取配置 return modelbox::STATUS_OK; } modelbox::Status Close() { // 功能单元关闭，释放资源 return modelbox::STATUS_OK; } modelbox::Status Process(std::shared_ptr data_ctx) { // 数据处理 return modelbox::STATUS_OK; } modelbox::Status DataPre(std::shared_ptr data_ctx) { // stream流数据处理开始 return modelbox::STATUS_OK; }; modelbox::Status DataPost(std::shared_ptr data_ctx) { // stream流数据处理结束 return modelbox::STATUS_OK; }; modelbox::Status DataGroupPre(std::shared_ptr data_ctx) { // 数据组处理开始 return modelbox::STATUS_OK; }; modelbox::Status DataGroupPost(std::shared_ptr data_ctx) { // stream流数据处理结束 return modelbox::STATUS_OK; }; }; 加速卡类型FlowUnit接口 目前ModelBox支持开发cuda 和 ascend类型的功能单元，与cpu类型不同，cuda和ascend上进行编程存在stream的概念，所以接口上有些差异，具体参考下列编程接口 设备 说明 连接 Ascend Huawei Ascend 链接 Cuda Nvidia Cuda 链接 功能单元初始化、关闭接口 对应需实现的接口为FlowUnit::Open、FlowUnit::Close，实现样例如下： modelbox::Status SomeFlowUnit::Open( const std::shared_ptr &opts) { // 获取功能单元配置参数 auto pixel_format = opts->GetString(\"pixel_format\", \"bgr\"); return modelbox::STATUS_OK; } Open函数将在图初始化的时候调用，const std::shared_ptr &opts为功能单元的配置参数，可调用相关的接口获取配置，返回modelbox::STATUS_OK，表示初始化成功，否则初始化失败。 modelbox::Status Close() { return modelbox::STATUS_OK; } Close函数将在图处理结束时调用，可用于释放相关的资源。 数据处理 对应需实现的接口为FlowUnit::Process，实现样例如下： modelbox::Status CVResizeFlowUnit::Process( std::shared_ptr ctx) { // 获取输入，输出Buffer对象，\"input\", \"output\"为对应功能单元Port名称，可以有多个。 // 此处的\"Input\"和\"Output\"必须与toml的端口名称一致 auto input_bufs = ctx->Input(\"input\"); auto output_bufs = ctx->Output(\"output\"); // 获取绑定设备，设备在DriverDesc的时候设置的输出buffer设备 auto device = GetBindDevice(); // 循环处理每个输入数据，并产生相关的输出结果。 for (auto &input : *input_bufs) { // 获取数据元数据信息 auto meta = input->Get(\"Meta\", \"Default\"); // 获取输入，输出的内存指针。输入为const只读数据，输出为可写入数据。 auto input_data = input->ConstData(); // 根据device类型构造buffer auto output_buffer = std::make_shared(device); // 处理数据，下面给出几个例子，根据需要选择对应转换方式 /* 1. string转成buffer */ std::string test_str = \"test string xxx\"; // 申请内存，单位是字节数 output_buffer->Build(test_str.size()); // 获取对应类型的buffer指针 auto output_data = static_cast(output_buffer->MutableData()); // 拷贝string到buffer中。假设输出为cpu设备，则这里使用cpu内存拷贝 if(memcpy_s(output_data, output_buffer->GetBytes(), test_str.data(), test_str.size()) != 0 ) { MBLOG_ERROR (input_data); output_buffer->Build(input->GetBytes()) // 拷贝string到buffer中。假设输出为cuda设备，则这里需要用cuda显存拷贝 if(cudaMemcpy(output_buffer, in_data, input_buf->GetBytes(), cudaMemcpyHostToDevice) != 0) { MBLOG_ERROR Set(\"Meta\", \"Meta Data\"); // push到输出bufferlist中 output_bufs->PushBack(output_buffer); } return modelbox::STATUS_OK; Process的返回值说明 返回值 说明 STATUS_OK 返回成功，将Output中的数据，发送到后续FlowUnit流程。 STATUS_CONTINUE 返回成功，暂缓发送Output中的数据。 STATUS_SHUTDOWN 停止数据处理，终止整个流程图。 其他 停止数据处理，当前数据处理报错。 Stream流数据处理 对应需实现的接口为FlowUnit::DataPre、FlowUnit::DataPost，此接口Stream模式可按需实现。实现样例如下： modelbox::Status VideoDecoderFlowUnit::DataPre( std::shared_ptr data_ctx) { // 获取Stream流元数据信息 auto stream_meta = data_ctx->GetInputMeta(\"Stream-Meta\"); // 初始化Stream流数据处理上下文对象。 auto decoder = CreateDecoder(stream_meta); // 保存流数据处理上下文对象。 data_ctx->SetPrivate(\"Decoder\", decoder); return modelbox::STATUS_OK; } modelbox::Status CVResizeFlowUnit::Process( std::shared_ptr ctx) { // 获取流数据处理上下文对象。 auto decoder = data_ctx->GetPrivate(\"Decoder\"); auto inputs = ctx->Input(\"input\"); auto outputs = ctx->Output(\"output\"); // 处理输入数据。 decoder->Decode(inputs, outputs); return modelbox::STATUS_OK; } modelbox::Status VideoDecoderFlowUnit::DataPost( std::shared_ptr data_ctx) { // 关闭解码器。 auto decoder = data_ctx->GetPrivate(\"Decoder\"); decoder->DestroyDecoder(); return modelbox::STATUS_OK; } 拆分合并处理 对应需实现的接口为FlowUnit::DataGroupPre、FlowUnit::DataGroupPost，假设需要统计视频流中每一帧有几个人脸，和整个视频文件所有人脸数量，实现样例如下： modelbox::Status VideoDecoderFlowUnit::DataGroupPre( std::shared_ptr data_ctx) { // 创建整个视频流计数 uint64_t stream_count = 0; data_ctx->SetPrivate(\"stream_count\", stream_count); return modelbox::STATUS_OK; } modelbox::Status VideoDecoderFlowUnit::DataPre( std::shared_ptr data_ctx) { // 创建当前帧的人脸计数 uint64_t frame_count = 0; data_ctx->SetPrivate(\"frame_count\", frame_count); return modelbox::STATUS_OK; } modelbox::Status CVResizeFlowUnit::Process( std::shared_ptr ctx) { // 获取流数据处理上下文对象 auto inputs = ctx->Input(\"input\"); auto outputs = ctx->Output(\"output\"); auto stream_count = std::static_pointer_cast(data_ctx->GetPrivate(\"stream_count\")); auto frame_count = std::static_pointer_cast(data_ctx->GetPrivate(\"frame_count\")); ++frame_count; ++stream_count; return modelbox::STATUS_OK; } modelbox::Status VideoDecoderFlowUnit::DataPost( std::shared_ptr data_ctx) { // 打印当前帧人脸计数 auto stream_count = std::static_pointer_cast(data_ctx->GetPrivate(\"frame_count\")); MBLOG_INFO data_ctx) { // 打印视频流的人脸计数 auto stream_count = std::static_pointer_cast(data_ctx->GetPrivate(\"stream_count\")); MBLOG_INFO 编译安装 ModelBox C++工程统一使用CMake进行编译，通过modelbox-tool生成的c++功能单元模板中默认包含CMakeLists.txt文件，主要功能如下： 设置功能单元名称 链接功能单元所需头文件 链接功能单元所需库 设置编译目标为动态库 指定功能单元安装目录 功能单元编译生成的so命名需要以libmodelbox-开头，否则ModelBox无法扫描。 通常情况开发cpu业务功能单元，开发者无需修改CMakeLists.txt即可完成编译，当存在引入第三方库时、设置cuda/ascend类型、修改编译选项等等诉求时需要自行修改。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/flowunit/exception.html":{"url":"develop/flowunit/exception.html","title":"异常处理","keywords":"","body":"异常处理 开发者在运行流程图和开发流程图的过程当中，需要针对flowunit的情况返回异常，能够可以在其他业务流程中捕获当前异常进行自定义处理，modelbox即可提供该场景下异常捕获处理的能力 异常处理样例 在自定义的flowunit当中，只需要在process处理过程当中针对需要处理的异常情况返回Status状态，如下例所示 Status Example::Process(std::shared_ptr data_ctx) { if (exception) { return {STATUS_FAULT, \"the desc you want to catch.\"}; } } 在自定义的需要捕获的flowunit当中，需要做如下三件事： 定义该flowunit的描述属性为ExceptionVisible(true) MODELBOX_FLOWUNIT(ExampleFlowUnit, desc) { ... desc.SetExceptionVisible(true); } // 若为c++ flowunit exception_visible = true # 若为python， 则在定义python的toml配置文件当中 在获取flowunit的process当中获取exception error. Status GetException::Process(std::shared_ptr data_ctx) { if (data_ctx->HasError()) { auto exception = data_ctx->GetError(); auto exception_desc = exception->GetDesc(); MBLOG_ERROR def process(self, data_ctx): if data_ctx.has_error(): exception = data_ctx.get_error() exception_desc = exception.get_description() print(\"error is: \" + exception_desc) # exception_desc 即为 \"the desc you want to catch\" 在定义的流程图当中增加属性exception可见 ... get_exception[..., is_exception_visible=true] ... 异常使用注意事项 不要在if-else、loop当中以及拆分合并的flowunit中捕获异常 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/service-plugin/service-plugin.html":{"url":"develop/service-plugin/service-plugin.html","title":"服务插件开发","keywords":"","body":"ModelBox服务插件 ModelBox服务插件介绍 什么是ModelBox服务插件 服务插件是指基于ModelBox框架对外交互的组件，它可以用来作为AI应用和周边系统对接的桥梁。ModelBox框架提供了服务插件管理和扩展开发能力，用户可以定制化开发属于自己业务的插件来对接第三方平台，ModelBox框架可以将其加载并运行。在服务插件内可以完成流程图的加载和运行、任务的创建和启停，统计数据的收集等。同时，ModelBox框架可以支持多个服务插件的加载。 服务插件使用场景 服务插件在视频场景使用较为普遍，典型使用场景为：视频分析任务需要从外部平台或者组件下发到ModelBox框架进行任务分析时，需要通过服务插件来接受外部的请求并转化为ModelBox框架里的分析任务进行业务分析。同时服务插件也可以实现统计信息的收集并发送给外部运维平台，实现与外部系统的对接。 ModelBox框架提供了预置的服务插件ModelBox Plugin，提供流程图的加载和运行, 见运行流程图章节。在大部分情况下，可以直接使用ModelBox Plugin完成相应的业务功能，当某些场景下，ModelBox Plugin功能无法满足要求时，需要自定义开发服务插件，下面介绍服务插件的具体开发流程。 服务插件开发流程 服务插件开发整体流程如下： 服务插件API ModelBox API按照类型包含： Plugin: 插件创建和启停等重载接口，此接口需要由用户实现 接口 接口功能 说明 CreatePlugin 用户创建服务插件对象，并返回给ModelBox框架 ModelBox框架启动时加载参加时调用 Plugin::Init 用户实现服务插件初始化逻辑，提供系统配置，插件初始化时调用 ModelBox框架启动时，在CreatePlugin成功后插件初始化调用；不能存在阻塞操作 Plugin::Start 用户实现服务插件启动逻辑，插件启动时调用 插件启动时调用 Plugin::Stop 用户实现服务插件停止逻辑，插件停止时调用 ModelBox框架进程退出时插件停止时调用 Job： 任务管理组件 任务管理组件提供任务的添加，删除，查询。ModelBox框架任务管理存在以下几种对象概念： Job：算法服务层面的任务，一个Job加载一个流程图。 JobManager：Job的管理，可以创建Job对象。 Task：处理数据源层面的作业，一个Task即对应一次数据分析，可以是一路视频流的分析，也可以是一个视频文件的分析。Task可以实现数据输入到流程图(需要配合Input节点使用)，也可以实现配置参数传递到功能单元。 TaskManager：Task的管理，可以创建Task对象。 OneShotTask: 继承自Task，一次task，专指只有一次数据输入到流程图的场景，比如输入为一路视频流的地址，只会有一次数据传递给流程图，而后需要等待分析结果。所以OneShotTask还提供了task状态变化的回调注册接口。 Session：会话信息，一个Task对应存在一个Session，Session中的数据可以在不同功能单元共享访问。 具体接口如下表： 接口 接口功能 说明 JobManager::CreateJob 创建Job JobManager::DeleteJob 删除Job JobManager::GetJob 获取某个Job对象 JobManager::GetJobList 获取全部Job对象列表 JobManager::QueryJobStatus 查询某个Job状态 JobManager::GetJobErrorMsg 获取某个异常Job的错误信息 Job::Init 初始化Job对象 Job::Build Job对象资源申请 Job::Run 运行Job对象 Job::Stop 停止Job对象 Job::GetJobStatus 获取某个Job状态 Job::CreateTaskManger 创建TaskManger TaskManager::Start 启动TaskManager TaskManager::Stop 停止TaskManager TaskManager::CreateTask 创建Task TaskManager::DeleteTaskById 删除某个Task TaskManager::GetTaskById 获取某个Task对象 TaskManager::GetTaskCount 获取Task个数 TaskManager::GetAllTasks 获取所有Task对象 TaskManager::SetTaskNumLimit 设置同时并发的Task最大个数 超过设置最大个数时，ModelBox内部会排队处理 Task::Start 启动Task Task::Stop 停止Task Task::GetUUID 获取Task id Task::CreateBufferList 创建输入的buffer数据对象 Task::GetLastError 获取Task错误信息 Task::GetTaskStatus 获取Task状态 Task::GetSessionConfig 获取Session配置对象 获取配置对象后可以通过设置自定义参数，传递给需要的功能单元读取 OneShotTask::FillData 发送数据指流程图 OneShotTask::RegisterStatusCallback 注册任务状态回调函数,任务结束或异常时会调用 Config： 配置对象 配置对象提供从服务配置文件中获取配置信息 Listener：http/https监听组件 Listener监听组件可以注册http服务，监听相关的URI Timer： 定时器组件 定时器组件可以用于启动定时任务 开发例子 准备工作 插件开发前，请确保： ModelBox Server正确安装并运行。 ModelBox Server Develop安装包正确安装。 创建服务插件模板 开发者可以通过modelbox-tool命名进行服务插件模板工程的创建，创建命令如下： modelbox-tool create -t service-plugin -n PluginName -d ./ 编写插件入口函数 插件入口流程 #ifndef MODELBOX_MODELBOX_EXAMPLE_PLUGIN_H_ #define MODELBOX_MODELBOX_EXAMPLE_PLUGIN_H_ #include \"modelbox/server/plugin.h\" #include // 插件需要实现的接口 class ModelBoxExamplePlugin : public Plugin { public: ModelBoxExamplePlugin(){}; ~ModelBoxExamplePlugin(){}; // 插件初始化时调用。 bool Init(std::shared_ptr config) override; // 插件开工启动时调用，非阻塞。 bool Start() override; // 插件停止时调用。 bool Stop() override; }; // 插件创建接口 extern \"C\" { std::shared_ptr CreatePlugin() { return std::make_shared(); }; } ModelBox加载服务插件流程如下： ModelBox Server先调用插件中的CreatePlugin函数创建插件对象。 插件需要在此函数中，创建插件对象，返回智能指针。 再调用Plugin::Init()初始化插件，入参为TOML文件配置。 插件可在初始化函数中，获取配置，并调用插件自身的初始化功能。 再调用Plugin::Start()启动插件。 插件在Start函数中启动插件服务，申请相关的资源；此函数不能阻塞。 进程退出时，调用Plugin::Stop()停止插件功能。 插件在Stop函数中停止插件的功能，并释放相关的资源。 调用ModelBox Server，ModelBox Library相关接口。 插件调用ModelBox Server，以及ModelBox Library的API进行业务控制和运行。具体参考相关的API。 Job创建流程 使用场景为流程图不依赖于外部给其输入，直接加载图配置即可运行场景。如图片推理服务，数据流可由流程图中的HTTP功能单元产生数据，再比如流程图中读本地文件作为数据源的场景。 Job job_; JobManager job_manager_; bool ModelBoxExamplePlugin::Init(std::shared_ptr config) { //创建JobManager job_manager_ = std::make_shared(); //从配置文件获取图配置，config对象为运行时传入的conf配置文件，默认路径为/usr/local/etc/modelbox/modelbox.conf auto graph_path = config->GetString(\"server.flow_path\"); //创建Job job_ = job_manager_->CreateJob(\"my_job\", graph_path); auto ret = job_->Init(); return ret; } bool ModelBoxExamplePlugin::Start() { job_->Build(); job_->Run(); return true; } bool ModelBoxExamplePlugin::Stop() { auto ret = job_->Stop(); ret = job_manager_->DeleteJob(\"my_job\"); return ret; } Task创建流程 使用场景为流程图运行依赖与外部输入的场景，如分析的视频流信息需要由外部传入服务插件，再用服务插件创建Task，并把相应配置参数数据传递到流程图。 void ModelBoxExamplePlugin::ModelBoxTaskStatusCallback(modelbox::OneShotTask *task, modelbox::TaskStatus status) { //实现任务结束或者任务异常时处理逻辑 return; } bool ModelBoxExamplePlugin::Start() { job_->Build(); job_->Run(); //创建task manager，携带最大并发数 auto task_manager = job->CreateTaskManger(10); task_manager->start(); //创建task auto task = task_manager->CreateTask(modelbox::TASK_ONESHOT); auto oneshot_task = std::dynamic_pointer_cast(task); //创建buff数据并发送给流程图 auto buff_list = oneshot_task->CreateBufferList(); auto input_cfg = \"{\\\"url\\\"：\\\"xxxx\\\"}\"; //输入需要的配置信息，由流程图中输入节点决定 auto status = buff_list->Build({input_cfg.size()}); if (status != modelbox::STATUS_OK) { return status; } auto buff = buff_list->At(0); auto ret = memcpy_s(buff->MutableData(), buff->GetBytes(), input_cfg.data(), input_cfg.size()); buff->Set(\"source_type\", std::string(\"url\")); //输入需要的配置信息，由流程图中输入节点决定 std::unordered_map> datas; datas.emplace(\"input1\", buff_list);//输入节点名称由流程图决定 status = oneshot_task->FillData(datas); if (status != modelbox::STATUS_OK) { return status; } //填充用户自定义配置 auto config = oneshot_task->GetSessionConfig(); config->SetProperty(\"nodes.{key}\", \"{vaule}\");//设置属性 //注册Task状态变更回调函数 oneshot_task->RegisterStatusCallback( [&](OneShotTask *task, TaskStatus status) { t->ModelBoxTaskStatusCallback(task, status); return; }); status = oneshot_task->Start(); if (status != modelbox::STATUS_OK) { return status; } //等待task执行结束 auto task_status = iva_task->GetTaskStatus(); while (task_status != TaskStatus::STOPPED && task_status != TaskStatus::ABNORMAL && task_status != TaskStatus::FINISHED) { sleep(1); task_status = iva_task->GetTaskStatus(); } task_manager->DeleteTaskById(oneshot_task->GetTaskId()); return true; } 服务插件配置使用 插件开发完成后，编译为SO文件。需要将插件加入ModelBox Server配置文件的plugin.files配置项插件配置列表中，即默认路径为/usr/local/etc/modelbox/modelbox.conf的plugin.files配置项。 [plugin] files = [ \"/usr/local/lib/modelbox-plugin.so\", #由于不同操作系统目录结构存在差异，此路径也可能为 /usr/local/lib64/modelbox-plugin.so \"/xxx/xxx/example-plugin.so\" ] 配置说明： modelbox-plugin.so为系统预置插件，可根据需要添加 插件按从上到下的顺序加载。 若采用tar.gz包安装的服务，modelbox.conf配置文件在对应的服务目录中。 开发者可扩展增加toml的配置项，在ModelBoxExamplePlugin::Init接口的configuration对象中获取即可。 插件加入配置文件后，systemctl restart modelbox重启ModelBox Server生效， 同时服务插件日志将统一收集到ModelBox日志。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/sdk/sdk.html":{"url":"develop/sdk/sdk.html","title":"SDK API集成","keywords":"","body":"SDK API集成 ModelBox提供了SDK API的方式，同时提供C++ SDK API接口和Python SDK API接口。 适用场景 通常场景基于ModelBox的AI应用作为独立进程运行，AI应用和周边系统应用交互通过http或者其他消息中间件进行通信。当AI应用需要作为组件被集成到其他系统进程中时，也可以直接使用ModelBox提供的SDK API进行集成开发，完成应用的集成。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/sdk/c++.html":{"url":"develop/sdk/c++.html","title":"C++","keywords":"","body":"C++开发流程图 当前方式适合哪些场景下使用 此方式主要适用于C++开发者开发流程图。 C++的API接口 flow的运行流程可参考flow章节。 从flow章节中我们知晓了流程图运行的流程，在C++中有对应的函数接口用于处理对应不同的阶段。下面是C++中使用的API列表： API接口 参数说明 函数说明 Flow::Init configfile: 指定config文件的路径format： 指定图文件的格式，可选项为 FORMAT_AUTO,FORMAT_TOML，FORMAT_JSON 初始化ModelBox服务，主要包含功能如下：1. 读取driver参数，获取driver的扫描路径2. 扫描指定路径下的driver文件，并创建driver实例3. 加载流程图并转换为ModelBox可识别的模型4. 初始化设备信息，性能跟踪和数据统计单元 Flow::Init name: 指定的图的名称graph: 存储图的字符串format：指定图的格式 与上面Init的区别是，上面通过读取文件的方式，而此函数通过读取字符串的方式，其他功能相同 Flow::Init is: 图的输入流istreamfname: 输入的图名称 功能与上面Init相同， 区别在于输入的是流保存的图信息 Flow::Init config: Configuration指针，存储图信息 功能同上 Flow::Build / 用于构建图，将图模型转为可以运行的Node节点并且建立好数据通道 Flow::Run / 图的运行： 同步方式，图运行完成后返回 Flow::RunAsync / 图的运行： 异步运行， 调用后直接返回， 通过调用Wait()函数判断运行是否结束 Flow::Wait millisecond: 超时时间， 以毫秒为单位ret_val: 图运行的结果 等待图运行结束，当图的运行时间超过millisecond表示的时间时，则强制停止图的运行，并返回TIMEOUT Flow::Stop() / 强制停止运行中的图 Flow::CreateExternalDataMap / 当图中的第一个节点为input节点时， 使用此函数可以创建一个输入的ExternalDataMap， 用户可以通过向ExternalDataMap数据中赋值并传递数据给Input节点。具体使用方法可参考章节 C++ SDK API调用说明 C++开发调用流程图时，需要先安装C++的运行包，然后再编写C++函数，调用Flow执行API执行流程图。 Flow流程图接口调用过程如下图所示。 安装C++ SDK包 开发流程图，配置基础部分和图部分。 调用Flow::init接口，输入流程图文件。 调用Flow::build初始化流程图。 调用Flow::run_async，异步执行流程图。 调用Flow::wait等待结果。 TOML流程图配置 [driver] dir=\"\" skip-default = false [graph] graphconf = '''digraph demo { input[type=input] output[type=output] process[flowunit=process] input->process->output }''' format = \"graphviz\" 导入ModelBox包 编写时，需要引入头文件。 #include 基本接口 int RunFlow(const std::string &file) { // 创建Flow执行对象 auto flow = std::make_shared(); // 输入流程图配置文件 MBLOG_INFO Init(file); if (!ret) { MBLOG_ERROR Build(); if (!ret) { MBLOG_ERROR RunAsync(); // 等待执行结果 ret = flow->Wait(); if (!ret) { MBLOG_ERROR Stop(); MBLOG_INFO 流程执行流程 使用flow-example.toml文件中配置的流程图初始化flow， auto flow = std::make_shared()， 如何配置流程图详见流程图开发流程 flow->Init(file) 根据配置文件初始化flow对象。 flow->Build() 开始构建flow对象 flow->RunAsync() 开始异步运行flow flow->Wait() 等待flow结束，参数为超时时间，超时时间为0表示无限等待。 flow->Stop() 停止流程图。 外部数据交互 配置图，图中增加input, output端口名称。 digraph demo { input[type=input] output[type=output] process[flowunit=process] input->process->output } 初始化图的数据处理对象。 std::shared_ptr ExternDataInit(std::shared_ptr flow) { auto ext_data = flow->CreateExternalDataMap(); return ext_data; } 代码发送数据，到input端口。 modelbox::Status SendExternalData(std::shared_ptr ext_data, void *data, int len) { // 申请外部数据对象 auto output_buf = ext_data->CreateBufferList(); // 申请内存，并设置内容 output_buf->Build({len}); auto buff = (int*)output_buf->MutableData(); memcpy(buff, data, len); // 将数据发送到input端口 auto status = ext_data->Send(\"input\", output_buf); if (!status) { return {status, \"send data to input failed.\"}; } // 关闭输入 status = ext_data->Shutdown(); if (!status) { return {status, \"shutdown failed.\"}; } return modelbox::STATUS_OK; } 代码从图中output端口接收数据 modelbox::Status RecvExternalData(std::shared_ptr ext_data) { OutputBufferList map_buffer_list; // 接收数据 while (true) { auto status = ext_data->Recv(map_buffer_list); if (status != STATUS_SUCCESS) { if (status == STATUS_EOF) { // 数据处理结束 break; } // 处理出错，关闭输出。 auto error = ext_data->GetLastError(); ext_data->Close(); MBLOG_ERROR GetDesc(); break; } // 处理结果数据 auto buffer_list = map_buffer_list[\"output\"]; ProcessData(buffer_list); } return modelbox::STATUS_OK; } C++日志 默认情况，ModelBox的SDK输出日志到console，业务需要注册相关的日志处理函数，注册方法可参考日志章节 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/sdk/python.html":{"url":"develop/sdk/python.html","title":"Python","keywords":"","body":"Python开发流程图 当前方式适合哪些场景下使用 此方式适用于python开发者开发流程图。 Python开发调用流程图时，需要安装python的运行包，然后再编写python函数，调用Flow执行API执行流程图。 Python的API接口 从flow章节中我们知晓了流程图运行的流程，在Python中有对应的函数接口用于处理对应不同的阶段。下面是Python中使用的API列表： API接口 参数说明 函数说明 Flow::init configfile: 指定config文件的路径format： 指定图文件的格式，可选项为 FORMAT_AUTO,FORMAT_TOML，FORMAT_JSON 初始化ModelBox服务，主要包含功能如下：1. 读取driver参数，获取driver的扫描路径2. 扫描指定路径下的driver文件，并创建driver实例3. 加载流程图并转换为ModelBox可识别的模型4. 初始化设备信息，性能跟踪和数据统计单元 Flow::init name: 指定的图的名称graph: 存储图的字符串format：指定图的格式 与上面init的区别是，上面通过读取文件的方式，而此函数通过读取字符串的方式，其他功能相同 Flow::init config: Configuration指针，存储图信息 功能同上 Flow::build() / 用于构建图，将图模型转为可以运行的Node节点并且建立好数据通道 Flow::run() / 图的运行： 同步方式，图运行完成后返回 Flow::run_async / 图的运行： 异步运行， 调用后直接返回， wait()函数判断运行是否结束 Flow::wait millisecond: 超时时间， 以毫秒为单位ret_val: 图运行的结果 等待图运行结束，当图的运行时间超过millisecond表示的时间时，则强制停止图的运行，并返回TIMEOUT Flow::stop / 强制停止运行中的图 Flow::create_external_data_map / 当图中的第一个节点为input节点时， 使用此函数可以创建一个输入的ExternalDataMap， 用户可以通过向ExternalDataMap数据中赋值并传递数据给Input节点。具体使用方法可参考外部数据交互章节 Python SDK API调用说明 Flow流程图接口调用过程如下图所示。 安装python SDK包 开发流程图，配置基础部分和图部分。 调用Flow::init接口，输入流程图文件。 调用Flow::build初始化流程图。 调用Flow::run_async，异步执行流程图。 调用Flow::wait等待结果。 TOML流程图配置 [driver] dir=\"\" skip-default = false [graph] graphconf = '''digraph demo { input[type=input] output[type=output] process[flowunit=process] input->process->output }''' format = \"graphviz\" 导入ModelBox包 编写时，需要导入ModelBox的开发包。 import modelbox 基本接口 def RunFlow(): # 指定图文件路径 flow_file = \"/path/to/graph/flow-example.toml\" flow = modelbox.Flow() # 初始化Flow接口 ret = flow.init(flow_file) if ret == False: modelbox.error(flow_file + \" flow init failed\") # 创建流程图 ret = flow.build() if ret == False: modelbox.error(flow_file + \" flow build failed\") # 异步执行流程图 ret = flow.run_async() if ret == False: modelbox.error(flow_file + \" flow run async failed\") # 等待结果 ret = flow.wait(0) if ret != modelbox.Status.StatusCode.STATUS_STOP: modelbox.error(flow_file + \" flow run failed\") 流程执行流程 使用flow-example.toml文件中配置的流程图初始化flow， flow = modelbox.Flow() 返回一个flow对象， 如何配置流程图详见流程图开发流程 flow.init(flow_file) 根据配置文件初始化flow对象。 flow.build() 开始构建flow对象 flow.run_async() 开始异步运行flow flow.wait(0) 等待flow结束，超时时间为0表示无限等待。 外部数据交互 配置图，图中增加input, output端口名称。 digraph demo { input[type=input] output[type=output] process[flowunit=process] input->process->output } 创建external data对象 # extern_data 对象 def init_external_dat(): extern_data = flow.create_external_data_map() return extern_data 代码发送数据，到input端口。 # 发送数据到图 def send_external_data(extern_data): # 申请内存。 buffer_list = extern_data.create_buffer_list() im_array = np.asarray(img_rgb[:,:]) buffer_list.push_back(im_array) # 将数据发送到\"input\"。 extern_data.send(\"input\", buffer_list) # 结束输入。 extern_data.shutdown() 代码从图中output端口接收数据 # 从图中接收数据 def recv_flow_data(extern_data): out_buffer = extern_data.create_buffer_list() # 使用创建的external对象从output接收数据 while True: ret = extern_data.recv(out_buffer) if ret != modelbox.Status.StatusCode.STATUS_SUCCESS: if ret == modelbox.Status.StatusCode.STATUS_EOF: break extern_data.close() print(\"recv data failed\", ret) break result_buffer_list = out_buffer.get_buffer_list(\"output\") # 循环处理数据 for i in range(result_buffer_list.size()): aa = result_buffer_list[i] np_image = np.array(aa, copy= False) image = Image.fromarray(np_image) # .... Python日志 默认情况，ModelBox的SDK输出日志到console，业务需要注册相关的日志处理函数，注册方法可参考日志章节 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/modelbox-tool/modelbox-tool.html":{"url":"develop/modelbox-tool/modelbox-tool.html","title":"ModelBox Tool","keywords":"","body":"ModelBox Tool ModelBox Tool是ModelBox套件集成的一个开发、维护工具，提供了开发、维护的常用命令, 可用于开发调试。 在功能上，ModelBox Tool包含了如下功能 功能 功能说明 help 显示帮助信息 driver 查看Driver列表及其功能 flow 快速运行一个流程，快速验证 create 创建模板 key 密码加解密，模型加解密 server 查看Log，Stack，Slab和Statistics信息 develop 切换开发模式 ModelBox为标准的命令行工具，可以使用modelbox-tool -h查看详细的帮助说明。 help功能 用于显示Modelbox各命令组帮助信息 查询各命令组帮助信息 modelbox-tool help driver modelbox-tool help flow modelbox-tool help create modelbox-tool help key modelbox-tool help server modelbox-tool help develop driver功能 用于查询ModelBox Driver相关的信息。 此命令组为modelbox-tool driver，格式如下： modelbox-tool driver [-type flowunit] [-path dir1,dir2] [-details [-name name]] [-conf path/to/graph.conf] -path为添加扫描路径，不携带时默认扫描系统目录，携带时，扫描系统目录和新增目录。 -name 为过滤参数，不携带时默认列出所有扫描到的结果，可以输入功能单元名称进行过滤，也可以输入cpu/cuda/ascend进行设备类型过滤。 查询列表 在开发过程中，可能需要查询图中需要的插件的列表，这时ModelBox Tool可以用于查询当前图的情况。 常用命令如下： 查询当前系统中已经安装可用的driver： modelbox-tool driver -info 查询当前系统中已经安装可用的flowunit列表： ```shell modelbox-tool driver -info -type flowunit 查询系统路径和指定图文件的flowunit列表 modelbox-tool driver -info -type flowunit -conf [path/to/graph.conf] 查询系统路径和指定路径使用的flowunit modelbox-tool driver -info -type flowunit -path [path/to/] 查询单个flowunit的详细信息 modelbox-tool driver -info -type flowunit -details -name [FlowunitName] -path [path/to/] 查询详细信息 如需要查询具体功能单元的功能说明，输入，输出名称和选项设置，可以用ModelBox Tool查询详细参数。 常用命令如下： 查询当前系统中driver的详细信息： modelbox-tool driver -info -details -name [name] 查询当前系统中所有功能单元的详细信息： modelbox-tool driver -info -type flowunit -details -name cuda 查询指定名称的功能单元详细信息 modelbox-tool driver -info -type flowunit -details -name [name] -path [path/to/] Flow功能 流程图相关的功能，用于测试，验证图是否配置正确。 此命令组为modelbox-tool flow 运行调测流程图 在开发过程中，可能需要临时调试图以及对应的功能单元，这时，可以使用modelbox-tool flow命令组的命令。 执行图 modelbox-tool flow -run [path/to/graph.toml] 工具执行后的运行日志，存储在/var/log/modelbox/modelbox-tool.log中。如果需要修改日志级别，或将日志输出到屏幕上，可参考后续章节的内容。 Create功能 创建代码模板，用于开发准备。可以使用modelbox-tool create命令组,格式如下： modelbox-tool create [-t typename] [-n name]] [-d dir] 创建算法工程模板 modelbox-tool create -t project -n [name] -d [path/to/] 创建c++功能单元模板 modelbox-tool create -t c++ -n [name] -d [path/to/src/flowunit] 创建python功能单元模板 modelbox-tool create -t python -n [name] -d [path/to/src/flowunit] 创建推理功能单元模板 modelbox-tool create -t infer -n [name] -d [path/to/src/flowunit 创建服务插件模板 modelbox-tool create -t service-plugin -n [name] -d [path/to/src/service-plugin] 通常情况下，先创建工程模板，再在工程对应目录创建功能单元或者服务插件。 Key功能 key功能包括了模型加解密，密码加密等功能。 此命令组为modelbox-tool key 密码加密 某些情况，需要对存储在本地文件，或图中的密码等敏感信息，加密。 键盘输入密码： modelbox-tool key -pass 标准输入输入密码： modelbox-tool key -pass modelbox-tool key -pass 环境变量输入密码加密 MODELBOX_PASSWORD=\"pass\" modelbox-tool key -pass 注意 默认情况下，加密的密码和设备绑定，若需要和设备无关，则需要增加-n参数。 密码安全性上，键盘输入最可靠，其次是标准输入，环境变量形式不推荐。 编程接口，可以使用popen执行命令，然后write密码到管道中。 模型加密 如需要对模型文件进行加密，则可以使用modelbox-tool key -model命令组对模型文件进行加密。 对指定模型文件进行加密 modelbox-tool key -model [path/to/model] 执行后，输入密码，工具加密后，会输出加密文件，以及加密密钥。 注意： 默认情况下，加密的密码和设备绑定，若需要和设备无关，则需要增加-n参数。 模型安全性上，并不能确保模型文件100%不被获取到明文，为保证模型的安全性，应该从系统角度考虑安全性。具体可参考推理功能单元的说明。 Server功能 查看Log，Stack，Slab和Statistics信息。 此命令组为modelbox-tool server server功能需要进行配置 Log 动态设置日志级别 此命令组为modelbox-tool server log, 命令格式如下： modelbox-tool server log --setlevel [level] modelbox-tool server log --getlevel Stack 查看modelbox线程栈信息 此命令组为modelbox-tool server stack Slab 查看内存碎片 此命令组为modelbox-tool server slab, 命令格式如下： modelbox-tool server slab modelbox-tool server slab --device --type [cuda/cpu] --id [id] Statistics 查看统计信息 此命令组为modelbox-tool server stat, 命令格式如下： modelbox-tool server stat --all modelbox-tool server stat --node [name] ModelBox Tool主配置 ModelBox Tool可以支持修改日志级别，输出形式，和日志文件路径，在执行命令时，可以通过如下参数修改 modelbox tool main options: -verbose output log to screen. -log-level log level: DEBUG, INFO, NOTICE, WARN, ERROR, FATAL. -log-path log file: default : /var/log/modelbox/modelbox-tool.log 注意，使用时，上述参数需要紧接modelbox-tool命令后，不能放到子命令组阶段，如 modelbox-tool -verbose [-log-level DEBUG] [-log-path filepath] flow -run [/path/to/graph.toml] 具体参数说明如下： 参数 功能说明 -verbose 是否将日志输出到屏幕 -log-level 输出日志级别，可以为debug, info, notice, warn, error, fatal -log-path 输出日志文件，默认为/var/log/modelbox/modelbox-tool.log ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/debug/debug.html":{"url":"develop/debug/debug.html","title":"调试定位","keywords":"","body":"调试 ModelBox提供了多种调试方法，包含了业务运行，性能，和代码的调试。 各个组件调试方法 各个组件的调试方法参考下表： 语言 组件 调试方法 c++ ModelBox套件 编译debug版本，安装并配置GDB，日志。 c++ 自开发服务 编译debug版本，安装并配置GDB，日志。 c++ 功能单元 编译debug版本，安装并配置GDB，日志，Profiling。 python 功能单元 PDB，日志，Profiling。 上述表格中，使用GDB、PDB调试的，可以配合IDE完成。 调试指导 调试方法 说明 连接 代码调试 代码级别的调试方法，主要使用现有的调试工具，IDE进行调试。 指导 运行调试 使用运行日志，业务代码使用log类函数打印相关的日志。 指导 性能调试 对图的执行进行数据打点，并输出甘特图供性能分析调试。 指导 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/debug/code-debug.html":{"url":"develop/debug/code-debug.html","title":"代码调试","keywords":"","body":"Debug 代码调试使用对应语言的调试方法即可，c++使用gdb，python使用pdb。 GDB调试方法 C++调试使用GDB即可，在调试前，需要将对应的软件编译为DEBUG版本。 编译debug版本 使用CMake的编译参数，编译为DEBUG版本。 mkdir build cd build cmake -DCMAKE_BUILD_TYPE=Debug .. make -j32 配置调试流程图 配置构造一个简单的flow流程图，确保被调测组件能被调用。 启动调试 若是调试功能单元，可以使用ModelBox Tool辅助调试。 GDB命令 gdb modelbox-tool set args -verbose -log-level info flow -run [path/to/graph.conf] b [some-func] r 上述命令意思为： 使用gdb启动modelbox-tool 设置运行参数-verbose -log-level info表示显示日志，及设置日志级别 flow -run [path/to/graph.conf]表示运行的调测流程图。 b [some-func]对指定的函数进行断点。 r 运行命令 注意：如果使用镜像开发，gdb提示无权限，则需要使用特权容器，具体参考这里的gdb调试设置 vscode vscode调试，可以先下载GDB插件，再配置调试文件.vscode/launch.json，设置program和args两个配置项如下。 \"program\": \"modelbox-tool\", \"args\": [ \"-verbose\", \"-log-level\", \"info\", \"flow\", \"-run\", \"[path/to/graph.toml]\" ], 设置完成后，使用vscode的F5功能键进行调试 Python调试方法 Python调试时，则需要先设置环境变量MODELBOX_DEBUG_PYTHON=yes后，直接使用IDE调试，其调试方法和标准的python脚本类似。 环境变量可通过python脚本，或启动进程前的shell命令设置。 python中设置启用 import os # 设置环境变量 os.environ['MODELBOX_DEBUG_PYTHON']=\"yes\" # 执行流程图 flow = modelbox.Flow() ... 环境变量中启用 export MODELBOX_DEBUG_PYTHON=yes Python功能单元调试 Python代码编写的功能单元需要从Python启动后，设置上述环境变量才能调试。但ModelBox也提供了专门用于调试Python功能单元的命令modelbox-python-debug。 具体操作方法为： IDE或调试工具设置启动程序为modelbox-python-debug; modelbox-python-debug启动toml文件的流程图。 modelbox-python-debug --flow [path/to/toml] IDE或调试工具打断点，启动调试。 Vscode调试 vscode调试，可以配置调试文件.vscode/launch.json，设置program和args两个配置项如下。 { \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Python: modelbox\", \"type\": \"python\", \"request\": \"launch\", \"program\": \"/usr/local/bin/modelbox-python-debug\", \"args\": [ \"--flow\", \"[/path/to/toml]\" ], \"console\": \"integratedTerminal\" } ] } 将[/path/to/toml]替换为实际的toml文件路径，并对需要调试的python功能单元设置断点。设置完成后，使用vscode的F5功能键进行调试。 注意： 若启用失败，则需要先安装pydevd包。 pip install pydevd ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/debug/log.html":{"url":"develop/debug/log.html","title":"日志","keywords":"","body":"日志 ModelBox提供了运行日志，对应的组件在运行时会输出相关的日志信息。 日志的基本流程 C++，Python功能单元、ModelBox库、插件调用ModelBox的日志函数后，由ModelBox的Logger将数据发送到Appender，Appender可注册不同的类型。 ModelBox的日志级别分为DEBUG, INFO, NOTICE, WARN, ERROR, FATAL。 ModelBox Server日志 ModelBox Server和ModelBox Tool中内置了File日志组件，在运行时，会将对应的日志记录到相关的文件中。对应的日志路径，配置方法如下： 进程 日志路径 级别设置 modelbox server /var/log/modelbox/modelbox.log /usr/local/etc/modelbox/modelbox.conf配置文件中，log字段的level。 modelbox tool /var/log/modelbox-tool.log modelbox-tool命令参数。 默认console日志 ModelBox Library在未设置输出appender的情况下，所有打印输出到console，且默认情况下日志输出关闭，若要设置日志级别，可以通过环境变量设置。可设置的变量值为DEBUG, INFO, NOTICE, WARN, ERROR, FATAL。 export MODELBOX_CONSOLE_LOGLEVEL=INFO 日志SDK ModelBox日志提供了日志输出接口，日志appender捕获接口；功能单元，ModelBox库，插件使用日志接口输出日志，业务模块使用appender捕获日志到对应的日志组件。 日志输出信息包括 level: 日志级别 file: 日志文件 lineno: 行号 func: 函数名称 msg: 日志内容 appender可以按需求输出日志。 不同语言的SDK日志调用接口，日志捕获接口如下： C++ c++日志调用 C++调用日志时，需要包含头文件，然后使用类似std::cout的语法输出日志。 #include void LogExample() { MBLOG_DEBUG c++日志捕获 c++提供了日志接口logger，只需要实现logger中的方法，即可将日志重定向。 class Logger { public: // vprint接口 virtual void Vprint(LogLevel level, const char *file, int lineno, const char *func, const char *format, va_list ap); // print接口 virtual void Print(LogLevel level, const char *file, int lineno, const char *func, const char *msg); // 设置日志级别 virtual void SetLogLevel(LogLevel level); // 获取日志级别 virtual LogLevel GetLogLevel() = 0; }; // 注册日志函数 ModelBoxLogger.SetLogger(logger); 流程： 编写自定义日志对象，从Logger派生，实现相关的接口 初始化时，调用ModelBoxLogger.SetLogger(logger)注册日志处理函数。 调用ModelBoxLogger.GetLogger->SetLogLevel(level)设置日志级别。 Python Python日志调用 python输出日志时，需要包含modelbox包，使用上类似，print函数。 import modelbox modelbox.debug(\"this is debug\") modelbox.info(\"this is info\") modelbox.notice(\"this is notice\") modelbox.warn(\"this is warning\") modelbox.error(\"this is error\") modelbox.fatal(\"this is fatal\") Python日志捕获 # 导入相关的包 import modelbox import datetime __log = modelbox.Log() # 日志捕获函数 def LogCallback(level, file, lineno, func, msg): # 输出日志信息 print(\"[{time}][{level}][{file}:{lineno}] {msg}\".format( time=datetime.datetime.now(), level=level, file=file, lineno=lineno, msg=msg )) # 日志注册函数 def RegLog(): # 注册日志函数 __log.reg(LogCallback) # 设置日志级别为INFO __log.set_log_level(modelbox.Log.Level.INFO) # 注册自定义日志 RegLog() 流程 编写自定义函数，函数原型为logfunc(level, file, lineno, func, msg)。 初始化日志对象modelbox.Log()。 将logfunc调用modelbox.Log::reg注册为日志处理函数 调用modelbox.Log::set_log_level(modelbox.Log.Level)设置日志级别。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/debug/profiling.html":{"url":"develop/debug/profiling.html","title":"性能优化","keywords":"","body":"性能统计 ModelBox提供了统计功能单元，以及运行任务的时间统计功能，开发者或维护人员可以开启性能统计功能，对功能单元或运行状态进行调试和维护。 性能统计操作流程 配置流程图。 配置文件中指定启动profiling。 运行流程图。 获取统计信息。 chrome浏览器打开chrome://tracing/。 优化代码，重新分析。 性能满足要求后，结束。 启用性能统计 启动ModelBox的性能统计功能，只需要在Flow的toml配置文件中增加如下配置，即可启用。 [profile] profile=true # 启用profile trace=true # 启用traceing dir=\"/tmp/modelbox/perf\" # 设置跟踪文件路径 通过配置profile和trace开关启用性能统计，dir配置存储跟踪文件路径；配置启动后，启动运行流程图，profile会每隔60s记录一次统计信息，trace会在任务执行过程中和结束时，输出统计信息。 显示性能统计 运行流程图后，会周期生成timeline性能相关的json文件，通过将json文件加载到chrome trace viewer中即可查看timeline信息。 打开chrome浏览器。 浏览器中输入chrome://tracing/。 点击界面中的Load按钮，加载trace的json文件。 加载成功后，将看到类似下面的timeline视图。视图提供了选择统计、平移、缩放、时间间隔等基本功能可用于分析性能瓶颈 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/device/device.html":{"url":"develop/device/device.html","title":"设备接口","keywords":"","body":"设备接口 ModelBox支持多种设备的编程，其中包括对Huawei Ascend，Nvidia Cuda的支持，这两种设备都有流水线接口，即Stream接口。为使用Stream接口，在开发功能单元时，需要实现和设备相关的功能单元，具体链接如下： 设备 说明 链接 Ascend Huawei Ascend 链接 Cuda Nvidia Cuda 链接 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/device/ascend.html":{"url":"develop/device/ascend.html","title":"Ascend","keywords":"","body":"Ascend卡 Huawei Ascend ACL支持接口编程，ACL接口相关的介绍，请点击此处 ModelBox为更好的支持Stream并发编程，默认情况下，ModelBox的Ascend ACL接口全部采用Stream模式，开发者需要在编程时，使用Ascend ACL的Stream接口以提升性能。 Ascend ACL功能单元接口 ModelBox框架会自动管理Stream，开发功能单元时，开发者可以通过Process的入参获取到Stream，之后可以用于ACL接口的调用中。 在实现功能单元之前，Ascend ACL相关的功能单元，需要从AscendFlowUnit派生，并实现AscendProcess接口。 class SomeAscendFlowUnit : public modelbox::AscendFlowUnit { public: SomeAscendFlowUnit() = default; virtual ~SomeAscendFlowUnit() = default; // 数据处理接口，需要实现AscendProcess，第二个参数为Ascend ACL Stream。 virtual modelbox::Status AscendProcess(std::shared_ptr data_ctx, aclrtStream stream); }; 除AscendProcess以外，其他接口和通用功能单元一致，AscendProcess接口如下： modelbox::Status ColorTransposeFlowUnit::AscendProcess( std::shared_ptr data_ctx, aclrtStream stream) { auto inputs = ctx->Input(\"input\"); auto outputs = ctx->Output(\"output\"); // 申请内存 std::vector data_size_list(1, 2, 3); outputs->Build(data_size_list); // 循环处理每个输入数据，并产生相关的输出结果。 for (size_t i = 0; i Size(); ++i) { // 获取数据元数据信息 auto meta = inputs[i].Get(\"Meta\", \"Default\"); // 获取输入，输出的内存指针。输入为const只读数据，输出为可写入数据。 auto input_data = inputs[i].ConstData(); auto output_data = outputs[i].MutableData(); // 使用Stream处理数据 // aclmdlExecuteAsync(model_id_, input.get(), output.get(), stream); // 设置输出Meta outputs[i].Set(\"Meta\", \"Meta Data\"); } return modelbox::STATUS_OK; } 数据处理时，Ascend Stream会自动由ModelBox框架生成，再调用Ascend ACL接口时，直接使用此Stream对象即可。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"develop/device/cuda.html":{"url":"develop/device/cuda.html","title":"Nvidia Cuda","keywords":"","body":"Nvidia Cuda显卡 Nvidia Cuda支持stream并发编程，什么是stream可参考此处 ModelBox为更好的支持Stream并发编程，默认情况下，ModelBox的Cuda接口全部采用Stream模式，开发者需要在编程时，使用Cuda的Stream接口以提升性能。 Cuda功能单元接口 ModelBox框架会自动管理Stream，开发功能单元时，开发者可以通过process的入参获取到Stream，之后可以用于Cuda接口的调用中。 在实现功能单元之前，cuda相关的功能单元，需要从CudaFlowUnit派生，并实现CudaProcess接口。 class SomeCudaFlowUnit : public modelbox::CudaFlowUnit { public: SomeCudaFlowUnit() = default; virtual ~SomeCudaFlowUnit() = default; // 数据处理接口，需要实现CudaProcess，第二个参数为Cuda Stream。 virtual modelbox::Status CudaProcess(std::shared_ptr data_ctx,cudaStream_t stream); }; 除CudaProcess以外，其他接口和通用功能单元一致，CudaProcess接口如下： modelbox::Status ColorTransposeFlowUnit::CudaProcess( std::shared_ptr data_ctx, cudaStream_t stream) { auto inputs = ctx->Input(\"input\"); auto outputs = ctx->Output(\"output\"); // 申请内存 std::vector data_size_list(1, 2, 3); outputs->Build(data_size_list); // 循环处理每个输入数据，并产生相关的输出结果。 for (size_t i = 0; i Size(); ++i) { // 获取数据元数据信息 auto meta = inputs[i].Get(\"Meta\", \"Default\"); // 获取输入，输出的内存指针。输入为const只读数据，输出为可写入数据。 auto input_data = inputs[i].ConstData(); auto output_data = outputs[i].MutableData(); // 使用Stream处理数据 // kernel3 >> ( …, … ) ; // 设置输出Meta outputs[i].Set(\"Meta\", \"Meta Data\"); } return modelbox::STATUS_OK; } 数据处理时，Stream会自动由ModelBox框架生成，再调用Cuda接口时，直接使用此Stream对象即可。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"solution/solution.html":{"url":"solution/solution.html","title":"案例","keywords":"","body":"ModelBox 推理案例 ModelBox同时也提供了一些推理的案例 案例名称 案例图例 案例链接 车辆检测 车辆检测案例 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"solution/car-detect.html":{"url":"solution/car-detect.html","title":"车辆检测","keywords":"","body":"车辆检测 流程图 车牌检测流程如下图所示，video_input 功能单元接收视频流，往下分别经过 videodemuxer和videodecoder功能单元，videodecoder功能单元输出image，image经过前处理，包含resize、normalize之后，送给模型（car_inference是一个yolov3模型），模型将推理得到的bbox结果传入后续的后处理功能单元进行处理（car_yolobox），可得到 最终的bbox框，将bbox框和videodecoder出来的image一同送入draw_bbox中，将绘制完bbox的image传入videoencoder，即得到带有检测框的视频。 上述提到的各个节点，在ModelBox中称为功能单元，模型图中的一个节点，编排功能单元构建运行图，运行图在ModelBox中的呈现形式为 toml文件。车辆检测运行toml文件内容如下： [driver] dir = [\"drivers\"] [log] level = \"INFO\" [graph] format = \"graphviz\" graphconf = \"\"\"digraph vehicle_detection { node [shape=Mrecord] video_input[type=flowunit, flowunit=video_input, device=cpu, deviceid=0, source_url=\"@SOLUTION_VIDEO_DIR@/test_video_vehicle.mp4\"] videodemuxer[type=flowunit, flowunit=video_demuxer, device=cpu, deviceid=0] videodecoder[type=flowunit, flowunit=video_decoder, device=cpu, deviceid=0, queue_size=16, batch_size=5, pix_fmt=rgb] frame_resize[type=flowunit, flowunit=resize, device=cpu, deviceid=0, queue_size=16, batch_size=5, interpolation=inter_nearest, image_height=480, image_width=800] car_color_transpose[type=flowunit, flowunit=packed_planar_transpose, device=cpu, deviceid=0, queue_size=16, batch=5] car_normalize[type=flowunit, flowunit=normalize, device=cpu, deviceid=0, queue_size=16, batch_size=5, standard_deviation_inverse=\"0.003921568627451, 0.003921568627451, 0.003921568627451\"] car_inference[type=flowunit, flowunit=car_inference, device=cuda, deviceid=0, queue_size=16, batch_size=5] car_yolobox[type=flowunit, flowunit=car_yolobox, device=cpu, deviceid=0, queue_size=16, batch_size=5, image_height=1080, image_width=1920] draw_bbox[type=flowunit, flowunit=draw_bbox, device=cpu, deviceid=0, queue_size=16, batch_size=5] videoencoder[type=flowunit, flowunit=video_encoder, device=cpu, deviceid=0, queue_size=16, encoder=mpeg4, default_dest_url=\"rtsp://localhost/test\"] video_input:out_video_url -> videodemuxer:in_video_url videodemuxer:out_video_packet -> videodecoder:in_video_packet videodecoder:out_video_frame -> frame_resize:in_image videodecoder:out_video_frame -> draw_bbox:in_image frame_resize:out_image -> car_color_transpose:in_image car_color_transpose:out_image -> car_normalize:in_data car_normalize:out_data -> car_inference:data car_inference:\"layer15-conv\" -> car_yolobox:\"layer15-conv\" car_inference:\"layer22-conv\" -> car_yolobox:\"layer22-conv\" car_yolobox:Out_1 -> draw_bbox:in_region draw_bbox:out_image -> videoencoder:in_video_frame }\"\"\" toml构建图，定义节点和构建节点之间关系即可完成。输入配置在video_input中source_url中配置实际的视频所在路径，输出通过videoencoder输出rtsp流。 其中，[dirver]中dir的路径为，图中功能单元的so包或toml配置文件所在路径。 功能单元 推理功能单元配置如下： [base] name = \"car_inference\" device = \"cuda\" version = \"1.1.2\" description = \"a day car detection inference flowunit\" entry = \"./vehicle_detection.engine\" type = \"inference\" virtual_type = \"tensorrt\" [config] plugin = \"yolo\" #预置yolov3自定义插件 [input] [input.input1] name = \"data\" type = \"float\" [output] [output.output1] name = \"layer15-conv\" type = \"float\" [output.output2] name = \"layer22-conv\" type = \"float\" 运行示例 用ModelBox的modelbox-tool命令，可以启动运行图。命令如下： modelbox-tool -verbose flow -run car_detection.toml 其中vehicle_detection.toml即为车牌检测的运行图，shell命令中为实际路径，运行环境中安装好EasyDarwin软件后，将 rtsp://localhost/video（localhost为你的ip）复制到网页中，即可打开浏览器，查看最后结果，示例结果如下： ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"framework-conception/framework-conception.html":{"url":"framework-conception/framework-conception.html","title":"基本概念","keywords":"","body":"基本概念 ModelBox为更好的支撑应用流程，抽象了许多概念，理解这些概念对于应用问题的解决将会有很大帮助。 本章节主要从下图中的几个概念对ModelBox进行讲解，它们是ModelBox中十分重要的概念，开发者将时刻与它们打交道。 数据经由INPUT Node产生，按箭头指向，流向Process Node，Process Node处理数据后，在发送给Sink Node汇总处理结果，这是一个典型的数据处理过程，这个过程中，涉及到了图(Graph)、节点(Node)、端口(Port)、数据流(Stream)、数据缓存(Buffer)。 Graph 图定义了ModelBox的执行过程，ModelBox根据图中指示的路径，调度Node的功能，处理Buffer数据。图的详细说明可阅读图章节的内容。 Flow 一个图构建完成后就是一个flow， 一个flow由多个node相连接构成。 Node 图的基本组成，是功能单元在图中的实例化，和输入、输出Port一起组成了数据的处理实体。不同Node间由边(edge)连接，边是有向的。node也是数据流中的节点。node作为实际的数据处理单元，集成了flowunit、device管理、内存管理、端口管理等功能。 功能单元的详细说明可阅读功能单元的内容。 Driver 功能单元的实现单元。实现的具体的功能单元是作为driver加载在ModelBox中的。ModelBox服务在启动的时候，会加载指定目录下的所有的功能单元，作为driver库并管理。 Port 节点上的数据连接点，可用于数据的输入或者输出，在图中两个Node之间的连接需要指定Port。 Flowunit driver是功能的抽象，那么flowunit就是功能的具体实现。当扫描完所有的driver之后，ModelBox会读取toml文件中的配置，通过flowunit_name以及配置创建driver抽象的实例，这个实例就称之为flowunit。根据不同的配置及配置参数，实现了不同的功能。当然除了创建实例的基本功能之外，还增加了一些例如内存管理、端口管理、设备管理等功能，详情请前往flowunit和device的页面查看。 Stream 一系列关联的顺序数据实体组成了数据流，在ModelBox中数据流是主要处理对象，比如视频流，音频数据流等。数据流的详细说明可阅读Stream流的内容。 Buffer 流中包含多个数据实体，单个数据实体在ModelBox中由buffer承载。单个buffer包含了数据的元数据Meta部分和数据内容部分，它是数据在Node间的流动实体。Buffer的详细说明可阅读Buffer的内容。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"framework-conception/graph.html":{"url":"framework-conception/graph.html","title":"图","keywords":"","body":"图 在ModelBox中由多个flowunit进行连接构成的实际业务的执行集合就是图。图是ModelBox的主要组件，其数据处理过程，完全按照图中的拓扑关系进行。之前已经介绍过图的基本使用，本章主要介绍图的连接约束，图的加载方式，图的执行原理及优先级。 图的连接约束 输入输出的约束 ModelBox中的图至少需要包含两种flowunit：source flowunit，sink flowunit。 source flowunit： 有输出无输入，如input，videoinput，httpserver_sync_receive和httpserver_async_receive。 sink flowunit： 有输入无输出，如output，httpserver_sync_reply和httpserver_async_reply。 ModelBox的图只能有一个source flowunit，这里主要是因为ModelBox中的运行的数据需要匹配，如果数据源是不同的，则其中的数据不一定能匹配。比如写了两个httpserver_sync_receive的flowunit，则会启动两个http服务来接受不同的请求，但无法确定两边的请求数量是否完全一致，如数量不一致时会出现无法匹配的情况，导致图中的数据无法正常运行。这里存在一个例外，即一个图中input flowunit是可以有多个的，因为对其输入做了强制匹配的要求，即多个input输入的buffer的数量必须是一样多的。 ModelBox的图可以有多个sink flowunit，如可以使用多个output flowunit，默认情况下，多个output flowunit的输出是匹配的。如果输出的部分不匹配则需要在output的节点的配置上增加output_type=unmatch的配置 回路的约束 ModelBox的图不支持出现回路的情况，因为回路会导致数据会循环流动而无法消耗。 匹配的约束 ModelBox的图在拼接时会检查图中的节点的输入边的数据是否是匹配的。如果出现某个节点输入的边互相不匹配则会报告图非法。详细的图匹配规则如下所示： 在上图中，第一个数据流在经过通用flowunit后，其产生的数据流与之前输入的数据流是可以匹配的，因此其输入输出数据流都是流a。第二个数据流在经过流flowunit后，其产生的数据流与之前输入的数据流是不可以匹配的，因此输入的数据流是流a，而输出的数据流是流b，流a与流b之间是无法匹配的。当功能单元的开发者确认流flowunit的输入输出数据是一样多的时候，可以在流flowunit中SetStreamSameCount(true)，增加了这个配置以后则输入和输出的数据都是流a，可以匹配。 用户在开发时可以根据输入的流是否匹配来检查一下自己的图是否合法，在上图中左侧的图因为某一条边上加入了stream功能单元，产生了流b，流b与流a无法匹配，因此左图是一个非法图。将该stream功能单元SetStreamSameCount(true)后其输出的流恢复为流a,可以匹配。因此右图可以正常运行。 条件分支的约束 在图中有条件功能单元的情况下，主流不能与子流做匹配，只有等全部的子流聚合恢复为主流后才可以与主流进行匹配。子流和主流的关系在条件功能单元数据处理有更详细的介绍 如上图所示，在左图中经过条件功能单元后，主流a会产生分流a1和分流a2，分流a1和分流a2都只有主流a的部分数据，因此不可以与主流a直接进行匹配，因此左图是非法的。在右图中，分流a1和分流a2在最后的通用功能单元聚合后恢复成主流a，可以与主流a进行匹配，因此该图是合法的 同时条件功能单元不允许在子流上添加流Flowunit，因为流Flowunit会按照主流中的序号顺序运行，而在子流中会出现缺失序号顺序的情况。如下图所示： 左图是一个非法的图，因为其在condition功能单元后的一个分路上加入了一个流Flowunit。右图将其流Flowunit设置为通用的Flowunit后，图恢复为合法图 层级的约束 在图有层级的情况下，子层与父层之间不能直接进行匹配。需要先将子层归拢为父层之后才能进行匹配。关于子层与父层之间的关系在数据流层级有更详细的介绍 左图中父流a在通用Flowunit 2上与子流a1和子流a2是无法匹配的才，因此左图是非法的。在右图中，将子流a1和子流a2收拢成为父流a后即可以与通用功能单元的另一路父流a进行匹配，因此右图是合法的 图的加载过程 图的加载过程如下所示： 图的执行及优先级 在图被放入调度器后，调度器会按照拓扑结构对图进行优先级排序，即越靠近出口的节点的优先级越高，这样做的目的是为了保证现有的请求可以尽快的完成，而不至于在入口处累计过多的buffer造成内存或显存的浪费。节点的优先级如下图所示： 当图中的某个节点收到数据时，会触发调度器去使用一个线程去执行该节点的run函数，并处于running状态直到run函数执行完毕。当该节点处在running状态的时候，后续的收到的数据会填入该节点的接收队列，但并不会触发run函数，直到该节点执行完run函数。在run的过程中，数据会按照流或者batch切分成多份，放入不同的线程去执行。当线程数量不够时，高优先级的节点会优先放入待执行的队列中，已保证高优先节点可以更快的完成。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"framework-conception/flowunit.html":{"url":"framework-conception/flowunit.html","title":"功能单元","keywords":"","body":"功能单元 功能单元FlowUnit是ModelBox中处理数据的基本单元，可称之为流程单元，简称功能单元，功能单元的处理对象是数据流。在ModelBox中，功能单元根据数据处理需求差异划分为不同的类别，下面将从功能单元组成、加载、分类进行详细的讲解。 功能单元组成 功能单元是数据处理的基本功能单元，实现可以是多种语言和设备类型的。 功能单元可选的实体功能组件如下： 类型 设备类型 说明 开发指导 C++动态库 CPU 使用CPU执行的C++动态库 指导 C++动态库 Cuda 使用Cuda执行的C++动态库 指导 C++动态库 Ascend 使用Ascend执行的C++动态库 指导 Python模块 CPU 使用CPU执行的Python模块 指导 Python模块 Cuda 使用Cuda执行的Python模块 指导 Python模块 Ascend 使用Ascend执行的Python模块 指导 Java模块 CPU 使用CPU执行的Java模块 指导 推理 TensorRT 使用TensorRT推理框架的模型推理功能 指导 推理 TensorFlow 使用TensorFlow推理框架的模型推理功能 指导 ModelBox可根据图中的配置，加载对应的功能单元实体功能组件，在功能单元开发时，开发者也可以选择相关类型的功能单元实体进行开发。 加载运行流程 FlowUnit插件的加载流程如上图： 初始化过程 ModelBox模块先扫描插件目录。 对扫描到的插件，调用DriverDescription获取FlowUnit插件信息。信息包括功能单元名称，功能单元版本号，执行的硬件信息，描述信息，配置参数信息。 当启动Flow时，则调用插件的DriverInit初始化插件。 初始化插件完成后，调用CreateDriverFactor创建插件工厂类。 之后调用FLowUnitFactor::FlowUnitProbe获取FlowUnit信息，信息包括输入，输出参数。 初始化完成后，业务调用Flow初始化图。 在图初始化时，首先通过图中指定的FlowUnit名称选择对应的FlowUnit实例化，调用实例化对象的Flow::Open初始化FlowUnit对象。 图初始化完成后，若有数据达到，则调用当前节点实例的Flow::Process处理数据；若当前功能单元选择的类型是流，还会调用Flow::DataPre接口，再调用Flow::Process接口，流数据结束时，调用Flow::DataPost接口。 当图运行完成后，则调用Flow::Close接口关闭图。 整个Flow结束时，ModelBox模块卸载FlowUnit插件，调用插件的DriverFini函数清理资源。 分类 功能单元被按照多个维度进行了分类，不同纬度的分类在满足约束的情况下可以进行组合 维度一：按处理数据相关性分类 类别 类别说明 约束 常见的功能单元 需要重写的接口 通用功能单元 在处理数据时，功能单元本身不关心数据之间的关联，只对当前数据做处理，并且不记录任何状态，则选择该类型。设置为该类型时，其一次process调用处理的数据可能来自多个数据处理任务，且process会并发调用，同一个任务内的数据在此时不保证处理的先后，当然数据处理完毕后会由框架重新收集排序，无需关心当前功能单元对整个数据流后续的影响 输入buffer的数量必须与输出buffer的数量一致 resize, crop Process 流数据功能单元 在处理数据时，功能单元需假设每次process都是处理当前任务数据流的数据，针对当前数据流可能还需要保存状态，并且process在数据流上要保持顺序处理，此时应当选择流类型的功能单元。设置为该类型时，框架会保证一个数据流的数据会顺序的进入process，不通数据流的数据会并发进入process，开发者无需关心数据之前是否是有序的，在process此处，已经由框架保证顺序。 输入buffer的数量无需与输出buffer的数量一致 decoder, encoder DataPre, Process, DataPost 通用功能单元举例：通用功能单元是比较常见的单元，比如要实现用固定的长宽去Resize其输入，这个功能单元，每次执行Resize时，不关心其输入数据的关联，即单个流的顺序上，以及多个流的隔离，因此这个Resize功能单元是一个通用功能单元，处理时一个process可以接收多个流混合的数据，并且process在并发调用，后续的数据可能会与之前的数据一同进行处理。关于通用功能单元数据运行的详细说明可以参考通用功能单元数据处理。配置：配置功能单元为通用功能单元，需要在MODELBOX_FLOWUNIT中将desc配置为modelbox::NORMAL，默认情况下功能单元是通用功能单元，此时功能单元的输入与输出必须一致。 MODELBOX_FLOWUNIT(ResizeFlowUnit, desc) { desc.SetFlowUnitName(\"Resize\"); desc.AddFlowUnitInput(modelbox::FlowUnitInput(\"In_1\", \"cpu\")); desc.AddFlowUnitOutput(modelbox::FlowUnitOutput(\"Out_1\", \"cpu\")); desc.SetFlowType(modelbox::NORMAL); } 流数据功能单元 举例：流数据流数据处理的是需要关注数据是否来自同一个数据流，且同一个数据流的数据处理要有先后顺序。比如一个视频编码的功能单元，每次process处理时，都需要保证当前输入的数据来自同一个流，且可以获取到当前流的状态(编码器)，同时输入的数据都是顺序的，这样才能保证编码功能单元正确的对每一路流进行编码。因此这个视频编码功能单元必须设置为一个流数据功能单元。关于流数据功能单元数据运行的详细说明可以参考流数据功能单元数据处理。 配置：配置功能单元为流数据功能单元，需要在MODELBOX_FLOWUNIT中将desc配置为modelbox::STREAM。流数据功能单元输出的buffer数量不一定与输入的buffer数量一致，默认情况下，输出输入的的buffer数量是认为不一致的，因此也是无法匹配，如果需要两者匹配可以配置SetStreamSameCount(true)。 MODELBOX_FLOWUNIT(EncoderFlowUnit, desc) { desc.SetFlowUnitName(\"Encoder\"); desc.AddFlowUnitInput(modelbox::FlowUnitInput(\"In_1\", \"cpu\")); desc.AddFlowUnitOutput(modelbox::FlowUnitOutput(\"Out_1\", \"cpu\")); desc.SetStreamSameCount(false); desc.SetFlowType(modelbox::STREAM); } 维度二：按输出数据层级分类 关于数据流层级，请参考数据流章节 类别 类别说明 约束 常见的功能单元 同级功能单元 输出的数据与输入的数据属于同一层级 无 resize, crop, decoder, encoder 展开功能单元 输出的数据是输入数据的下一层级，展开功能单元将输入的每个Buffer展开为一个新的Stream，该Stream属于输入Stream下一级的Stream 输入只能是一个buffer，且必须有输出buffer demuxer 收拢功能单元 输出的数据是输入数据的上一层级，收拢功能单元是将输入Stream中的数据收齐后形成一个Buffer，该Buffer属于输入Stream上一级的Stream 输出只能是一个buffer enmuxer 展开功能单元 举例：在开发功能单元时，输入输出的数据有固定的要求，如Resize输入的是图片流，产生的也是图片流。这是同一层级的。视频解封装(demuxer)功能单元输入的是视频组成的流(流里面的每一个buffer都是一个视频)，产生的是每个视频产生的packet流，每个packet流属于一个视频。因此packet流是视频组成的流的下一层级，而视频解封装功能单元是一个展开功能单元。关于层级的说明可以参考数据流层级 配置：配置功能单元为展开功能单元,需要SetOutputType(modelbox::EXPAND)，在默认情况下OutputType是modelbox::ORGINE，表示功能单元是同级功能单元。 MODELBOX_FLOWUNIT(DemuxerFlowUnit, desc) { desc.SetFlowUnitName(\"Encoder\"); desc.AddFlowUnitInput(modelbox::FlowUnitInput(\"In_1\", \"cpu\")); desc.AddFlowUnitOutput(modelbox::FlowUnitOutput(\"Out_1\", \"cpu\")); desc.SetOutputType(modelbox::EXPAND); } 收拢功能单元 举例：与展开功能单元相对应的是收拢功能单元,视频封装(enmuxer)功能单元输入和输出与视频解封装刚好是反过来的，视频封装功能单元是一个收拢功能单元。关于层级的说明可以参考数据流层级 配置：配置功能单元为展开功能单元,需要SetOutputType(modelbox::COLLAPSE)。默认情况下流中的数据只要到达了就会立即处理，如果需要一次性取完放入process中处理，可以配置SetCollapseAll(true)来实现。 MODELBOX_FLOWUNIT(DemuxerFlowUnit, desc) { desc.SetFlowUnitName(\"Encoder\"); desc.AddFlowUnitInput(modelbox::FlowUnitInput(\"In_1\", \"cpu\")); desc.AddFlowUnitOutput(modelbox::FlowUnitOutput(\"Out_1\", \"cpu\")); desc.SetOutputType(modelbox::COLLAPSE); desc.SetCollapseAll(false); } 特例：条件功能单元 条件功能单元是通用功能单元中的一种，当一个功能单元的输出，在不同的条件下需要用不同的流程去处理时，就可以使用条件功能单元来完成数据流的分支选择，使得同一路流可以在不同的流程处理，关于条件功能单元的说明可以参考条件功能单元数据处理 配置：配置条件功能单元时，需要在MODELBOX_FLOWUNIT中将desc配置为modelbox::NORMAL，并且SetConditionType(modelbox::IF_ELSE) MODELBOX_FLOWUNIT(ConditionFlowUnit, desc) { desc.SetFlowUnitName(\"Condition\"); desc.AddFlowUnitInput(modelbox::FlowUnitInput(\"In_1\", \"cpu\")); desc.AddFlowUnitOutput(modelbox::FlowUnitOutput(\"Out_1\", \"cpu\")); desc.SetFlowType(modelbox::NORMAL); desc.SetConditionType(modelbox::IF_ELSE); } 注：使用条件功能单元时，必须配置当前功能单元batch_size= 1 功能单元类别与接口说明 类别 类别说明 需要重写的接口 同级通用功能单元 输入输出的数据是同一级别的，输入的数据不会排序，直接放入Process中 Process 同级流数据功能单元 输入输出的数据是同一级别的，流开始会调用DataPre,流结束会调用DataPost，输入的数据会排序后放入Process中 DataPre, Process, DataPost 展开通用功能单元 输出的数据是输入数据的下一层级，输入的数据不会排序直接放入Process中 Process 展开数据流功能单元 输出的数据是输入数据的下一层级，流开始会调用DataPre,流结束会调用DataPost，输入的数据会排序后放入Process中 DataPre, Process, DataPost 收拢通用功能单元 输出的数据是输入数据的上一层级，流开始会调用DataPre,流结束会调用DataPost，输入的数据会会排序后放入Process中。两个流之间不会按照输入的顺序排序 DataPre, Process, DataPost 收拢数据流功能单元 输出的数据是输入数据的上一层级，流开始会调用DataPre,流结束会调用DataPost，输入的数据会排序后放入Process中。流之间会按照输入的顺序排序调用，在所有流开始之前会调用DataGroupPre,在所有的流结束之后会调用DataGroupPost DataGroupPre, DataPre, Process, DataPost, DataGroupPost 按业务类型分类 按业务区分功能单元，功能单元的分类大致如下 类别 类别说明 例子 输入类功能单元 数据输入类功能组件，输入数据使用 http, filereader, obs等 输出类功能单元 数据输出类功能组件，输出数据使用 http, filewriter, obs等 图像类功能单元 处理单个图像数据的功能组件，处理图像使用 resize, brightness等 视频类功能单元 处理视频数据的功能组件 demutex, decode, encode等 推理类功能单元 调用推理功能进行推理的组件 tensorrt, tensorflow等 预处理、后处理功能单元 对tensor数据进行处理。 normalize, mean等 功能单元类型样例 下图以车辆检测为例子说明涉及到功能单元类型 例子 车辆跟踪推理DEMO，当发现车辆时，对车辆画框图提示。 Flow流程图 流程说明： 将文件数据发送给VideoDemux，VideoDemux将数据解开packet后发送给VideoDecoder。 VideoDecode获取packet并解码为图像。 图像数据分别发送到两个流程，一个发送给ImageResize，一个发送给ImageRender。 ImageResize将图像数据进行resize。 resize后的图像，发送给CarDetect进行模型推理。 推理后的数据发送给Box进行框信息处理。 Box输出框信息。 ImageRender接收两路输入，图像和框图信息，并对图像进行画框。 画框后的图像，输出到编码器VideoEncoder。 VideoEncode对图像进行编码，并发送给RTSP服务器。 流程上，使用了8个功能单元，1个是输入类，3个是处理流数据的视频功能单元，其他是图像处理和推理类的通用功能单元。 上图流程的涉及的功能单元列表以及类别 功能单元名称 功能 功能分类 业务分类 解释 File Reader 读取数据文件 流数据拆分类 输入类 输入是一个URL，输出是一个文件流。 Video Demux 解数据封包 流数据类 视频类 输入是文件流，输出是一组连续的packet流。 Video Decoder 视频解码 流数据类 视频类 输入是packet流，输出是独立的图像数据。 Image Resize 图像大小调整 通用类 图像类 输入是一张图像，输出也是一张图像。 Car Detect 车辆推理 通用类 推理类 输入是Tensor，输出是Tensor。 Box 框选取 通用类 后处理类 输入是Tensor，输出是框信息。 Image Render 合并框图信息 通用类 图像类 输入是两组数据，图像和框图，输出是图像。 Video Encoder 视频编码 流数据类 视频类 输入是多张图像，输出是一个视频流。 要查阅ModelBox所有预置的功能单元，请参考FlowUnits章节。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"framework-conception/stream.html":{"url":"framework-conception/stream.html","title":"数据流","keywords":"","body":"stream流 Stream流数据是一组顺序、连续到达的数据序列。ModelBox支持各种流数据的处理，包括视频，音频，文件，结构化数据。 ModelBox中的流有如下属性： stream特点 保序的 流中的数据只能按照顺序处理，处理完成后的结果，要将按照顺序输出。 分段处理的。 流中的每个数据可以在处理逻辑上组成一个BufferList，每个BufferList都可以单独处理。 连续的。 流中的每个数据都是连续的，不能中断，也不能将流中的数据在图中执行不同的分支流程。 stream结构 ModelBox中流数据由Buffer组成，其结构如下： Buffer是组成stream的基本单位。 BufferList是一个逻辑概念，主要用于批量处理一组Buffer数据。 N(0 在stream中buffer有序号，标明buffer在流中的位置，位置是在流产生时决定的。 每个Buffer包含一个Meta结构，记录Buffer信息。 每个Stream包含一个Meta结构，记录Stream信息。 流的基本处理 流数据经过不同的功能单元处理后，可以匹配，产生兄弟流，聚合，展开，收拢。 匹配 为什么需要匹配 如上图所示，Source功能单元功能是产生图片，Inference功能单元的功能是输入图片输出图片中包含人的框，ColorTranspose功能单元的功能是将图片颜色进行变换，输入是图片输出也是图片，DrawBox功能单元的功能是输入图片和框，输出画了框的图片。在上图中，浅绿色表示图片，深绿色表示多个框的集合。在图-A中，每个端口的输入是单一明确的。在图-B中Inference功能单元输出的每一个buffer都是图片和多个框的集合的一个组合体。ColorTranspose功能单元的输入也必须是图片和多个框的集合组合成一个buffer，但ColorTranspose本身只处理组合体中的图片数据。而在图-A下ColorTranspose只需要处理图片数据即可。 但在图-A中需要解决框的集合和图片之间匹配的问题。 如何匹配 两个流匹配是基于流里面的buffer数量一致。 功能单元可能有多个端口作为输入，功能单元会将数据先进行匹配，匹配完成后将数据放入process中处理。在上图中，通用功能单元有first和second两个端口。first端口的数据先传入，second端口的数据后传入。则1-stream first端口进入时，功能单元会把buffer按照1 2 3 4顺序放入缓存但不会执行process，当second端口的数据传入后，匹配的数据完成匹配后才会放入process中执行，而产生的数据的顺序会按照first端口的顺序来排列。通用功能单元要求输入的流必须是一个流，而经过通用功能单元所产生的流与输入的流也必须是一个流。不同流之间的数据匹配是无关的，如上图中1-stream中的数据是可以互相匹配的，但是1-stream的数据与2-stream的数据是不能匹配的。 通用功能单元数据处理 如上图所示，1-stream和2-stream是两个流，经过同一个通用功能单元。 输入输出数量一致 通用功能单元的输入与输出的buffer数量必须一致，1-stream输入四个buffer，则输出也必须为四个buffer。1-stream经过通用功能单元产生的四个buffer还是在1-stream中，不会出现在2-stream中，因此对每个stream来说，可以认为其它的stream是不可见的。 按batch_size合并后输出 通用功能单元会按batch数量合并后由process处理。如上图所示，通用功能单元的batch_size设置为5,则通用功能单元会再将1-stream的数据填满后会取走2-stream的部分数据填满batch。如果剩下的数据无法填满batch，数据也会把剩下的所有数据聚合在下一个batch中处理。 条件功能单元数据处理 条件功能单元是一种特殊的通用功能单元，条件功能单元的输出必须大于1。条件功能单元其向每个端口的输出数量之和等于输入buffer的数量。如上图所示，1号 2号 3号 4号四个buffer经过条件功能单元A后，其上端口输出1 2 3 三个buffer，下端口输出4 一个buffer。但这两路数据都会被认为是1-stream流的一个部分流，部分流只能用通用功能单元处理，而不能用数据流功能单元处理。因为每一路数据中包含的流信息都是不完整的。部分流可以通过条件功能单元进一步切分成新的部分流。当将部分流的数据输入到一个通用功能单元的同一端口时，会产生聚合，即将输入的部分流聚合成条件功能单元输入时的流。如条件功能单元B产生的1-1-1-part-stream和1-1-2-part-stream最终由通用功能单元B聚合得到1-1-part-stream。注意部分流有层级结构，如图上所示1-1-1-part-stream只能与1-1-2-part-stream聚合，而不能与1-2-part-stream的部分流聚合，只有在聚合成1-1-part-stream的流后才能再进行聚合。 流数据功能单元数据处理 数据经过流处理功能单元会产生兄弟流。在单元数据在匹配后会先进行排序，如上图所示，1-stream的在进入流处理功能单元后会排序，然后放入同一个batch中由process处理,在流数据功能单元中不同的stream中的buffer会放入不同的batch中进行处理。在经过了流数据功能单元流处理后，会产生一个新的兄弟流，兄弟流在默认的情况下与前面的流不是一个流，无法匹配。但可以与可以通过设置SetStreamSameCount(true)来设置流处理单元输出的兄弟流与输入的流可以进行匹配。 流处理功能单元除了通常处理数据process函数，还会有其他一些函数也会在stream的开始和结束阶段被调用： 在处理流之前，会触发DataPre调用，这里可以用来申请资源，DataPre中可以设置下一个Stream的Meta信息，如图中2-stream的Meta信息。 当流中最后一个数据处理完成后，将会触发DataPost调用，这里可以用来释放资源。 数据流层级 数据流在业务中常常需要展开或收拢，如上图所示，main-stream中有两个buffer每个buffer表示一个视频流地址，而其后的图片普通功能单元处理的是多张图片组成的一个图片流，因此视频流地址需要展开为多张图片组成的一个流。展开功能单元主要就是用来完成将图中main-stream 的1 buffer展开成图片流1-stream，在图片普通功能单元处理后，如果需要收拢为图片流为视频流，可以通过收拢功能单元其还原成main-stream。 在展开功能单元中，process中输入的buffer每次只有一个。收拢功能单元接收下一层流时会排序，并对接收到的每个流都会触发Datapre和DataPost调用。一个流经过收拢后最终会产生一个上级流的buffer。 展开功能单元和收拢功能单元也可以分为通用展开功能单元，数据流展开功能单元，通用收拢功能单元，数据流收拢功能单元。如上图所示：通用展开功能单元和数据流展开功能单元的区别在于，在展开时，数据流展开功能单元如图-A所示，在展开完1-stream后才可以展开2-stream。通用展开功能单元会如图-B所示，会同时展开1-stream和2-stream。数据流收拢功能单元则会在1-stream收拢完后才会2-stream，通用收拢功能单元会同时收拢1-stream和2-stream。 如图-B所示，数据流收拢功能单元在所有的子流收拢之前会调用DataGroupPre，在所有的子流收拢之后则会调用DataGroupPost 展开归拢 VS 产生一个兄弟流 展开表现为由一个buffer产生多个buffer。但是由一个buffer产生多个buffer并不一定是展开。同样,归拢表现为由多个buffer合成一个buffer，但是由多个buffer合成一个buffer并不一定是归拢。展开和归拢限定于将一个buffer展开成一个完整的流和将一个流里全部的buffer合成为一个buffer。比如，一个长视频可以展开为N(0 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"framework-conception/buffer.html":{"url":"framework-conception/buffer.html","title":"Buffer","keywords":"","body":"Buffer Buffer是ModelBox中功能单元之前传递数据的唯一载体。采用Buffer进行传递的主要原因是功能单元会运行在多种设备上，因此当前功能单元实现时，不应假设其之前或者之后的功能单元所使用的内存属于哪一个设备，当前功能单元只需要指明其输入所期望的设备是什么，由框架完成数据的搬移工作，以降低功能单元的连接限制。 Buffer与数据的传递 在ModelBox的功能单元开发中，Buffer作为功能单元的输入或者输出数据的载体出现，对其使用的了解是基于ModelBox开发的基本要求，同时了解其如何承载数据、数据的存储规范对于更好的开发功能单元将会有很大帮助。 功能单元进行数据处理时，其process将要对输入数据完成操作，并产生输出，这个过程中，用户将从DataContext中获取到本次需要处理的数据。ModelBox根据如下因素的影响来决定本次需要处理的数据： 当前节点存在一个输入队列，用来存放最近未处理的数据，其长度可以通过配置进行设定。 当节点触发调用运行时，会将队列中的数据全部取出，准备进行处理。 数据取出后，调用process处理时，存在batch_size的选项，即每次process最多可以处理的数据量。框架根据batch_size和功能单元的类型对数据进行划分，同时将数据搬移到功能单元指定的输入设备上，最终决定了process调用的次数，以及每次process调用时的数据数量。 在功能单元开发者的process函数看到的输入BufferList便是在框架中完成了拆分后本次process需要处理的数据列表，列表满足的约束请参考功能单元章节。 输出数据时，首先要从DataContext中取出的输出BufferList，然后进行BufferList的Build，或者在创建Buffer时使用GetBindDevice，这两个操作都会为输出的内存指定设备，保证输出的数据分配在指定的设备上。 Buffer的约束 作为输入数据时，不应当对当前内存进行修改，因此对象内存已被标记未数据不可修改的状态，此时读取数据需要使用ConstData来获得数据指针。 作为输出数据时，buffer的持有者唯一，它是可以写入的，需要调用MutableData返回数据指针，并对其进行写入。 数据主体应当存放于Buffer里获取的数据指针所指向的存储空间，对于当前数据的描述信息即元数据则需要存放在Buffer->Set中，因为这类元信息是与设备无关的，只需要一直保存在主机内存里即可。 Buffer常用接口介绍 以下列表展现了较为常用的Buffer的成员函数。 函数名称 返回值类型 函数功能 MutableData() void* 获取buffer可变数据的指针 ConstData() const const void* 获取buffer常量数据的指针 GetBytes() const size_t 获取buffer的字节大小 Get(const std::string& key) std::tuple 根据meta的键获取相对应的值 GetDevice() std::shared_ptr 返回buffer所对应的设备 Get(const std::string& key, T&& value) bool 在buffer中是否存在meta的key值 Set(const std::string& key, T&& value) void 给buffer设置meta的键值对 CopyMeta(const std::shared_ptr buf, bool is_override = false) Status 复制buf的meta值 Copy() std::shared_ptr buffer的浅拷贝 DeepCopy() std::shared_ptr buffer的深拷贝 BufferList BufferList是Buffer的vector集合。ModelBox提供了完备的api，可以简单地批量修改Buffer。 其中，BufferList->At(idx)可直接用BufferList[idx]代替。 函数名称 返回值类型 函数功能 MutableData() void* 获取bufferList首个buffer的可变数据的指针 ConstData() const void* 获取bufferList首个buffer的常量数据的指针 MutableBufferData(size_t idx) void* 获取bufferList首个buffer的可变数据的指针 ConstBufferData(size_t idx) const const void* 获取bufferList首个buffer的常量数据的指针 GetBytes() size_t 获取bufferList的字节大小 Size() size_t 获取bufferList的长度 GetDevice() std::shared_ptr 返回bufferList的首个buffer所对应的设备 At(size_t idx) std::shared_ptr 根据索引值 返回此处的buffer PushBack(const std::shared_ptr& buf) void 将新的buffer加入到bufferList末尾 Set(const std::string& key, T&& value) void 给bufferList中所有buffer设置相同的meta键值对 CopyMeta(const std::shared_ptr bufferList, bool is_override = false) Status 复制传入函数中的另一个bufferList的meta值 MakeContiguous() Status 使bufferList在显存或者内存中连续 Reset() Status 清空bufferList ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"compile/compile.html":{"url":"compile/compile.html","title":"编译安装","keywords":"","body":"编译安装 ModelBox框架采用C++语言编写，工程编译软件是CMake，本文主要讲解ModelBox源代码的编译过程。 如基于ModelBox开发AI应用，推荐使用现有ModelBox镜像开发，避免从源代码构建ModelBox。 编译依赖准备 在编译ModelBox之前，需要满足如下要求。 类别 依赖 依赖说明 最低版本 推荐版本 是否必须 相关组件 编译器 gcc gcc编译器 4.8 7.x 是 所有 编译器 g++ g++编译器 4.8 7.x 是 所有 编译器 CMake CMake工具 2.9 3.5 是 所有 OS Linux Linux操作系统 ubuntu16.04, centOS 7.2 ubuntu 18.04 是 所有 运行时 nodejs 前端编译 10.x V12.x 否 前端Editor 运行时 python python编译 3.x 3.8 否 python支持 开发库 cuda cuda支持 10.0 10.1 否 cuda支持 开发库 ascend Ascend支持 否 ascend支持 开发库 ffmpeg 视频解码编码支持 否 视频相关功能 开发库 tensorrt tensorrt模型推理 否 tensorrt相关的模型推理功能 开发库 tensorflow tensorflow推理支持 否 tensorflow相关的模型推理功能 开发库 cpprest http服务支持 是 modelbox-server以及http相关的功能组件 上述依赖可按需求选择，其中是否必须为“是”的依赖，必须要安装到编译环境中才能正常编译代码。如果使用基于镜像的开发环境，可以省去这一步。 基于Docker开发镜像 ModelBox项目提供了docker镜像，里面包含了ModelBox编译运行所需的组件及预先安装的ModelBox，可以优先选择docker镜像进行应用的开发编译。 关于容器镜像的使用，可参考容器镜像使用的内容。 基于当前操作系统安装 如果不想下载开发镜像，那么也可按上述依赖列表，自行基于当前操作系统进行安装。 ubuntu操作系统 apt update apt install build-essential unzip ffmpeg cmake apt install python3-setuptools python3-wheel python3-numpy python3-opencv python3-pip apt install libssl-dev libcpprest-dev python3-dev libswscale-dev libavformat-dev graphviz-dev centos操作系统 yum update yum install ffmpeg cmake libcpprest 编译和安装 准备 编译ModelBox之前，需要准备好开发环境。或在镜像中进行编译，或按上述依赖列表，安装相应的依赖组件。 下载ModelBox代码 git clone https://github.com/modelbox-ai/modelbox.git cd modelbox 或者： git clone https://gitee.com/modelbox/modelbox.git cd modelbox 执行cmake创建编译工作区 mkdir build cd build cmake .. -DUSE_CN_MIRROR=yes：在编译过程中，还需要下载第三方依赖，请保持网络能正常连接第三方服务器，如在国内无法下载以来，可以增加此cmake参数，从国内镜像下载依赖。 -DLOCAL_PACKAGE_PATH：若本地已经有依赖的第三方软件包，则可以使用此参数指定本地依赖包路径，若使用ModelBox编译镜像时，编译镜像的/opt/thirdparty/source已经有相关依赖包，可直接指定本地路径使用，若需要从公共源码仓下载，则无需指定此参数，但需要确保网络通畅。 如需编译release版本，可以执行如下cmake命令 cmake -DCMAKE_BUILD_TYPE=Release .. 如需进行断点调试，则应编译debug版本，可以执行如下cmake命令 cmake -DCMAKE_BUILD_TYPE=Debug .. 编译安装包 make package -j16 编译完成后，将在release目录下生成对应的安装包。 安装 ModelBox编译完成后，将生成配套OS安装的安装包，如deb、rpm包和tar.gz包，路径为编译目录的release子目录。可根据使用需求进行安装，下表是软件包的用途对照表。 安装包功能对照表 类型 名称 说明 运行库 modelbox-x.x.x-Linux-libmodelbox.[deb|rpm] ModelBox核心运行库。 运行库 modelbox-x.x.x-Linux-graph-graphviz.[deb|rpm] 图解析组件。 服务组件 modelbox-x.x.x-Linux-server.[deb|rpm] ModelBox Server服务组件。 运行库 modelbox-x.x.x-Linux-ascend-device-flowunit.[deb|rpm] Ascend设备SDK以及配套基础功能单元组件。 运行库 modelbox-x.x.x-Linux-cpu-device-flowunit.[deb|rpm] Cuda设备SDK以及配套基础功能单元组件。 运行库 modelbox-x.x.x-Linux-cuda-device-flowunit.[deb|rpm] CPU设备SDK以及配套基础功能单元组件。 开发库 modelbox-x.x.x-Linux-libmodelbox-devel.[deb|rpm] ModelBox开发库。 开发库 modelbox-x.x.x-Linux-server-devel.[deb|rpm] ModelBox Server服务插件开发库。 开发库 modelbox-x.x.x-Linux-ascend-device-flowunit-devel.[deb|rpm] Ascend设备开发库。 开发库 modelbox-x.x.x-Linux-cpu-device-flowunit-devel.[deb|rpm] CPU开发包。 开发库 modelbox-x.x.x-Linux-cuda-device-flowunit-devel.[deb|rpm] Cuda设备开发库。 手册 modelbox-x.x.x-Linux-document.deb.[deb|rpm] 开发手册，包含API说明。 WebUI modelbox-x.x.x-Linux-modelbox-webui.[deb|rpm] 编排界面。 运行库 modelbox-x.x.x-py3-none-any.whl python wheel包。 全量包 modelbox-x.x.x-Linux.tar.gz 全量安装包，包括上述所有组件。 安装包说明 modelbox运行库，cpu运行库，graphviz图解析组件必须安装。 ascend设备组件，cuda设备组件，可根据硬件配置情况合理安装。 modelbox-server服务组件，推荐安装。 modelbox-x.x.x-py3-none-any.whl在需要python运行时安装。 modelbox-x.x.x-Linux.tar.gz可解压直接使用。推荐使用安装包，方便管理。 安装命令说明 debian安装包 sudo dpkg -i *.deb rpm安装包 sudo rpm -i *.rpm python wheel包 pip install *.whl tar.gz包的使用。（可选，如果已经安装了deb|rpm包，则可不用安装tar.gz包） tar xf modelbox-x.x.x-Linux.tar.gz 将解压后的目录，复制到/目录，此步骤可选。 cd modelbox cp * / -avf 若未选择上述步骤，未复制modelbox文件到/目录，则需要将/lib/systemd/system/modelbox.service中文件修改为对应的解压目录 ExecStart=[path/to]/modelbox -p /var/run/modelbox.pid -c [path/to]/modelbox.conf 将上述路径[[path/to]修改为对应解压后的路径。然后执行如下命令 cp modelbox.service /lib/systemd/system/modelbox.service systemctl daemon-reload 启动服务 如安装了modelbox-x.x.x-Linux-server，可以使用下述命令启动服务 systemctl enable modelbox systemctl start modelbox 关于ModelBox Server服务的配置，请查阅运行服务章节 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/api.html":{"url":"api/api.html","title":"API","keywords":"","body":"API ModelBox API包括了多种编程语言，有C++，python，具体API的支持范围如下： 请选择合适的开发语言进行扩展。 类型 说明 C++ Python ModelBox Server Plugin ModelBox微服务插件。 ✔️ ❌ ModelBox Library ModelBox开发API。 ✔️ ✔️(不包含基础组件) ModelBox FlowUnit ModelBox功能单元开发API。 ✔️ ✔️ ModelBox Device 设备支持开发API。 ✔️ ❌ 下面具体说明各个组件的API组件信息。 ModelBox Server Plugin ModelBox微服务插件，提供了开发为服务必要的API接口，对应的周边组件如下： ModelBox插件可以调用的接口有： Job: 任务管理，可以添加，删除，查询图以及对应的任务。 Config：配置读取，可以从ModelBox Server的配置文件/usr/local/etc/modelbox/modelbox.conf中读取配置项。 Listener: http server，可以注册HTTP请求的URL事件。 Timer: 定时器，可以注册定时任务，定时触发特定的函数。 ModelBox Library: ModelBox运行库的所有API。 ModelBox Library ModelBox运行库，提供了对业务开发需要的API接口，对应的周边组件如下： ModelBox Library包含基础Base部分和功能部分。基础部分用于支撑业务的运行，功能部分用于支撑AI推理的运行。 基础Base 基础Base，包含了各种支撑业务运行的组件，包括如下组件： BlockingQueue，阻塞队列。 Config，图配置读取。 Crypto，数据加解密。 Status，错误返回接口。 Utils，工具函数。 Device， 设备抽象接口。 Timer，定时器组件。 ThreadPool，线程池组件。 Log，日志组件。 Slab，Slab内存缓存组件。 OS Adapter API，OS抽象接口 Driver，ModelBox插件接口。 注意：python仅包含Log, Status, Config组件接口。 ModelBox推理接口 推理接口包含运行推理任务，和编写功能单元的模块，包括如下组件 Buffer: 数据接口，用于承载AI推理数据。 Flow，推理启动接口，用于加载编排图，并启动推理任务。 FlowUnit，功能单元接口，用于扩展新的功能单元组件。 TensorList，Buffer操作接口，支持使用Tensor相关的接口操作Buffer。 DataContext，支持FLowUint功能单元开发的接口，用于获取功能单元的输入，输出，和上下文的存储。 Session，会话上下文，用于开发存储和会话相关的信息。 Statistics，统计接口，用于统计，获取相关组件的统计信息。 注意：python仅包含Buffer, Flow, Flowunit, tensor, Datacontext, Session相关的接口。 开发扩展 ModelBox Server Plugin，ModelBox Device，ModelBox Flowunit的扩展，请参考相关的开发指导。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/c++.html":{"url":"api/c++.html","title":"C++","keywords":"","body":"C++ API 在ModelBox服务启动，并开启Editor编辑器后，可直接使用http://[host]:1104/api/访问。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python.html":{"url":"api/python.html","title":"Python","keywords":"","body":"Python API modelbox 组件名 功能 modelbox.Buffer modelbox存储基本数据的数据结构 modelbox.BufferList modelbox存储基本数据的数据结构 modelbox.Configuration modelbox存放配置项的数据结构 modelbox.DataContext modelbox在流单元执行时存放数据的上下文 modelbox.DataMeta modelbox挂在端口上面存放数据元信息的数据结构 modelbox.Device modelbox映射设备的数据结构 modelbox.ExtOutputBufferList modelbox获取入口信息的数据结构 modelbox.ExternalData modelbox流单元中自驱动产生数据的数据结构 modelbox.ExternalDataMap modelbox当中flow对象产生数据的数据结构 modelbox.Flow modelbox中启动任务的组件 modelbox.FlowUnit modelbox当中构建业务的基本节点的数据结构 modelbox.FlowUnitError modelbox中描述error的数据结构 modelbox.FlowUnitEvent modelbox中描述event的数据结构 modelbox.Log modelbox的日志组件 modelbox.SessionContext modelbox描述上下文的数据结构 modelbox.Status modelbox描述状态的数据结构 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_buffer.html":{"url":"api/python/modelbox_buffer.html","title":"Buffer","keywords":"","body":"modelbox.Buffer 函数 作用 as_object 将modelbox buffer对象转换成python对象 copy_meta 拷贝参数自带的所有meta信息给当前buffer has_error 判断当前buffer是否存在error get_error 获取当前buffer的error get_bytes 获取当前buffer的字节数 get 获取当前buffer的某个meta值 set 设置当前buffer的某个meta值 构造方法 buffer的构造方法 构造方法 把参数的buffer的meta信息 copy给当前buffer modelbox.Buffer(device, data) args: device (modelbox.Device) —— 构造当前buffer所在的modelbox.Device对象 data (numpy.array) —— 当前buffer包含的numpy数据 modelbox.Buffer(device, string) args: device (modelbox.Device) —— 构造当前buffer所在的modelbox.Device对象 string (str) —— 当前buffer包含的string数据 modelbox.Buffer(device, list_item) args: device (modelbox.Device) —— 构造当前buffer所在的modelbox.Device对象 list_item (str) —— 当前buffer包含的list数据，其中每一个元素必须同一类型 return: modelbox.Buffer example: import numpy as np ... def Process(self, data_ctx): infer_data = np.ones((5,5)) numpy_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) str_buffer = modelbox.Buffer(self.get_bind_device(), \"test\") list_buffer = modelbox.Buffer(self.get_bind_device(), [3.1, 3.2, 3.3]) ... return modelbox.Status() result: new_buffer具有和原始buf相同的meta信息 modelbox.Buffer.as_object 将modelbox buffer object 转换成python对象(可以转换成numpy array和str对象) args: 无 return: str 或者 numpy.array对象 example: ... def Process(self, data_ctx): buf_list = data_ctx.input(\"input\") for buf in buf_list: data = buf.as_object() print(data, type(data)) ... return modelbox.Status() result: # 在demo mnist 当中mnist_preprocess的结果为(str) {\"image_base64\": \"iVBORw0...\"} # 在test python当中的python_show flowunit中结果为(numpy.ndarray) [ 3 5 6 ..., 3 6 13] modelbox.Buffer.has_error 判断当前buffer是否存在error args: 无 return: bool, 是否存在error example: ... def Process(self, data_ctx): buf_list = data_ctx.input(\"input\") for buf in buf_list: res = buf.has_error() ... return modelbox.Status() result: buf是否有error modelbox.Buffer.get_error args: 无 return: modelbox.FlowUnitError， 具体参见FlowUnitError章节 example: ... def Process(self, data_ctx): buf_list = data_ctx.input(\"input\") for buf in buf_list: error = buf.get_error() ... return modelbox.Status() result: 获得一个FlowUnitError对象 modelbox.Buffer.get_bytes 获取当前buffer的字节数 args: 无 return: int64, buffer的bytes example: import numpy as np ... def Process(self, data_ctx): infer_data = np.ones((5,5)) new_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) bytes = new_buffer.get_bytes() print(bytes) ... return modelbox.Status() result: 字节数为 5*5*8 = 200 modelbox.Buffer.set 设置当前buffer的某个meta值 args: key (str) —— meta的key值 obj (int, str, double, bool, modelbox.ModelBoxDataType, list[str], list[int], list[double], list[bool]) —— meta的value值 return: bool, 是否设置成功 modelbox.Buffer.get 获取当前buffer的某个meta值 args: key (str) —— meta的key值 return: python object 获取key对应的value值 type: int, double, str, bool, list[int], list[str], list[double], list[bool] example: ... def Process(self, data_ctx): infer_data = np.ones((5,5)) new_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) res = new_buffer.set(\"test\", \"test\") print(test) print(new_buffer.get(\"test\")) ... return modelbox.Status() result: True'test' modelbox.Buffer.copy_meta 把参数的buffer的meta信息 copy给当前buffer args: buffer (modelbox.Buffer) —— meta来源的buffer return: modelbox.Status 返回copy_meta接口Status example: import numpy as np ... def Process(self, data_ctx): buf_list = data_ctx.input(\"input\") for buf in buf_list: infer_data = np.ones((5,5)) new_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) status = new_buffer.copy_meta(buf) ... return modelbox.Status() result: new_buffer具有和原始buf相同的meta信息 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_bufferlist.html":{"url":"api/python/modelbox_bufferlist.html","title":"BufferList","keywords":"","body":"modelbox.BufferList 函数 作用 build bufferlist对象申请指定长度大小的内存空间 copy_meta 拷贝参数自带的所有meta信息给当前bufferlist get_bytes 获取当前bufferlist的字节大小 push_back 将一个buffer插入到当前的bufferlist当中 set 设置当前bufferlist的某个meta值 size 获取当前bufferlist的长度 len 可以被len函数获取当前bufferlist的长度 构造方法 bufferlist的构造方法 构造方法 BufferList申请内存空间 modelbox.BufferList() args: 无 modelbox.BufferList(device) args: device (modelbox.Device) —— 构造当前buffer所在的modelbox.Device对象 modelbox.BufferList(buffer) args: buffer (modelbox.Buffer) —— 通过buffer构建bufferList modelbox.BufferList(buffer_list) args: buffer_list (list[modelbox.Buffer]) —— 一组buffer return: modelbox.BufferList example: ... def Process(self, data_ctx): inputbuf_list = data_ctx.input(\"input\") outputbuf_list = data_ctx.output(\"output\") ... return modelbox.Status() result: inputbuf_list和output_buf_list均为构建好的bufferlist，一般而言并不需要用户构建bufferlist modelbox.BufferList.build BufferList申请内存空间 args: sizes (list[int]) —— buffer_list当中每一个buffer的大小 return: modelbox.Status 申请结果的状态 example: ... def Process(self, data_ctx): buf_list = data_ctx.output(\"output\") res = buf_list.build([20, 20, 20]) print(res, buf_list.size()) for buf in buf_list: print(buf.get_bytes()) ... return modelbox.Status() result: true, 3202020 modelbox.BufferList.copy_meta 把参数的bufferlist里面的meta信息，copy给当前的bufferlist，一对一拷贝 args: buffer_list (modelbox.BufferList) —— meta来源的bufferlist return: modelbox.Status example: ... def Process(self, data_ctx): input_bufs = data_ctx.input(\"input\") output_bufs = data_ctx.output(\"output\") input_bytes = [] for buf in input_bufs: input_bytes.append(buf.get_bytes()) output_bufs.build(input_bytes) res = output_bufs.copy_meta(input_bufs) ... return modelbox.Status() result: output_bufs具有和原始input_bufs相同的meta信息 modelbox.BufferList.get_bytes 获取BufferList中的所有的字节数 args: 无 return: uint64 example: ... def Process(self, data_ctx): buf_list = data_ctx.output(\"output\") buf_list.build([20,20,20]) print(buf_list.get_bytes()) ... return modelbox.Status() result: 60 modelbox.BufferList.push_back 往bufferlist当中插入一个新的buffer args: buffer (modelbox.Buffer) —— 需要插入到bufferlist当中的buffer return: 无 example: import numpy as np ... def Process(self, data_ctx): buf_list = data_ctx.output(\"output\") infer_data = np.ones((5,5)) new_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) buf_list.push_back(new_buffer) ... return modelbox.Status() result: buf_list当中的第一个buffer即为新建的buffer modelbox.BufferList.size 获取当前bufferlist的长度 args: 无 return: modelbox.Bufferlist的长度 example: ... def Process(self, data_ctx): buf_list = data_ctx.output(\"output\") buf_list.build([20,20,20]) size = buf_list.size() length = len(buf_list) print(size) print(length) for buf in buf_list: print(buf.get_bytes()) ... return modelbox.Status() result: 33202020 modelbox.BufferList.set 设置当前bufferlist的某个meta值 args: key (str) —— meta的key值 obj (int, str, double, bool, modelbox.ModelBoxDataType, list[str], list[int], list[double], list[bool]) —— meta的value值 return: 无 example: ... def Process(self, data_ctx): buf_list = data_ctx.output(\"output\") for i in range(3): infer_data = np.ones((5,5)) new_buffer = modelbox.Buffer(self.get_bind_device(), infer_data) buf_list.push_back(new_buffer) res = buf_list.set(\"test\", \"test\") print(res) for buf in buf_list: print(buf.get(\"test\")) ... return modelbox.Status() result: truetesttesttest ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_configuration.html":{"url":"api/python/modelbox_configuration.html","title":"Configuration","keywords":"","body":"modelbox.Configuration 函数 作用 get 从configuration对象当中获取值 set 在configuration对象中设置值 modelbox.Configuration.set args: key: str meta的key值 obj: int, str, double, bool, list[str], list[int], list[double], list[bool]meta的value值 return: 无 modelbox.Configuration.get api: 函数名 功能 get_string 获取字符串值 get_int 获取整型值 get_float 获取浮点型值 get_bool 获取布尔值 get_string_list 获取字符串列表值 get_int_list 获取整型列表值 get_float_list 获取浮点型列表值 get_bool_list 获取布尔列表值 args: key (str) —— 需要获取的meta的key值 return: python object 获取key对应的value值 type: int, double, str, bool, list[int], list[str], list[double], list[bool] example: ... def Open(self, data_ctx, config): config.set(\"int\", 3) config.set(\"bool\", True) config.set(\"string\", \"test\") config.set(\"float\", 3.1) config.set(\"ints\", [3,4]) config.set(\"bools\", [True, False]) config.set(\"strings\", [\"test1\", \"test2\"]) config.set(\"floats\", [3.1, 3.2]) print(config.get_int(\"int\")) print(config.get_int_list(\"ints\")) print(config.get_bool(\"bool\")) print(config.get_bool_list(\"bools\")) print(config.get_string(\"string\")) print(config.get_string_list(\"strings\")) print(config.get_float(\"float\")) print(config.get_float_list(\"floats\")) ... return modelbox.Status() result: 3[3,4]True[True, False]\"test\"[\"test1\", \"test2\"]3.1[3.1, 3.2] ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_datacontext.html":{"url":"api/python/modelbox_datacontext.html","title":"DataContext","keywords":"","body":"modelbox.DataContext 每一个流单元当中存放数据上下文的所有接口 函数 作用 input flowunit获取input端口的数据 output flowunit获取output端口的数据 has_error datacontext当中是否存在error get_error 从datacontext中获取error set_private_string 设置datacontext中的私有字符串值 get_private_string 获取datacontext中的私有字符串值 set_private_int 设置datacontext中的私有整型值 get_private_int 获取datacontext中的私有整型值 get_input_meta 获取datacontext当中绑定在input端口的值 set_output_meta 设置datacontext当中绑定在output端口的值 get_session_config 获取datacontext当中的session config get_session_context 获取datacontext当中的session_context send_event 发送event modelbox.DataContext.has_error 当前数据上下文是否存在error args: 无 return: bool 是否存在error modelbox.DataContext.get_error 获取当前数据上下文是否存在error args: 无 return: modelbox.FlowUnitError 获取当前数据上下文的error对象 example: ... def Process(self, data_ctx): if data_ctx.has_error(): error = data_ctx.get_error() print(error.get_description(), type(error)) ... return modelbox.Status() result: \"error\"modelbox.FlowUnitError modelbox.DataContext.send_event 从当前数据上下文发送event给调度器 args: modelbox.FlowUnitEvent return: 无 example: ... def Process(self, data_ctx): event = modelbox.FlowUnitEvent() data_ctx.send_event(event) ... return modelbox.Status() result: 具体接口参见FlowUnitEvent modelbox.DataContext.set_private_string 设置当前数据上下文私有字符串值 args: key (str) —— 设置字符串型值得key value (str) —— 设置字符串型值的value return: 无 modelbox.DataContext.get_private_string 获取当前数据上下文私有字符串值 args: key (str) —— 需要获取的字符串型的key return: str 获取当前key值的字符串型value值 modelbox.DataContext.set_private_int 设置当前数据上下文私有整型值 args: key (str) —— 设置整型值得key value (int) —— 设置整型值的value return: 无 modelbox.DataContext.get_private_int 获取当前数据上下文私有整型值 args: key (str) —— 需要获取的整型的key return: int 获取当前key值的整型value值 example: ... def Process(self, data_ctx): data_ctx.set_private_string(\"test\", \"test\") print(data_ctx.get_private_string(\"test\")) data_ctx.set_private_int(\"int\", 33) print(data_ctx.get_private_int(\"int\")) ... return modelbox.Status() result: \"test\"33 modelbox.DataContext.input flowunit获取input端口的数据 args: key (str) —— input端口的名称 return: modelbox.BufferList 名称为key的input端口的数据的BufferList modelbox.DataContext.output flowunit获取input端口的数据 args: key (str) —— output端口的名称 return: modelbox.BufferList 名称为key的output端口的数据的BufferList example: ... def Process(self, data_ctx): input_buf_list = data_ctx.input(\"input\") output_buf_list = data_ctx.output(\"output\") ... return modelbox.Status() result: 获取指定端口的数据bufferList, 注意input和output端口必须为当前流单元定义 modelbox.DataContext.get_input_meta 获取当前数据上下文的input端口上面的meta值 args: key (str) —— input端口名 return: modelbox.DataMeta 保存meta值得modelbox数据结构 modelbox.DataContext.set_output_meta 设置当前数据上下文的output端口上面的meta值 args: key (str) —— output端口名 meta (modelbox.DataMeta) —— 绑定在当前端口的DataMeta数据结构 return: modelbox.Status 设置的状态 example: ... def Process(self, data_ctx): input_meta = data_ctx.get_input_meta(\"input\") res = data_ctx.set_output_meta(\"output\", input_meta) ... return modelbox.Status() result: 获取input端口的meta和直接将该meta设置给output, modelbox.DataMeta参照data meta的接口 modelbox.DataContext.get_session_config 获取当前数据上下文的session config args: 无 return: modelbox.SessionConfig modelbox.DataContext.get_session_context 获取当前数据上下文的session context args: 无 return: modelbox.SessionContext example: ... def Process(self, data_ctx): session_config = data_ctx.get_session_config() session_context = data_ctx.get_session_context() ... return modelbox.Status() result: 具体接口参见session_config和session_context接口 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_datameta.html":{"url":"api/python/modelbox_datameta.html","title":"DataMeta","keywords":"","body":"modelbox.DataMeta 函数 作用 set_private_string 设置datameta中的私有字符串值 get_private_string 获取datameta中的私有字符串值 set_private_int 设置datameta中的私有整型值 get_private_int 获取datameta中的私有整型值 modelbox.DataMeta.set_private_string 设置DataMeta私有字符串值 args: key (str) —— 设置字符串型值得key value (str) —— 设置字符串型值的value return: 无 modelbox.DataMeta.get_private_string 获取DataMeta私有字符串值 args: key (str) —— 需要获取的字符串型的key return: str 获取当前key值的字符串型value值 modelbox.DataMeta.set_private_int 设置DataMeta私有整型值 args: key (str) —— 设置整型值得key value (int) 设置整型值的value return: 无 modelbox.DataMeta.get_private_int 获取DataMeta私有整型值 args: key (str) —— 需要获取的整型的key return: int 获取当前key值的整型value值 example: ... def Process(self, data_ctx): data_meta = modelbox.DataMeta() data_meta.set_private_string(\"test\", \"test\") print(data_meta.get_private_string(\"test\")) data_meta.set_private_int(\"int\", 33) print(data_meta.get_private_int(\"int\")) ... return modelbox.Status() result: \"test\"33 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_device.html":{"url":"api/python/modelbox_device.html","title":"Device","keywords":"","body":"modelbox.Device 函数 作用 get_device_id 获取当前device id, e.g. 0, 1, 2 get_type 获取当前device 类型, e.g. cpu, cuda get_device_desc 获取当前device 描述 modelbox.Device.get_device_id 获取当前device id args: 无 return: str 设备的id modelbox.Device.get_type 获取当前device type args: 无 return: str 设备的类型信息 modelbox.Device.get_device_desc 获取当前device desc args: 无 return: str 设备的描述信息 example: ... def Process(self, data_ctx): device = get_bind_device() print(device.get_device_id()) print(device.get_device_type()) print(device.get_device_desc()) ... return modelbox.Status() result: \"0\"\"cpu\"\"this is a cpu device\" ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_externaldata.html":{"url":"api/python/modelbox_externaldata.html","title":"ExternalData","keywords":"","body":"modelbox.ExternalData 函数 作用 create_buffer_list 创建bufferlist send 发送要给本流单元的process单元的bufferlist get_session_context 获取session_context对象 get_session_config 获取session_config对象 close 关闭当前external_data的链接 modelbox.ExternalData.create_buffer_list 创建bufferList args: 无 return: modelbox.BufferList modelbox.ExternalData.send 发送bufferlist给下一个流单元 args: bufferlist (modelbox.BufferList) —— 需要发送的bufferlist return: modelbox.Status 发送的返回状态 modelbox.ExternalData.close 关闭external对象 args: 无 return: modelbox.Status 关闭的返回状态 example: ... def Open(self, config): extern_data = create_external_data() buffer_list = extern_data.create_buffer_list() buffer = np.ones((5,5)) buffer_list.push_back(buffer) extern_data.send(buffer_list) extern_data.close() ... return modelbox.Status() result: 本流单元的process既可以接受到当前bufferlist modelbox.ExternalData.get_session_context 获取session_context对象 args: 无 return: modelbox.SessionContext modelbox.ExternalData.get_session_config 获取session_config对象 args: 无 return: modelbox.SessionConfig example: ... def Open(self, config): extern_data = create_external_data() session_config = extern_data.get_session_config() session_context = extern_data.get_session_context() ... return modelbox.Status() result: 获取session_config和session_context ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_externaldatamap.html":{"url":"api/python/modelbox_externaldatamap.html","title":"ExternalDataMap","keywords":"","body":"modelbox.ExternalDataMap 函数 作用 create_buffer_list 设置datameta中的私有字符串值 send 设置datameta中的私有字符串值 recv 设置datameta中的私有字符串值 shutdown 设置datameta中的私有字符串值 set_output_meta 设置datameta中的私有字符串值 modelbox.ExternalDataMap.create_buffer_list 创建bufferList args: 无 return: modelbox.BufferList modelbox.ExternalDataMap.send 发送bufferlist给下一个流单元 args: port_name (str) —— 需要发送的数据的端口名 bufferlist (modelbox.BufferList) —— 需要发送的bufferlist return: modelbox.Status 发送的返回状态 modelbox.ExternalDataMap.recv 在参数的output_bufferlist接收数据 args: bufferlist (modelbox.ExtOutputBufferList) —— 用来接收数据的bufferlist return: modelbox.Status 发送的返回状态 modelbox.ExternalDataMap.shutdown 关闭external data map对象 args: 无 return: modelbox.Status 关闭的返回状态 example: ... import modelbox import numpy as np flow = modelbox.Flow() img_np = np.ones((5,5)) extern_data_map = flow.create_external_data_map() buffer_list = extern_data_map.create_buffer_list() buffer_list.push_back(img_np) ret = extern_data_map.send(\"input1\", buffer_list) ret = extern_data_map.shutdown() buffer_list_map = modelbox.ExtOutputBufferList() ret = extern_data_map.recv(buffer_list_map) digraph demo { input1[type=input] python_buffer[type=flowunit, flowunit=python_buffer, device=cpu, deviceid=0, label=\" | \", buffer_config = 0.2] output1[type=output] input1 -> python_buffer:buffer_in python_buffer:buffer_out -> output1 } result: 在定义的流程图中从input1输入数据 modelbox.ExternalDataMap.set_output_meta 设置输出端口的meta值 args: port_name (str) —— 输出的端口名字 meta (modelbox.DataMeta) —— 存放meta的数据结构 return: modelbox.Status 返回状态 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_extoutputbufferlist.html":{"url":"api/python/modelbox_extoutputbufferlist.html","title":"ExtOutputBufferList","keywords":"","body":"modelbox.ExtOutputBufferList 函数 作用 get_buffer_list 设置datameta中的私有字符串值 modelbox.ExtOutputBufferList.get_buffer_list 获取当前device id args: 无 return: modelbox.BufferList example: ... import numpy as np img_np = np.ones((5,5)) flow = modelbox.Flow() extern_data_map = flow.create_external_data_map() buffer_list = extern_data_map.create_buffer_list() buffer_list.push_back(img_np) extern_data_map.send(\"input1\", buffer_list) extern_data_map.shutdown() buffer_list_map = modelbox.ExtOutputBufferList() ret = extern_data_map.recv(buffer_list_map) self.assertTrue(ret) result_buffer_list = buffer_list_map.get_buffer_list(\"output1\") ... result: 获取指定端口的数据(bufferlist), 一般和externalDataMap一起使用 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_flow.html":{"url":"api/python/modelbox_flow.html","title":"Flow","keywords":"","body":"modelbox.Flow 函数 作用 init 初始化flow对象 build 构建flow对象，当中主要通过配置文件构建图 run 同步运行flow run_async 异步运行flow wait flow对象等待返回 stop 停止flow create_external_data_map 创建external_data_map modelbox.Flow.init 初始化flow对象 modelbox.Flow.init(conf_file, format) args: conf_file (str) —— 构建流程图的toml文件 format (modelbox.Flow.Format) —— 流程图的format格式，默认可不填 modelbox.Flow.init(name, graph, format) args: name (str) —— 构建图的名称 graph (str) —— 流程图 format (modelbox.Flow.Format) —— 流程图的format格式，默认可不填 modelbox.Flow.init(config) args: config (modelbox.Configuration) —— 构建图的config return: modelbox.Status 初始化flow的状态 modelbox.Flow.build 构建flow对象，当中主要通过配置文件构建图 args: 无 return: modelbox.Status 构建flow的状态 modelbox.Flow.run 同步运行flow args: 无 return: modelbox.Status 同步运行flow的状态 modelbox.Flow.run_async 异步运行flow args: 无 return: modelbox.Status 异步运行flow的状态 modelbox.Flow.wait flow对象等待返回 args: 无 return: modelbox.Status 等待flow的状态 modelbox.Flow.stop 停止运行flow args: 无 return: modelbox.Status 停止运行flow的状态 example: ... conf_file = \"test.toml\" ret = flow.init(conf_file) ret = flow.build() async = True if async == True: ret = flow.run_async() else: ret = flow.run() retval = modelbox.Status() ret = flow.wait(0, retval) ret = flow.stop() result: flow的构建流程 modelbox.Flow.create_external_data_map 创建external_data_map args: 无 return: modelbox.ExternalDataMap, 创建好的external_data_map example: flow = modelbox.Flow() extern_data_map = flow.create_external_data_map() result: 通过flow构建external_data_map ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_flowunit.html":{"url":"api/python/modelbox_flowunit.html","title":"Flowunit","keywords":"","body":"modelbox.FlowUnit 函数 作用 open flowunit初始化逻辑 process flowunit处理逻辑 close flowunit关闭逻辑 data_pre stream flowunit 初始化stream时的逻辑 data_post stream flowunit 结束stream时的逻辑 data_group_pre stream flowunit 初始化所有stream data前的逻辑(不用处理) data_group_post stream flowunit 结束所有stream data后的逻辑(不用处理) create_external_data 创建external_data_map get_bind_device 获取绑定的device create_buffer 创建buffer modelbox.FlowUnit.open flowunit初始化逻辑 args: config (modelbox.Configuration) —— 流程图当中配给当前flowunit的配置项 return: modelbox.Status 初始化flowunit的返回状态 modelbox.FlowUnit.process flowunit处理逻辑 args: data_context (modelbox.DataContext) —— 处理逻辑当中存放数据的上下文 return: modelbox.Status flowunit处理逻辑的返回状态 modelbox.FlowUnit.close flowunit 结束逻辑 args: 无 return: modelbox.Status flowunit 结束逻辑的返回状态 modelbox.FlowUnit.data_pre stream flowunit 初始化stream时的逻辑 args: data_context (modelbox.DataContext) —— 初始化stream逻辑当中存放数据的上下文 return: modelbox.Status 初始化stream时的逻辑的返回状态 modelbox.FlowUnit.data_post stream flowunit 结束stream时的逻辑 args: data_context (modelbox.DataContext) —— 结束stream逻辑当中存放数据的上下文 return: modelbox.Status 结束stream逻辑的返回状态 modelbox.FlowUnit.data_group_pre stream flowunit 初始化所有stream data前的逻辑 args: data_context (modelbox.DataContext) —— 初始化所有stream data前当中存放数据的上下文 return: modelbox.Status 初始化所有stream data前的返回状态 modelbox.FlowUnit.data_group_post stream flowunit 结束所有stream data后的逻辑 args: data_context (modelbox.DataContext) —— 结束所有stream data后当中存放数据的上下文 return: modelbox.Status 结束所有stream data后的逻辑的返回状态 example: ... # 典型flowunit场景 class ExampleFlowUnit(modelbox.FlowUnit): # Derived from modelbox.FlowUnit def __init__(self): super().__init__() def open(self, config): # Open the flowunit to obtain configuration information return modelbox.Status.StatusCode.STATUS_SUCCESS def process(self, data_context): # Process the data in_data = data_context.input(\"in_1\") out_data = data_context.output(\"out_1\") # Example process code. # Remove the following code and add your own code here. for buffer in in_data: response = \"Hello World \" + buffer.as_object() result = response.encode('utf-8').strip() add_buffer = modelbox.Buffer(self.get_bind_device(), result) out_data.push_back(add_buffer) return modelbox.Status.StatusCode.STATUS_SUCCESS def close(self): # Close the flowunit return modelbox.Status() def data_pre(self, data_context): # Before streaming data starts return modelbox.Status() def data_post(self, data_context): # After streaming data ends return modelbox.Status() def data_group_pre(self, data_context): # Before all streaming data starts return modelbox.Status() def data_group_post(self, data_context): # After all streaming data ends return modelbox.Status() [base] name = \"Example\" # The FlowUnit name device = \"cpu\" # The device the flowunit runs on，cpu，cuda，ascend。 version = \"1.0.0\" # The version of the flowunit description = \"description\" # The description of the flowunit entry = \"example@ExampleFlowUnit\" # Python flowunit entry function type = \"python\" # Fixed value # Flowunit Type stream = false # Whether the flowunit is a stream flowunit condition = false # Whether the flowunit is a condition flowunit collapse = false # Whether the flowunit is a collapse flowunit collapse_all = false # Whether the flowunit will collapse all the data expand = false # Whether the flowunit is a expand flowunit # The default Flowunit config [config] item = \"value\" # Input ports description [input] [input.input1] # Input port number, the format is input.input[N] name = \"in_1\" # Input port name type = \"string\" # Input port type # Output ports description [output] [output.output1] # Output port number, the format is output.output[N] name = \"out_1\" # Output port name type = \"string\" # Output port type modelbox.FlowUnit.create_external_data 创建external_data args: 无 return: modelbox.ExternalData, 创建好的external_data example: ... def open(self, config): extern_data = self.create_external_data() ... return modelbox.Status() result: 可以参考external data的接口 modelbox.FlowUnit.get_bind_device 获取当前flowunit绑定的device args: 无 return: modelbox.Device, 当前绑定的device example: ... def process(self, data_context): device = self.get_bind_device() print(type(device)) ... return modelbox.Status() result: modelbox.Device modelbox.FlowUnit.create_buffer 创建buffer args: 无 return: modelbox.Buffer 创建出来的buffer example: ... def process(self, data_context): e_array = np.array([]) e_buffer = self.create_buffer(e_array) ... return modelbox.Status() result: 创建了一个空buffer ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_flowuniterror.html":{"url":"api/python/modelbox_flowuniterror.html","title":"FlowunitError","keywords":"","body":"modelbox.FlowUnitError 函数 作用 get_description 获取error的描述信息 构造方法 构造modelbox.FlowUnitError 构造方法 构造modelbox.FlowUnitError args: error (str) —— 具体的error描述 return: modelbox.FlowUnitError modelbox.FlowUnitError.get_description 获取error的描述信息 args: 无 return: str, 当前error的描述信息 example: ... error = modelbox.FlowUnitError(\"this is error\") err_desc = error.get_description() print(error) result: \"this is error\" ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_flowunitevent.html":{"url":"api/python/modelbox_flowunitevent.html","title":"FlowunitEvent","keywords":"","body":"modelbox.FlowUnitEvent 函数 作用 set_private_string 设置flowunit_event中的私有字符串值 get_private_string 获取flowunit_event中的私有字符串值 set_private_int 设置flowunit_event中的私有整型值 get_private_int 获取flowunit_event中的私有整型值 modelbox.FlowUnitEvent.set_private_string 设置FlowUnitEvent私有字符串值 args: key (str) —— 设置字符串型值得key value (str) —— 设置字符串型值的value return: 无 modelbox.FlowUnitEvent.get_private_string 获取FlowUnitEvent私有字符串值 args: key (str) —— 设置字符串型值得key return: str 获取当前key值的字符串型value值 modelbox.FlowUnitEvent.set_private_int 设置FlowUnitEvent私有整型值 args: key (str) —— 设置整型值得key value (int) —— 设置整型值的value return: 无 modelbox.FlowUnitEvent.get_private_int 获取FlowUnitEvent私有整型值 args: key (str) —— 设置整型值得key return: int 获取当前key值的整型value值 example: ... def Process(self, data_ctx): event = modelbox.FlowUnitEvent() event.set_private_string(\"test\", \"test\") print(event.get_private_string(\"test\")) event.set_private_int(\"int\", 33) print(event.get_private_int(\"int\")) ... return modelbox.Status() result: \"test\"33 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_log.html":{"url":"api/python/modelbox_log.html","title":"Log","keywords":"","body":"modelbox.Log 函数 作用 reg 注册log的回调函数 set_log_level 设置log的日志级别 print 打印日志 print_ext 打印带有额外信息的日志 log推荐用法 推荐使用log的用法 modelbox.Log.reg 注册一个log的回调函数 args: Callable (python function) —— 注册的python回调函数Callable[[Level level, str file, int lineno, str func, str msg], None] return: 无 modelbox.Log.set_log_level 设置log组件的日志级别 args: level (modelbox.Log.Level) —— 日志级别 return: 无 modelbox.Log.print 打印日志 args: level (modelbox.Log.Level) —— 日志级别 msg (str) —— 打印的日志 return: 无 modelbox.Log.printExt args: level (modelbox.Log.Level) —— 日志级别 file (str) —— 文件的路径 lineno (str) —— 行号 func (python function) —— 日志的回调函数 msg (str) —— 日志信息 return: 无 example: import modelbox import inspect import os import datetime def LogCallback(level, file, lineno, func, msg): print(\"[{time}][{level}][{file}:{lineno}] {msg}\".format( time=datetime.datetime.now(), level=level, file=file, lineno=lineno, msg=msg )) def RegLog(log): log.reg(LogCallback) log.set_log_level(modelbox.Log.Level.INFO) if __name__ == \"__main__\": log = modelbox.Log() RegLog(log) log.print(modelbox.Log.Level.INFO, \"test print\") frame = inspect.currentframe() info = inspect.getframeinfo(frame) log.print_ext(modelbox.Log.Level.INFO, os.path.basename(info.filename), info.lineno + 2, info.function, \"test print_ext\") # 推荐用法 modelbox.info(\"test_info\") modelbox.warn(\"test_warn\") modelbox.error(\"test_error\") result: [2021-12-13 17:45:47.614834][Level.INFO][test.py:20] test print[2021-12-13 17:45:47.615028][Level.INFO][test.py:25] test print_ext[2021-12-13 19:39:54.994327][Level.INFO][test.py:28] test_info[2021-12-13 19:39:54.994454][Level.WARN][test.py:29] test_warn[2021-12-13 19:39:54.994601][Level.ERROR][test.py:30] test_error modelbox.Log.Level log level分为以下几种级别 modelbox.Log.Level.DEBUGmodelbox.Log.Level.INFOmodelbox.Log.Level.ERRORmodelbox.Log.Level.WARN ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_sessioncontext.html":{"url":"api/python/modelbox_sessioncontext.html","title":"SessionContext","keywords":"","body":"modelbox.SessionContext 函数 作用 set_private_string 设置session_context中的私有字符串值 get_private_string 获取session_context中的私有字符串值 set_private_int 设置session_context中的私有整型值 get_private_int 获取session_context中的私有整型值 get_session_config 获取session_context中的session confg get_session_id 获取session_context中的session id modelbox.SessionContext.set_private_string 设置SessionContext私有字符串值 args: key (str) —— 设置字符串型值得key value (str) —— 设置字符串型值的value return: 无 modelbox.SessionContext.get_private_string 获取SessionContext私有字符串值 args: key (str) —— 设置字符串型值得key return: str 获取当前key值的字符串型value值 modelbox.SessionContext.set_private_int 设置SessionContext私有整型值 args: key (str) —— 设置整型值得key value (int) —— 设置整型值的value return: 无 modelbox.SessionContext.get_private_int 获取SessionContext私有整型值 args: key (str) —— 设置整型值得key return: int 获取当前key值的整型value值 example: ... def Process(self, data_ctx): session_ctx = data_ctx.get_session_context() session_ctx.set_private_string(\"test\", \"test\") print(session_ctx.get_private_string(\"test\")) session_ctx.set_private_int(\"int\", 33) print(session_ctx.get_private_int(\"int\")) ... return modelbox.Status() result: \"test\"33 modelbox.SessionContext.get_session_config 获取session_config args: 无 return: modelbox.Configuration modelbox.SessionContext.get_session_id 获取session_id args: 无 return: str 获取当前session的id example: ... def Process(self, data_ctx): session_ctx = data_ctx.get_session_context() id = session_ctx.get_session_id() config = session_ctx.get_session_config() ... return modelbox.Status() result: 获取当前session对应的config和id ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/python/modelbox_status.html":{"url":"api/python/modelbox_status.html","title":"Status","keywords":"","body":"modelbox.Status 函数 作用 构造方法 构造status对象 code status的code码 str_code status的code码的描述 StatusCode status的状态码 set_errormsg status设置错误信息 errormsg status获取错误信息 wrap_errormsgs status获取链式的错误信息 unwrap status解链式status对象 构造方法 modelbox.Status(status_code) args: code (modelbox.Status.StatusCode) —— 从StatusCode创建Status modelbox.Status(success) args: success (bool) —— 从bool创建Status modelbox.Status(code, errmsg) args: code (modelbox.Status.StatusCode) —— modelbox的状态码 errmsg (str) —— 错误的信息 modelbox.Status(status, errmsg) status (modelbox.Status) —— modelbox的状态 errmsg (str) —— 错误的信息 return: modelbox.Status str: \"code: \" + StrCode() + \", errmsg: \" + errmsg_ bool: bool(status) example: import modelbox status = modelbox.Status() print(status) status1 = modelbox.Status(modelbox.Status.StatusCode.STATUS_CONTINUE) print(status1) status2 = modelbox.Status(False) print(status2) status3 = modelbox.Status(modelbox.Status.StatusCode.STATUS_CONTINUE, \"continue\") print(status3) status4 = modelbox.Status(status2, \"continue\") print(status4) print(bool(status)) result: SuccessContinue operationFaultcode: Continue operation, errmsg: continuecode: Fault, errmsg: continueTrue modelbox.Status.code 获取status的code值 args: 无 return: modelbox.StatusCode example: import modelbox status = modelbox.Status() print(status.code()) result: StatusCode.STATUS_SUCCESS modelbox.Status.str_code 获取status的str_code值 args: 无 return: str example: import modelbox status = modelbox.Status() print(status.str_code()) result: Success modelbox.Status.StatusCode code str_code modelbox.Status.StatusCode.STATUS_SUCCESS Success modelbox.Status.StatusCode.STATUS_SUCCESS Fault modelbox.Status.StatusCode.STATUS_AGAIN Try again modelbox.Status.StatusCode.STATUS_NOSPACE No space left modelbox.Status.StatusCode.STATUS_ALREADY Operation already in progress modelbox.Status.StatusCode.STATUS_NOSTREAM Out of streams resources modelbox.Status.StatusCode.STATUS_BADCONF Bad config modelbox.Status.StatusCode.STATUS_NOTFOUND Not found modelbox.Status.StatusCode.STATUS_BUSY Device or resource busy modelbox.Status.StatusCode.STATUS_NOTSUPPORT Not supported modelbox.Status.StatusCode.STATUS_CONTINUE Continue operation modelbox.Status.StatusCode.STATUS_OVERFLOW Value too large for defined data type modelbox.Status.StatusCode.STATUS_EDQUOT Quota exceeded modelbox.Status.StatusCode.STATUS_PERMIT Operation not permitted modelbox.Status.StatusCode.STATUS_EOF End of file modelbox.Status.StatusCode.STATUS_RANGE Out of range modelbox.Status.StatusCode.STATUS_EXIST Already exists modelbox.Status.StatusCode.STATUS_RESET Request reset modelbox.Status.StatusCode.STATUS_FAULT Fault modelbox.Status.StatusCode.STATUS_SHUTDOWN Shutdown operation modelbox.Status.StatusCode.STATUS_INPROGRESS Operation now in progress modelbox.Status.StatusCode.STATUS_STOP Stop operation modelbox.Status.StatusCode.STATUS_INTERNAL Internal error modelbox.Status.StatusCode.STATUS_INVALID Invalid argument modelbox.Status.StatusCode.STATUS_TIMEDOUT Operation timed out modelbox.Status.StatusCode.STATUS_NOBUFS No buffer space available modelbox.Status.StatusCode.STATUS_NODATA No data available modelbox.Status.StatusCode.STATUS_NOMEM Out of memory modelbox.Status.StatusCode.STATUS_NOENT No such file or directory modelbox.Status.set_errormsg 设置status的错误信息 args: errmsg: str 错误信息 return: 无 modelbox.Status.errormsg 获取status的errormsg args: 无 return: str 当前status的errmsg modelbox.Status.wrap_errormsgs 获取status的所有子层次的errmsg args: 无 return: str 当前status的子层次errmsg modelbox.Status.unwrap 返回wrap的status args: 无 return: modelbox.Status wrap的status example: import modelbox status = modelbox.Status(False) status.set_errormsg(\"test failed\") print(status.errormsg()) status1 = modelbox.Status(status, \"test failed outside\") print(status1.wrap_errormsgs()) status2 = status1.unwrap() print(status == status2) result: test failedFault, test failed outside -> test failedTrue ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"api/rest.html":{"url":"api/rest.html","title":"REST","keywords":"","body":"REST API ModelBox Server启动后之后，ModelBox Plugin就开始对外提供服务，服务的endpoint为http://server.ip:server.port，其中server.ip和server.port为ModelBox服务运行配置中的配置项，默认为http://127.0.0.1:1104，服务的path为/v1/modelbox/job，业务可通过发送REST请求到插件管理流程图。 ModelBox服务当前提供动态增加flow作业，动态删除flow作业，查询所有flow作业列表，查询flow作业状态 增加flow作业 REST API URI: http://server.ip:server.port/v1/modelbox/job/ METHOD: POST REST API BODY { \"job_id\": \"flow2\", \"job_graph\": \"xxxxx\" } job_id： flow名字，用户自定义，建议不要包含特殊字符。 job_graph：toml格式的图信息，graph的配置详见图 例子 命令：curl -X PUT --data @flow-example http://127.0.0.1:1104/v1/modelbox/job flow-example文件内容： { \"job_id\": \"flow-example\", \"job_graph\": { \"graph\": { \"format\":\"graphviz\", \"graphconf\": [ \" digraph demo { \", \" httpserver_sync_receive[type=flowunit, flowunit=httpserver_sync_receive, device=cpu, deviceid=0, endpoint=\\\"http://127.0.0.1:8080/example\\\", max_requests=10, time_out=5000]\", \" httpserver_sync_reply[type=flowunit, flowunit=httpserver_sync_reply, device=cpu, deviceid=0]\", \" httpserver_sync_receive:out_request_info -> httpserver_sync_reply:in_reply_info\", \" }\" ] }, \"driver\": { \"dir\": \"\", \"skip-default\": \"false\" } } } 返回值 正常返回HTTP code 201。 异常返回错误json： { \"error_code\": \"[some error code]\", \"error_msg\" : \"[some error message]\" } error_code：错误码，参考错误码 error_msg：错误码对应的消息。 查询flow作业状态 REST API URI: http://server.ip:server.port/v1/modelbox/job/[flow-name] REST API RESPONSE 正常返回HTTP code 200，如下json： { \"job_status\": \"RUNNING\", \"job_id\": \"[flow-name]\" } job_status： flow的状态代码。 job_id：flow名称。 例子 命令：curl http://127.0.0.1:1104/v1/modelbox/job/flow-example 删除flow作业 REST API URI: http://server.ip:server.port/v1/modelbox/job/[flow-name] 返回值 正常返回HTTP code 204。 异常返回错误json。 例子 命令： curl -X DELETE http://127.0.0.1:1104/v1/modelbox/job/flow-example 查询所有flow作业列表 REST API URI: http://server.ip:server.port/v1/modelbox/job/list/all 例子 命令: curl http://127.0.0.1:1104/v1/modelbox/job/list/all REST API BODY { \"job_list\": [ { \"job_status\": \"RUNNING\", \"job_id\": \"[flow-name1]\" }, { \"job_status\": \"RUNNING\", \"job_id\": \"[flow-name2]\" } ] } job_list: flow列表。 flow作业状态码 状态码 状态码说明 CREATEING 正在创建任务 RUNNING 任务正在执行 SUCCEEDED 任务执行成功 FAILED 任务执行失败 PENDING 等待执行 DELETEING 正在删除任务 UNKNOWN 未知状态 NOTEXIST 任务不存在 错误码 当前支持的错误码： 错误码 错误码说明 MODELBOX_001 server internal error MODELBOX_002 request invalid, no such job MODELBOX_003 request invalid, can not get jobId MODELBOX_004 request invalid, can not get graph MODELBOX_005 request invalid, job already exist MODELBOX_006 request invalid, invalid command ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"flowunits/flowunits.html":{"url":"flowunits/flowunits.html","title":"预置功能单元","keywords":"","body":"预置功能单元 ModelBox预置了多个通用功能单元，可用于完成AI推理算法的基本流程，开发者可以直接使用。 按业务类型分类，ModelBox主要预置FlowUnit如下表所示。 业务分类 功能单元名称 功能简介 输入类 data_source_parse 解析外部到算法流水线的输入 输入类 video_input 获取视频输入地址 输出类 output_broker 将算法处理结果输出到外部 网络收发类 httpserver_async 收发http异步请求 网络收发类 httpserver_sync_receive 接受http同步请求 网络收发类 httpserver_sync_reply 回复http同步请求 视频类 video_decoder 视频解码 视频类 video_demuxer 视频解封装 视频类 video_encoder 视频编码 图像类 color_convert 对图片进行颜色通道转换 图像类 crop 对图片进行裁剪 图像类 draw_bbox 在图像上画框 图像类 image_decoder 图像解码 图像类 mean 图像减均值 图像类 normalize 图像标准化 图像类 padding 图像填充 图像类 resize 图像尺寸调整 图像类 image_preprocess 图像尺寸调整 推理类 inference 模型推理功能单元 后处理类 yolov3_postprocess 从yolov3模型中获取检测目标的信息 buffer处理类 buff_meta_mapping 做元数据映射 开发者可以通过ModelBox Tool命令查询各个功能单元的详细信息，包括功能介绍、CPU/GPU类型、输入要求、输出信息、配置项、约束等。命令如下： 查询当前系统目录下所有可以加载的功能单元列表： modelbox-tool driver -info -type flowunit 查询单个功能单元详细信息： modelbox-tool driver -info -type flowunit -detail -name xxx 查询当前系统目录和用户自定义路径下所有可以加载的功能单元列表： modelbox-tool driver -info -type flowunit -path xxx 命令帮助信息： modelbox-tool driver 以resize功能单元为例，查询详细结果字段含义如下： [root@996a6346d170 modelbox]$ modelbox-tool driver -info -type flowunit -detail -name resize -------------------------------------- flowunit name : resize # flowunit名称 type : cpu # flowunit类型：cpu：普通cpu; cuda：nvidia gpu; ascend： ascend d310推理加速卡 driver name : resize # driver名称：c++场景一个driver对应一个so，一个driver可以包含多个flowunit version : 1.0.0 descryption : @Brief: A resize flowunit on cpu # flowunit 功能简介 @Port paramter: the input port buffer type and the output port buffer type are image. The image type buffer contain the following meta fields: # flowunit 输入输出数据格式 Field Name: width, Type: int32_t Field Name: height, Type: int32_t Field name: width_stride, Type: int32_t Field name: height_stride, Type: int32_t Field name: channel, Type: int32_t Field name: pix_fmt, Type: string Field name: layout, Type: int32_t Field name: shape, Type: vector Field name: type, Type: ModelBoxDataType::MODELBOX_UINT8 @Constraint: the field value range of this flowunit support：'pix_fmt': [rgb_packed,bgr_packed], 'layout': [hwc]. # flowunit 使用约束 group : Image # flowunit 使用约束 inputs : # flowunit 输入端口列表 input index : 1 name : in_image # 输入端口名称 type : # 输入端口类型，预留 device : cpu # 输入端口数据存放设备要求 outputs : # flowunit 输出端口列表 output index : 1 name : out_image # 输出端口名称 device : cpu # 输出端口数据存放位置 options : # flowunit支持的图配置参数 option : 1 name : image_width # 配置参数名称 default : 640 # 配置参数默认值 desc : the resize width # 配置参数含义描述 required : true # 配置参数是否必填 type : int # 配置参数类型 option : 2 name : image_height default : 480 desc : the resize height required : true type : int option : 3 name : interpolation default : inter_linear desc : the resize interpolation method required : true type : list # 配置参数枚举类型 inter_area : inter_area # 配置参数枚举含义 inter_cubic : inter_cubic inter_lanczos4 : inter_lanczos4 inter_linear : inter_linear inter_max : inter_max inter_nearest : inter_nearest warp_fill_outliers : warp_fill_outliers warp_inverse_map : warp_inverse_map ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"faq/faq.html":{"url":"faq/faq.html","title":"FAQ","keywords":"","body":"FAQ ModelBox 什么是ModelBox，ModelBox有什么功能？ ModelBox是一个AI应用的推理框架，ModelBox通过编排和插件化的形式支持AI应用的开发，支持的数据有视频，音频，语音，文本，通用数据的编排处理，ModelBox的主要功能列表可参考这里 相比直接调用底层API开发AI业务，ModelBox有什么优势？ ModelBox主要聚焦解决AI应用开发的问题，相比直接调用底层API，开发者需要关注每个底层的API使用方法，关注并发，关注GPU，NPU设备编程接口，关注tensorflow，tensorrt等推理框架的编程API，与云计算结合的接口，和分布式通信，日志等琐碎而复杂的周边代码。 ModelBox解决的就是业务开发的周边问题，将周边问题交由ModelBox处理，ModelBox通过对内存，CPU，GPU，周边组件的精细化管理，使AI推理业务开发更高效，性能也更高，质量也更好。 ModelBox目前支持哪些框架训练的模型（TensorFlow、Caffe、PyTorch等） ModelBox框架里面包含了支持TensorFlow, Caffe, Pytorch模型运行所需的功能单元Flowunit，我们称为推理功能单元(Inference Flowunit)，这些推理功能单元可以直接加载对应的模型文件，而不需要编写代码，只需提供一个简单的配置文件，即可将模型引入到ModelBox的流程中。目前支持的模型有TensorFlow, TensorRT, Ascend ACL模型。 ModelBox组件 ModelBox程序包含哪些部分 ModelBox目前包含如下组件 微服务ModelBox Server 运行库ModelBox Library 维护工具ModelBox Tool CPU相关的功能单元 Huawei Ascend相关的功能单元 Cuda相关的功能单元 可视化编辑工具 ModelBox支持服务式吗？ ModelBox有专门的微服务程序，ModelBox Server，ModelBox Server内置了通用的管理插件，和基本功能，开发者只需要配置ModelBox Server即可启动微服务。 如何调试ModelBox程序 ModelBox本身为C++代码编写，开发者可以通过如下方式调试ModelBox程序和相关的功能单元： GDB，IDE等工具调试 ModelBox运行日志。 ModelBox Profiling性能统计工具。 具体操作方法，可参考调试定位章节内容 模型问题 tensorrt在解析模型出错 当tensorrt在解析模型出错时，如果报错 \" expecting compute x.x got compute 7.5, please rebuild\"，说明模型和推理引擎不配套，需要转换模型到配套的硬件, 并在与当前环境配置相同的环境上重新编译模型。 查看当前的镜像对应的欧拉系统的版本 cat /etc/EulerLinux.conf 功能单元 功能单元的分类 功能单元可以分为两大类 1. 实际的功能单元 由实际代码所实现，每套代码对应自己的功能单元 2. 虚拟功能单元 只有一个in配置文件，所有的具体实现在一个tensorrt的模块中，端口名、数据类型都是通过配置文件配置的。 其中的plugin参数指定了可以注册功能的类，比如plugin为yolo，也就是说，yolo的实例注册到tensorrt里面的。 sessioncontext与datacontext sessioncontext保存的是当前flow的全局变量，每一个flowunit存储在里面的数据在其他flowunit也可以读到。 datacontext表示当前flowunit在当前流的数据buffer，可以设置输入输出，也可以保存私有数据。 video_input video_input的repeat可以创建多个并发视频，并不是串行视频流 ModelBox Tool develop mode already enabled 在执行modelbox-tool develop -e开启开发者模式后，如果更改了默认位于/usr/local/etc/modelbox/的modelbox.conf配置文件的内容，需要先执行modelbox-tool develop -d来关闭开发者模式，再启动才行。 开发常见问题 流单元找不到 常见日志报错：code: Not Found, errmsg: create flowunit 'xxx' failed., 通常有如下几个原因，可一一进行排查： 流程图toml配置的driver路径不包含所需流单元so或文件夹； 流单元编译异常，找不到符号。通常会在日志前面扫描到so时提示错误，可通过ldd、c++filt命令进行具体定位； 端口未连接 常见日志报错：code: Bad config, errmsg: flowunit 'xxxx' config error, port not connect correctly, 可能错误原因：代码中流单元定义的端口，未在toml图中使用。需检查定义输入输出端口名称、或driver路径是否错误。 创建图失败 常见日志报错：code: Invalid argument, errmsg: check stream fail., build flow failed等, 通常有以下几种可能错误： toml流程图中，node定义节点在后面边链接中未使用； 端口冲突，如多个输出连接到同一输入端口（if-else终点除外）； if-else流单元之后的各分支，最终需要合并到一个端口上； if-else分支中不能使用stream类型流单元； 多个if-else流单元不能共用同一个终点； 流单元端口连接不能跨越if-else，拆分合并流单元； 具体约束原因详见stream流章节。 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "},"faq/container-usage.html":{"url":"faq/container-usage.html","title":"Container-usage","keywords":"","body":"容器镜像使用 AI推理业务依赖的外部组件比较多，手工安装部署工作量比较大，ModelBox提供了多种推理引擎、硬件加速卡的容器镜像方便开发者使用。本章节介绍了容器镜像使用的步骤。 ModelBox容器镜像选择 ModelBox提供的CUDA，ASCEND硬件和tensoflow，pytorch，mindspore，tensorrt的多种镜像，开发者按照需要拉取使用。 镜像仓库：https://hub.docker.com/u/modelbox 可以选择使用以下命令拉取相关的镜像。比如cuda11.2，tensorflow的open欧拉开发镜像，则镜像如下： docker pull modelbox/modelbox-develop-tensorflow_2.6.0-cuda_11.2-openeuler-x86_64 其他版本可以查看DockerHub中ModelBox仓库的镜像列表。 一键式脚本 为方便使用，可以使用如下一键式脚本，快速启动容器。可将如下脚本按需修改后，粘贴到ssh终端中执行： #!/bin/bash # ssh map port, [modify] SSH_MAP_PORT=50022 # editor map port [modify] EDITOR_MAP_PORT=1104 # http server port [modify] HTTP_SERVER_PORT=8080 # container name [modify] CONTAINER_NAME=\"modelbox_instance_`date +%s` \" # image name IMAGE_NAME=\"modelbox/modelbox-develop-tensorflow_2.6.0-cuda_11.2-openeuler-x86_64\" HTTP_DOCKER_PORT_COMMAND=\"-p $HTTP_SERVER_PORT:$HTTP_SERVER_PORT\" docker run -itd --gpus all -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,video \\ --tmpfs /tmp --tmpfs /run -v /sys/fs/cgroup:/sys/fs/cgroup:ro \\ --name $CONTAINER_NAME -v /opt/modelbox:/opt/modelbox -v /home:/home \\ -p $SSH_MAP_PORT:22 -p $EDITOR_MAP_PORT:1104 $HTTP_DOCKER_PORT_COMMAND \\ $IMAGE_NAME 如果docker版本低于19.03，则需要修改脚本 docker run -itd --runtime=nvidia -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,video \\ --tmpfs /tmp --tmpfs /run -v /sys/fs/cgroup:/sys/fs/cgroup:ro \\ --name $CONTAINER_NAME -v /opt/modelbox:/opt/modelbox -v /home:/home \\ -p $SSH_MAP_PORT:22 -p $EDITOR_MAP_PORT:1104 $HTTP_DOCKER_PORT_COMMAND \\ $IMAGE_NAME 注意事项： 可使用vim start_docker.sh创建文件后，i进入编辑模式后，粘贴上述代码，编辑修改后，wx保存。 SSH_MAP_PORT: 为容器ssh映射端口号。 EDITOR_MAP_PORT: 为可视化开发界面链接端口号。 HTTP_SERVER_PORT: 为http flowunit默认服务端口号。 IMAGE_NAME: 要启动的镜像名称。 docker启动脚本中，请注意启动的镜像版本是否与自己所需的镜像版本一致。 如果在没有GPU的机器上执行上述命令，可以删除--gpus相关的参数。但此时只能使用CPU相关的功能单元。 如果启动镜像之后，端口未被占用却仍旧无法访问，需要检查防火墙。 docker启动脚本中，请注意启动的镜像版本是否与自己所需的镜像版本一致。 使用容器 容器启动完成后，需要配置容器中账号信息，并方便后续使用ssh工具链接进入容器，具体的步骤： 从Host中进入容器，设置root密码 docker exec -it [container id] bash password 使用ssh，或相关的工具链接到容器内部，并启用modelbox的开发者模式。 ssh [docker ip] -p [ssh map port] [docker ip]: 容器所在得Host IP地址。 [ssh map port]：步骤1中SSH_MAP_PORT映射的端口号。 gdb调试设置 如果需要在容器中进行gdb调试，需要在启动容器时添加如下选项： --privileged docker启动脚本详解 此处以modelbox_cuda101_develop:latest镜像举例 docker run -itd --gpus all -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,video \\ --tmpfs /tmp --tmpfs /run -v /sys/fs/cgroup:/sys/fs/cgroup:ro \\ modelbox/modelbox_cuda101_develop:latest 参数: -itd 选项 选项简写 说明 -detach -d 在后台运行容器,并且打印容器id。 -interactive -i 即使没有连接，也要保持标准输入保持打开状态，一般与 -t 连用。 –tty -t 容器重新分配一个伪输入终端，一般与 -i 连用。 参数: -gpus all 请通过 docker -v 检查 Docker 版本。对于 19.03 之前的版本，需要使用 nvidia-docker2 和 --runtime=nvidia 标记；对于 19.03 及之后的版本，则使用 nvidia-container-toolkit 软件包和 --gpus all 标记。 参数: -e 设置环境变量 -参数: -tmpfs 挂载目录到容器中，而且容器内的修改不会同步到宿主机，也不希望存储在容器内， 调用这个参数，将该挂载存储在主机的内存中，当容器停止后， tmpfs挂载被移除，即使提交容器，也不会保存tmpfs挂载 参数: -v 挂载宿主机的指定目录 ( 或文件 ) 到容器内的指定目录 ( 或文件 ) ro表示read-only 注意事项： 容器目录必须为绝对路径 容器销毁后，挂载的文件以及 在容器修改过的内容仍然保留在宿主机中 参数: --privileged=true 当开发者需要使用gdb调试功能时，需要使用特权模式启动docker 参数: --cap-add=SYS_PTRACE 增加容器镜像系统的权限 ptrace()系统调用函数提供了一个进程（the “tracer”）监察和控制 另一个进程（the “tracee”）的方法。 并且可以检查和改变“tracee”进程的内存和寄存器里的数据。 它可以用来实现断点调试和系统调用跟踪。（用于gdb） 参数: --security-opt seccomp=unconfined Seccomp是Secure computing mode的缩写。 设为unconfined可以允许容器执行全部的系统的调用。 有遇到无法启动的问题， 请检查是否安装nvidia-container-toolkit 和对应的cuda(10)版本 ©2022 ModelBox Team all right reserved，powered by Gitbook文件修订时间： 2022-02-24 12:59:08 "}}